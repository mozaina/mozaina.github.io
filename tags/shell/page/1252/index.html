<!doctype html>
<html lang="en-us">
<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">


    <title>shell | 开发者问答集锦</title>
    <meta property="og:title" content="shell - 开发者问答集锦">
    <meta property="og:type" content="article">
        
        
    <meta name="Keywords" content="">
    <meta name="description" content="shell">
        
    <meta name="author" content="">
    <meta property="og:url" content="https://zaina.newban.cn/tags/shell/">
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">

    <link rel="stylesheet" href='/css/normalize.css'>
    <link rel="stylesheet" href='/css/style.css'>
    <link rel="alternate" type="application/rss+xml+xml" href="https://zaina.newban.cn/tags/shell/index.xml" title="开发者问答集锦" />
    <script type="text/javascript" src="//cdn.bootcdn.net/ajax/libs/jquery/3.4.1/jquery.min.js"></script>

    
    
    
    
    
    
</head>


<body>
    <header id="header" class="clearfix">
    <div class="container">
        <div class="col-group">
            <div class="site-name ">
                
                    <a id="logo" href="https://zaina.newban.cn">
                        开发者问答集锦
                    </a>
                
                
            </div>
            <div>
                <nav id="nav-menu" class="clearfix">
                    <a class="" href="https://zaina.newban.cn">首页</a>
                    
                </nav>
            </div>
        </div>
    </div>
</header>

    <div id="body">
        <div class="container">
            <div class="col-group">

                <div class="col-8" id="main">
                    
<div class="res-cons">
    
    <h3 class="archive-title">
        包含标签
        <span class="keyword">shell</span>
        的文章
    </h3>
    

    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/spark%E6%93%8D%E4%BD%9Csparkshell/">spark操作sparkshell</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            读取HDFS 上文件命令，
spark.read.textFile(&ldquo;/user/ssy.097&rdquo;).count
spark.read.wholeTextFiles
SparkContext.wholeTextFiles 能够读取指定目录下的许多小文本文件
spark.read.textFile(&ldquo;/user/ssy.097&rdquo;).map(_.split(&rdquo;\u001,-1&rdquo;)).show //相当于把每一行的内容看做一个map
spark.read.parquet(&ldquo;/user/ssy.097&rdquo;).createOrReplaceTempView(&ldquo;&rdquo;) // createOrReplaceTempView注册为临时表 注册完临时表就可以写sql语句去查询你需要的信息了
val df = sqlContext.read.json(&ldquo;file:///usr/local/spark/examples/src/main/resources/people.json&rdquo;) 读取 JSON 格式的数据
DataFrames 处理结构化数据
df.select(&ldquo;name&rdquo;).show() // 只显示 &ldquo;name&rdquo; 列
df.select(df(&ldquo;name&rdquo;), df(&ldquo;age&rdquo;) + 1).show() // 将 &ldquo;age&rdquo; 加 1
df.filter(df(&ldquo;age&rdquo;) &gt; 21).show() //条件语句
df.groupBy(&ldquo;age&rdquo;).count().show() // groupBy 操作
SQL 语句来进行操作
df.registerTempTable(&ldquo;people&rdquo;) // 将 DataFrame 注册为临时表 people
val result = sqlContext.sql(&ldquo;SELECT name, age FROM people WHERE age &gt;= 13 AND age &lt;= 19&rdquo;) // 执行 SQL 查询……
            <p class="readmore"><a href="https://zaina.newban.cn/posts/spark%E6%93%8D%E4%BD%9Csparkshell/">阅读全文</a></p>
        </div>
    </article>
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/spark%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B8%80sparkshell%E5%90%AF%E5%8A%A8%E8%84%9A%E6%9C%AC%E6%97%B6%E5%80%99%E8%BF%87%E7%A8%8B/">spark源码分析一sparkshell启动脚本时候过程</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            当我们在命令行中输入spark-shell的时候，会自动转为spark shell界面。这个界面中我们可以完成spark的操作。那么，这个过程是怎么进行的呢？
当我们在命令行中输入spark-shell的时候，调用的是spark/bin/spark-shell脚本。以下是spark-shell脚本中的部分代码：
function main() { if $cygwin; then stty -icanonmin 1 -echo &gt; /dev/null 2&gt;&amp;1 export SPARK_SUBMIT_OPTS=&quot;$SPARK_SUBMIT_OPTS -Djline.terminal=unix&quot; &quot;$FWDIR&quot;/bin/spark-submit --class org.apache.spark.repl.Main &quot;${SUBMISSION_OPTS[@]}&quot; spark-shell &quot;${APPLICATION_OPTS[@]}&quot; sttyicanon echo &gt; /dev/null 2&gt;&amp;1 else export SPARK_SUBMIT_OPTS &quot;$FWDIR&quot;/bin/spark-submit --class org.apache.spark.repl.Main &quot;${SUBMISSION_OPTS[@]}&quot; spark-shell &quot;${APPLICATION_OPTS[@]}&quot; fi }  通过上方代码我们可以清楚的看见，main()方法调用了spark-submit脚本。我们前往spark-submit脚本去查看，发现spark- submit又调用了spark-class脚本。
exec &quot;$SPARK_HOME&quot;/bin/spark-class org.apache.spark.deploy.SparkSubmit &quot;${ORIG_ARGS[@]}&quot;  调用了spark-class脚本，并传入若干个参数，其中一个参数是org.apache.spark.deploy.SparkSubmit。spark- class脚本接收到传入的参数，并执行下述语句。
if [ -n &quot;${JAVA_HOME}&quot; ]; then RUNNER=&quot;${JAVA_HOME}/bin/java&quot; else if [ `command -v java` ]; then RUNNER=&quot;java&quot; else echo &quot;JAVA_HOME is not set&quot; &gt;&amp;2 exit 1 fi fi exec &quot;$RUNNER&quot; -cp &quot;$CLASSPATH&quot; $JAVA_OPTS &quot;$@&quot;  上述语句的最后一条表示启动java程序（org.……
            <p class="readmore"><a href="https://zaina.newban.cn/posts/spark%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B8%80sparkshell%E5%90%AF%E5%8A%A8%E8%84%9A%E6%9C%AC%E6%97%B6%E5%80%99%E8%BF%87%E7%A8%8B/">阅读全文</a></p>
        </div>
    </article>
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/spark%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2sparkshell%E7%8E%AF%E5%A2%83%E4%B8%8B%E9%85%8D%E7%BD%AE%E6%9C%AC%E5%9C%B0%E8%AF%BB%E5%85%A5%E6%96%87%E6%9C%AC%E4%BF%A1%E6%81%AF%E6%97%B6%E5%87%BA%E7%8E%B0%E6%8A%A5%E9%94%99console17errornotfoundvaluesc/">Spark环境部署sparkshell环境下配置本地读入文本信息时出现报错console17errornotfoundvaluesc</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            Spark环境部署,配置本地读入文本信息时出现报错：
**Caused by: org.apache.hadoop.ipc.RemoteException: Cannot create directory /tmp/hive/root/648867dc-0554-406f-8a02-233cef6b6cf2. Name node is in safe mode.
The reported blocks 71 needs additional 2 blocks to reach the threshold 0.9990 of total blocks 73.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1335)
at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3874)
at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol 2. c a l l B l o c k i n g M e t h o d ( C l i e n t N a m e n o d e P r o t o c o l P r o t o s .……
            <p class="readmore"><a href="https://zaina.newban.cn/posts/spark%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2sparkshell%E7%8E%AF%E5%A2%83%E4%B8%8B%E9%85%8D%E7%BD%AE%E6%9C%AC%E5%9C%B0%E8%AF%BB%E5%85%A5%E6%96%87%E6%9C%AC%E4%BF%A1%E6%81%AF%E6%97%B6%E5%87%BA%E7%8E%B0%E6%8A%A5%E9%94%99console17errornotfoundvaluesc/">阅读全文</a></p>
        </div>
    </article>
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/spark%E7%9A%84python%E5%92%8Cscalashell%E4%BB%8B%E7%BB%8D%E7%BF%BB%E8%AF%91%E8%87%AAlearningsparklightningfastbigdataanalysis/">Spark的Python和Scalashell介绍翻译自LearningSparkLightningFastBigDataAnalysis</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            ……
            <p class="readmore"><a href="https://zaina.newban.cn/posts/spark%E7%9A%84python%E5%92%8Cscalashell%E4%BB%8B%E7%BB%8D%E7%BF%BB%E8%AF%91%E8%87%AAlearningsparklightningfastbigdataanalysis/">阅读全文</a></p>
        </div>
    </article>
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/spark%E7%9A%84shell%E7%95%8C%E9%9D%A2%E6%93%8D%E4%BD%9Crdd%E7%AE%97%E5%AD%90%E7%B1%BB%E5%9E%8B%E8%BD%AC%E6%8D%A2%E7%AE%97%E5%AD%90%E6%89%A7%E8%A1%8C%E7%AE%97%E5%AD%90%E6%8E%A7%E5%88%B6%E7%AE%97%E5%AD%90/">Spark的shell界面操作RDD算子类型转换算子执行算子控制算子</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            目录
一、HADOOP和Spark生态圈
二、Spark Shell 中算子的操作 （转换算子，执行算子，控制算子）
2.1、Tansformation算子/函数 延迟执行 转换算子
2.2、Action 立刻执行 行动算子
2.3、控制算子 主要是为了对数据进行缓存 详细介绍：https://blog.csdn.net/qq_44472134/article/details/104166577
三、进入shell界面操作算子的两种进入方式（spark的三种模式安装 链接：https://blog.csdn.net/qq_44472134/article/details/104339585）
3.1、spark基于standload的进入方式
3.2、spark基于yarn调度的进入方式
一、HADOOP和Spark生态圈 
二、Spark Shell 中算子的操作 （转换算子，执行算子，控制算子） 2.1、Tansformation算子/函数 延迟执行 转换算子 1、map 窄依赖
2、filter 窄依赖
3、flatMap 窄依赖
4、coalesce (分区数,true) rdd7.partitions.size 查看rdd的分区数 val rdd5=rdd4.coalesce(3,true)
可以增加分区，可以减少分区，有 shuffle（一个父RDD到多个子RDD） 所以是宽依赖
5、repartition (分区数) 不管允不允许都会进行 shuffle val rdd5=rdd4.repartition(4)
可以增加分区，可以减少分区，有shuffle 所以是宽依赖 分区
6、groupByKey（） RDD[String,Iterable(Int)]
7、reduceBykey（_+） val rdd8=rdd7.reduceByKey(+_) 宽依赖
8、sortBykey（） 根据K排序，要求RDD 中必须是KV的，宽依赖
9、sortBy（_._2,false） 以value排序，进行倒序排序
2.2、Action 立刻执行 行动算子 1、collect
2、sum（） 返回Double类型……
            <p class="readmore"><a href="https://zaina.newban.cn/posts/spark%E7%9A%84shell%E7%95%8C%E9%9D%A2%E6%93%8D%E4%BD%9Crdd%E7%AE%97%E5%AD%90%E7%B1%BB%E5%9E%8B%E8%BD%AC%E6%8D%A2%E7%AE%97%E5%AD%90%E6%89%A7%E8%A1%8C%E7%AE%97%E5%AD%90%E6%8E%A7%E5%88%B6%E7%AE%97%E5%AD%90/">阅读全文</a></p>
        </div>
    </article>
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/spark%E7%A8%8B%E5%BA%8F%E6%8F%90%E4%BA%A4%E6%89%A7%E8%A1%8Csparkshell%E7%AE%97%E5%AD%90/">spark程序提交执行sparkshell算子</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            文章目录  spark-shell  spark-shell里的内容 spark-submit spark-class  spark的一些函数  两种方法读文件 transformations和actions  综合程序  打包 提交   把上一次编译后的包解压。

本地启动spark，可以在4040看到sparkUI

spark默认程序名字

spark-shell spark-shell里的内容 调用spark-submit，默认名字Spark shell，$@相当于获取用户输入的模式（比如local）
&quot;${SPARK_HOME}&quot;/bin/spark-submit --class org.apache.spark.repl.Main --name &quot;Spark shell&quot; &quot;$@&quot;  spark-submit 调用了spark-class，传给spark-shell的参数被继承下来了
exec &quot;${SPARK_HOME}&quot;/bin/spark-class org.apache.spark.deploy.SparkSubmit &quot;$@&quot;  spark-class 加载spark-env，环境参数
. &quot;${SPARK_HOME}&quot;/bin/load-spark-env.sh  spark的一些函数 import org.apache.spark.{SparkConf, SparkContext} object Spark02 { def main(args: Array[String]): Unit = { val sparkConf=new SparkConf() //在spark-shell运行的时候再指定，这里的优先级要比在shell里更高，appname可以默认 //shell里有内置 //.setMaster(&quot;local[2]&quot;).setAppName(&quot;Spark02&quot;) val sc =new SparkContext(sparkConf) //创建rdd方法1，第一个参数是数组，第二个参数是默认切片 // val rdd = sc.……
            <p class="readmore"><a href="https://zaina.newban.cn/posts/spark%E7%A8%8B%E5%BA%8F%E6%8F%90%E4%BA%A4%E6%89%A7%E8%A1%8Csparkshell%E7%AE%97%E5%AD%90/">阅读全文</a></p>
        </div>
    </article>
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/spark%E8%BF%90%E8%A1%8Cshell%E6%8A%A5%E9%94%99servicesparkdrivercouldnotbindonarandomfreeport/">Spark运行shell报错ServicesparkDrivercouldnotbindonarandomfreeport</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            安装了spark之后，想要运行Scala版本的shell，于是进入Spark目录，执行下面的代码
./bin/spark-shell  出现报错，前面是一些WARN

对于WARN
 WARN Utils: Service 'sparkDriver' could not bind on a random free port. You may check whether configuring an appropriate binding address.  需要修改hostname

还有个前提是，hostname的修改要与其他文件的修改对应起来
首先是主机名的修改
修改/etc/sysconfig/network

如图，我是把原来起的一个名字改回了localhost
在然后修改/etc/hosts文件，我也是改回了原来的默认配置
127.0.0.1 localhost
再次运行，不再报错了，之前说的那个WARN也没有了……
            <p class="readmore"><a href="https://zaina.newban.cn/posts/spark%E8%BF%90%E8%A1%8Cshell%E6%8A%A5%E9%94%99servicesparkdrivercouldnotbindonarandomfreeport/">阅读全文</a></p>
        </div>
    </article>
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/spark%E9%9B%86%E7%BE%A4%E9%85%8D%E7%BD%AE%E5%92%8Csparkshell%E4%B8%80%E4%BA%9B%E5%88%97%E5%91%BD%E4%BB%A4/">Spark集群配置和Sparkshell一些列命令</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            1.安装配置JDK 2.安装配置Spark，修改Spark配置文件(两个配置文件spark-env.sh和slaves) vim spark-env.sh
#指定JAVA_HOME位置
export JAVA_HOME=/home/hadoop/appp/java/jdk1.7.0_45
#指定spark Master的IP
export SPARK_MASTER_IP=192.168.146.100
#指定spark老大Master的端口
export SPARK_MASTER_PORT=7077
#指定可用的CPU内核数量(默认:所有可用)
export SPARK_WORKER_CORES=2
#作业可使用的内存容量，默认格式为1000m或者2g(默认:所有RAM去掉给操作系统用的1GB)
export SPARK_WORKER_MEMORY=2g
3.在slaves文件中加入所有Work的地址 192.168.146.101
192.168.146.102
4.(可选)配置两个Spark Master实现高可靠(首先要配置zookeeper集群，在spark- env.sh添加SPARK_DAEMON_JAVA_OPTS)
export JAVA_HOME=/home/hadoop/appp/java/jdk1.7.0_45
export SPARK_DAEMON_JAVA_OPTS=&ldquo;-Dspark.deploy.recoveryMode=ZOOKEEPER -Dspark.deploy.zookeeper.url=192.168.146.100:2181 -Dspark.deploy.zookeeper.dir=/spark&rdquo;
export SPARK_WORKER_CORES=2
export SPARK_WORKER_MEMORY=2g
export JAVA_HOME=/home/hadoop/appp/java/jdk1.7.0_45
export SPARK_MASTER_IP=192.168.146.100
export SPARK_MASTER_PORT=7077
export SPARK_WORKER_CORES=2
export SPARK_WORKER_MEMORY=1g
启动 spark 命令 在sbin目录下运行master （和启动hadoop命令相同，可以更改）
./start-all.sh
启动 spark shell 命令 bin/spark-shell &ndash;master spark://192.168.146.100:7077 &ndash;total-executor-cores 2 &ndash;executor-memory 512m
不写默认1G,worker上面核全部用
运行相关包的命令 bin/spark-submit &ndash;master spark://192.168.146.100:7077 (不指定就会在本地跑) &ndash;class 指定main方法 -total &ndash;executor-memory 512m -executor-cores 2 指定jar包 传入参数（hdfs://192.……
            <p class="readmore"><a href="https://zaina.newban.cn/posts/spark%E9%9B%86%E7%BE%A4%E9%85%8D%E7%BD%AE%E5%92%8Csparkshell%E4%B8%80%E4%BA%9B%E5%88%97%E5%91%BD%E4%BB%A4/">阅读全文</a></p>
        </div>
    </article>
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/spark%E9%A1%B9%E7%9B%AE%E7%9A%84%E5%88%9B%E5%BB%BAsparkshell%E7%94%A8%E6%B3%95/">Spark项目的创建Sparkshell用法</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            Spark 2.2.0 is built and distributed to work with Scala 2.11 by default. (Spark can be built to work with other versions of Scala, too.) To write applications in Scala, you will need to use a compatible Scala version (e.g. 2.11.X).
如何创建一个Spark项目：
To write a Spark application, you need to add a Maven dependency on Spark. Spark is available through Maven Central at:
 org.apache.spark spark-core_2.11 2.2.0  Finally, you need to import some Spark classes into your program.……
            <p class="readmore"><a href="https://zaina.newban.cn/posts/spark%E9%A1%B9%E7%9B%AE%E7%9A%84%E5%88%9B%E5%BB%BAsparkshell%E7%94%A8%E6%B3%95/">阅读全文</a></p>
        </div>
    </article>
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/spbshell3d%E6%89%93%E9%80%A0%E6%9C%80%E9%85%B73d%E6%95%88%E6%9E%9C%E7%9A%84android%E7%95%8C%E9%9D%A2/">SPBShell3D打造最酷3D效果的Android界面</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            ……
            <p class="readmore"><a href="https://zaina.newban.cn/posts/spbshell3d%E6%89%93%E9%80%A0%E6%9C%80%E9%85%B73d%E6%95%88%E6%9E%9C%E7%9A%84android%E7%95%8C%E9%9D%A2/">阅读全文</a></p>
        </div>
    </article>
    

    



<ol class="page-navigator">
    
    <li class="prev">
        <a href="https://zaina.newban.cn/tags/shell/page/1251/">上一页</a>
    </li>
    

    

    
        
        
    
    

    
        
        
        <li >
            <a href="https://zaina.newban.cn/tags/shell/">1</a>
        </li>
        
    
        
        <li>
            <span>...</span>
        </li>
        
    
        
        
        <li >
            <a href="https://zaina.newban.cn/tags/shell/page/1250/">1250</a>
        </li>
        
    
        
        
        <li >
            <a href="https://zaina.newban.cn/tags/shell/page/1251/">1251</a>
        </li>
        
    
        
        
        <li  class="current">
            <a href="https://zaina.newban.cn/tags/shell/page/1252/">1252</a>
        </li>
        
    
        
        
        <li >
            <a href="https://zaina.newban.cn/tags/shell/page/1253/">1253</a>
        </li>
        
    
        
        
        <li >
            <a href="https://zaina.newban.cn/tags/shell/page/1254/">1254</a>
        </li>
        
    
        
        <li>
            <span>...</span>
        </li>
        
    
        
        
        <li >
            <a href="https://zaina.newban.cn/tags/shell/page/1621/">1621</a>
        </li>
        
    

    
    

    <li class="next">
        <a href="https://zaina.newban.cn/tags/shell/page/1253/">下一页</a>
    </li>
    
</ol>




</div>

                    <footer id="footer">
    <div>
        &copy; 2020 <a href="https://zaina.newban.cn">开发者问答集锦 By </a>
        
    </div>
    <br />
    <div>
        <div class="github-badge">
            <a href="https://gohugo.io/" target="_black" rel="nofollow"><span class="badge-subject">Powered by</span><span class="badge-value bg-blue">Hugo</span></a>
        </div>
        <div class="github-badge">
            <a href="https://www.flysnow.org/" target="_black"><span class="badge-subject">Design by</span><span class="badge-value bg-brightgreen">飞雪无情</span></a>
        </div>
        <div class="github-badge">
            <a href="https://github.com/flysnow-org/maupassant-hugo" target="_black"><span class="badge-subject">Theme</span><span class="badge-value bg-yellowgreen">Maupassant</span></a>
        </div>
    </div>
</footer>



<a id="rocket" href="#top"></a>
<script type="text/javascript" src='/js/totop.js?v=0.0.0' async=""></script>



    <script type="text/javascript" src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script>




                </div>

                <div id="secondary">
    <section class="widget">
        <form id="search" action='https://zaina.newban.cn/search/' method="get" accept-charset="utf-8" target="_blank" _lpchecked="1">
      
      <input type="text" name="q" maxlength="20" placeholder="Search">
      <input type="hidden" name="sitesearch" value="https://zaina.newban.cn">
      <button type="submit" class="submit icon-search"></button>
</form>
    </section>
    
    <section class="widget">
        <h3 class="widget-title">最近文章</h3>
<ul class="widget-list">
    
    <li>
        <a href="https://zaina.newban.cn/posts/001rubyruby%E4%B8%AD%E5%85%A8%E5%B1%80%E5%8F%98%E9%87%8F%E5%AE%9E%E4%BE%8B%E5%8F%98%E9%87%8F%E5%B1%80%E9%83%A8%E5%8F%98%E9%87%8F%E7%B1%BB%E5%8F%98%E9%87%8Fsymbol%E5%AF%B9%E6%AF%94/" title="001rubyRuby中全局变量实例变量局部变量类变量Symbol对比">001rubyRuby中全局变量实例变量局部变量类变量Symbol对比</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/007hadoop%E9%9B%86%E7%BE%A4%E9%85%8D%E7%BD%AEhadoop%E9%9B%86%E7%BE%A4%E7%9A%84%E5%90%AF%E5%8A%A8%E5%92%8C%E6%B5%8B%E8%AF%95ssh%E5%85%8D%E7%99%BB%E9%99%86%E9%85%8D%E7%BD%AEstartallshhdfs%E5%B8%B8%E7%94%A8%E7%9A%84shell/" title="007Hadoop集群配置Hadoop集群的启动和测试SSH免登陆配置startallshhdfs常用的shell">007Hadoop集群配置Hadoop集群的启动和测试SSH免登陆配置startallshhdfs常用的shell</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/009shell%E8%84%9A%E6%9C%AC%E4%B8%8B%E6%9D%A1%E4%BB%B6%E6%B5%8B%E8%AF%95eqne/" title="009Shell脚本下条件测试eqne">009Shell脚本下条件测试eqne</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/00pythonmanagepyshell%E5%92%8Cpython%E7%9A%84%E5%88%86%E6%9E%90/" title="00Pythonmanagepyshell和Python的分析">00Pythonmanagepyshell和Python的分析</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/010zookeeper%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5zookeeper%E7%9A%84%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BAzookeeper%E7%9A%84shell%E5%91%BD%E4%BB%A4/" title="010Zookeeper的基本概念Zookeeper的集群搭建Zookeeper的shell命令">010Zookeeper的基本概念Zookeeper的集群搭建Zookeeper的shell命令</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/018dockerfileshell/" title="018DockerfileSHELL">018DockerfileSHELL</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/01shell%E5%85%A5%E9%97%A801bashshell%E7%89%B9%E6%80%A7/" title="01Shell入门01bashShell特性">01Shell入门01bashShell特性</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/01shell%E5%8F%98%E9%87%8F/" title="01Shell变量">01Shell变量</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/01shell%E5%9F%BA%E7%A1%80%E6%A6%82%E8%BF%B0%E8%84%9A%E6%9C%AC%E6%89%A7%E8%A1%8C%E6%96%B9%E5%BC%8Fbash%E5%9F%BA%E6%9C%AC%E5%8A%9F%E8%83%BD/" title="01Shell基础概述脚本执行方式Bash基本功能">01Shell基础概述脚本执行方式Bash基本功能</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/01shell%E7%BC%96%E7%A8%8Bhelloworld/" title="01shell编程helloworld">01shell编程helloworld</a>
    </li>
    
</ul>
    </section>

    

    <section class="widget">
        <h3 class="widget-title"><a href="/categories">分类</a></h3>
<ul class="widget-list">
    
</ul>
    </section>

    <section class="widget">
        <h3 class="widget-title"><a href="/tags">标签</a></h3>
<div class="tagcloud">
    
    <a href="https://zaina.newban.cn/tags/ruby/">ruby</a>
    
    <a href="https://zaina.newban.cn/tags/shell/">shell</a>
    
</div>
    </section>

    

    <section class="widget">
        <h3 class="widget-title">其它</h3>
        <ul class="widget-list">
            <li><a href="https://zaina.newban.cn/index.xml">文章 RSS</a></li>
        </ul>
    </section>
</div>
            </div>
        </div>
    </div>
</body>

</html>