<!doctype html>
<html lang="en-us">
<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">


    <title>shell | 开发者问答集锦</title>
    <meta property="og:title" content="shell - 开发者问答集锦">
    <meta property="og:type" content="article">
        
        
    <meta name="Keywords" content="">
    <meta name="description" content="shell">
        
    <meta name="author" content="">
    <meta property="og:url" content="https://zaina.newban.cn/tags/shell/">
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">

    <link rel="stylesheet" href='/css/normalize.css'>
    <link rel="stylesheet" href='/css/style.css'>
    <link rel="alternate" type="application/rss+xml+xml" href="https://zaina.newban.cn/tags/shell/index.xml" title="开发者问答集锦" />
    <script type="text/javascript" src="//cdn.bootcdn.net/ajax/libs/jquery/3.4.1/jquery.min.js"></script>

    
    
    
    
    
    
</head>


<body>
    <header id="header" class="clearfix">
    <div class="container">
        <div class="col-group">
            <div class="site-name ">
                
                    <a id="logo" href="https://zaina.newban.cn">
                        开发者问答集锦
                    </a>
                
                
            </div>
            <div>
                <nav id="nav-menu" class="clearfix">
                    <a class="" href="https://zaina.newban.cn">首页</a>
                    
                </nav>
            </div>
        </div>
    </div>
</header>

    <div id="body">
        <div class="container">
            <div class="col-group">

                <div class="col-8" id="main">
                    
<div class="res-cons">
    
    <h3 class="archive-title">
        包含标签
        <span class="keyword">shell</span>
        的文章
    </h3>
    

    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/sparkshell%E7%94%B1%E4%BA%8Escala%E7%BC%96%E8%AF%91%E5%99%A8%E5%8E%9F%E5%9B%A0%E4%B8%8D%E8%83%BD%E6%AD%A3%E5%B8%B8%E5%90%AF%E5%8A%A8/">SparkShell由于Scala编译器原因不能正常启动</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            ……
            <p class="readmore"><a href="https://zaina.newban.cn/posts/sparkshell%E7%94%B1%E4%BA%8Escala%E7%BC%96%E8%AF%91%E5%99%A8%E5%8E%9F%E5%9B%A0%E4%B8%8D%E8%83%BD%E6%AD%A3%E5%B8%B8%E5%90%AF%E5%8A%A8/">阅读全文</a></p>
        </div>
    </article>
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/sparkshell%E7%9A%84%E4%BD%BF%E7%94%A8/">SparkShell的使用</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            前言 前一章中我们介绍了Spark的Standalone模式的安装. 本章我们介绍下Spark Shell操作窗口的基本的安装.
 基本启动与使用 基本算子使用  基本启动与使用  本地启动
进入./bin目录, 使用spark-shell即可启动. 未链接集群, 直接启动了一个Worker结点. 可以通过 http://localhost:4040 进行访问.
localhost:bin Sean$ spark-shell Picked up JAVA_TOOL_OPTIONS: -Dfile.encoding=UTF-8 Picked up JAVA_TOOL_OPTIONS: -Dfile.encoding=UTF-8 Using Spark&rsquo;s default log4j profile: org/apache/spark/log4j-defaults.properties Setting default log level to &ldquo;WARN&rdquo;. To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel). 19/03/29 17:15:00 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform&hellip; using builtin-java classes where applicable 19/03/29 17:15:01 WARN Utils: Your hostname, localhost resolves to a loopback address: 127.……
            <p class="readmore"><a href="https://zaina.newban.cn/posts/sparkshell%E7%9A%84%E4%BD%BF%E7%94%A8/">阅读全文</a></p>
        </div>
    </article>
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/sparkshell%E7%9A%84%E8%AF%8D%E9%A2%91%E7%BB%9F%E8%AE%A1%E5%8E%BB%E9%87%8D%E6%8E%92%E5%BA%8F%E5%8F%8A%E5%90%88%E5%B9%B6%E5%9A%AF%E5%95%8A%E5%9A%AF/">sparkshell的词频统计去重排序及合并嚯啊嚯</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            Spark技术  RDD算子  本地文件上传至HDFS RDD保存文件至HDFS HDFS保存文件到本地 spark-shell基础操作 wordcount统计 去重distinct 排序sortByKey 合并join 求平均值   RDD算子 RDD有两种类型的操作 ，分别是Transformation（返回一个新的RDD）和Action（返回values）。
1.Transformation：根据已有RDD创建新的RDD数据集build
（1）map(func)：对调用map的RDD数据集中的每个element都使用func，然后返回一个新的RDD，这个返回的数据集是分布式的数据集。
（2）filter(func) ：对调用filter的RDD数据集中的每个元素都使用func，然后返回一个包含使func为true的元素构成的RDD。
（3）flatMap(func)：和map很像，但是flatMap生成的是多个结果。
（4）mapPartitions(func)：和map很像，但是map是每个element，而mapPartitions是每个partition。
（5）mapPartitionsWithSplit(func)：和mapPartitions很像，但是func作用的是其中一个split上，所以func中应该有index。
（6）sample(withReplacement,faction,seed)：抽样。
（7）union(otherDataset)：返回一个新的dataset，包含源dataset和给定dataset的元素的集合。
（8）distinct([numTasks])：返回一个新的dataset，这个dataset含有的是源dataset中的distinct的element。
（9）groupByKey(numTasks)：返回(K,Seq[V])，也就是Hadoop中reduce函数接受的key-valuelist。
（10）reduceByKey(func,[numTasks])：就是用一个给定的reduce func再作用在groupByKey产生的(K,Seq[V])，比如求和，求平均数。
（11）sortByKey([ascending],[numTasks])：按照key来进行排序，是升序还是降序，ascending是boolean类型。
2.Action：在RDD数据集运行计算后，返回一个值或者将结果写入外部存储
（1）reduce(func)：就是聚集，但是传入的函数是两个参数输入返回一个值，这个函数必须是满足交换律和结合律的。
（2）collect()：一般在filter或者足够小的结果的时候，再用collect封装返回一个数组。
（3）count()：返回的是dataset中的element的个数。
（4）first()：返回的是dataset中的第一个元素。
（5）take(n)：返回前n个elements。
（6）takeSample(withReplacement，num，seed)：抽样返回一个dataset中的num个元素，随机种子seed。
（7）saveAsTextFile（path）：把dataset写到一个textfile中，或者HDFS，或者HDFS支持的文件系统中，Spark把每条记录都转换为一行记录，然后写到file中。
（8）saveAsSequenceFile(path)：只能用在key-value对上，然后生成SequenceFile写到本地或者Hadoop文件系统。
（9）countByKey()：返回的是key对应的个数的一个map，作用于一个RDD。
（10）foreach(func)：对dataset中的每个元素都使用func。
本地文件上传至HDFS 在启动spark-shell之前，需将数据文件上传至hdfs上
hadoop fs -mkdir -p /dir hadoop fs -put /data/file /dir  RDD保存文件至HDFS 在spark-shell上操作
rdd.repartition(1).saveAsTextFile(&quot;hdfs://localhost:9000/dir/out.txt&quot;)  HDFS保存文件到本地 mkdir -p /data hadoop fs -get /dir/out.txt/part-00000 /data/ans20_ans1.txt  spark-shell基础操作 使用Spark shell对数据进行WordCount统计、去重、排序、求平均值以及Join操作。……
            <p class="readmore"><a href="https://zaina.newban.cn/posts/sparkshell%E7%9A%84%E8%AF%8D%E9%A2%91%E7%BB%9F%E8%AE%A1%E5%8E%BB%E9%87%8D%E6%8E%92%E5%BA%8F%E5%8F%8A%E5%90%88%E5%B9%B6%E5%9A%AF%E5%95%8A%E5%9A%AF/">阅读全文</a></p>
        </div>
    </article>
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/sparkshell%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8/">SparkShell简单使用</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            基础
Spark的shell作为一个强大的交互式数据分析工具，提供了一个简单的方式学习API。它可以使用Scala(在Java虚拟机上运行现有的Java库的一个很好方式)或Python。在Spark目录里使用下面的方式开始运行：
./bin/spark-shell  在Spark Shell中，有一个专有的SparkContext已经为您创建好了，变量名叫做sc。自己创建的SparkContext将无法工作。可以用&ndash; master参数来设置SparkContext要连接的集群，用&ndash; jars来设置需要添加到CLASSPATH的jar包，如果有多个jar包，可以使用逗号分隔符连接它们。例如，在一个拥有4核的环境上运行spark- shell，使用：
./bin/spark-shell --master local[4]  或在CLASSPATH中添加code.jar，使用：
./bin/spark-shell --master local[4] --jars code.jar  可以执行spark-shell &ndash;help获取完整的选项列表。
Spark最主要的抽象是叫Resilient Distributed Dataset(RDD)的弹性分布式集合。RDDs可以使用Hadoop InputFormats(例如HDFS文件)创建，也可以从其他的RDDs转换。让我们在Spark源代码目录里从README.md文本文件中创建一个新的RDD。
scala&gt; val textFile = sc.textFile(&quot;file:///home/hadoop/hadoop/spark/README.md&quot;) 16/07/24 03:30:53 INFO storage.MemoryStore: ensureFreeSpace(217040) called with curMem=321016, maxMem=280248975 16/07/24 03:30:53 INFO storage.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 212.0 KB, free 266.8 MB) 16/07/24 03:30:53 INFO storage.MemoryStore: ensureFreeSpace(20024) called with curMem=538056, maxMem=280248975 16/07/24 03:30:53 INFO storage.……
            <p class="readmore"><a href="https://zaina.newban.cn/posts/sparkshell%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8/">阅读全文</a></p>
        </div>
    </article>
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/sparkshell%E8%84%9A%E6%9C%AC%E6%89%B9%E9%87%8F%E6%89%A7%E8%A1%8C%E5%91%BD%E4%BB%A4%E5%91%BD%E4%BB%A4%E8%A1%8C%E6%89%B9%E9%87%8F%E6%89%A7%E8%A1%8C%E5%91%BD%E4%BB%A4/">Sparkshell脚本批量执行命令命令行批量执行命令</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            spark-shell 执行脚本，批量执行命令
#!/bin/bash source /etc/profile exec spark-shell --name spark-sql-test --executor-cores 8 --executor-memory 8g --num-executors 1 --conf spark.cleaner.ttl=240000 &lt;  ……
            <p class="readmore"><a href="https://zaina.newban.cn/posts/sparkshell%E8%84%9A%E6%9C%AC%E6%89%B9%E9%87%8F%E6%89%A7%E8%A1%8C%E5%91%BD%E4%BB%A4%E5%91%BD%E4%BB%A4%E8%A1%8C%E6%89%B9%E9%87%8F%E6%89%A7%E8%A1%8C%E5%91%BD%E4%BB%A4/">阅读全文</a></p>
        </div>
    </article>
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/sparkshell%E8%AF%BB%E5%8F%96hadoophdfs%E4%B8%8A%E6%96%87%E6%9C%AC%E6%96%87%E4%BB%B6%E7%BB%9F%E8%AE%A1wordcount%E7%9A%84%E6%96%B9%E6%B3%95/">sparkshell读取hadoophdfs上文本文件统计wordcount的方法</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            spark shell读取hadoop hdfs上文本文件统计wordcount的方法
hellospark文件内容如下所示：
[hadoop3@master app]$ hdfs dfs -cat /spark/hellospark hello spark hello world hello spark!  统计结果为：
scala&gt; count.collect(); res0: Array[(String, Int)] = Array((spark!,1), (spark,1), (hello,3), (world,1))  启动spark-shell控制台
[hadoop3@master app]$ spark-shell 2018-08-17 14:37:57 WARN NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable Setting default log level to &quot;WARN&quot;. To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel). Spark context Web UI available at http://master:4040 Spark context available as 'sc' (master = local[*], app id = local-1534487889053).……
            <p class="readmore"><a href="https://zaina.newban.cn/posts/sparkshell%E8%AF%BB%E5%8F%96hadoophdfs%E4%B8%8A%E6%96%87%E6%9C%AC%E6%96%87%E4%BB%B6%E7%BB%9F%E8%AE%A1wordcount%E7%9A%84%E6%96%B9%E6%B3%95/">阅读全文</a></p>
        </div>
    </article>
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/sparkshell%E8%AF%BB%E5%8F%96hbase%E6%95%B0%E6%8D%AE/">SparkShell读取HBase数据</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            ……
            <p class="readmore"><a href="https://zaina.newban.cn/posts/sparkshell%E8%AF%BB%E5%8F%96hbase%E6%95%B0%E6%8D%AE/">阅读全文</a></p>
        </div>
    </article>
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/sparkshell%E8%BF%90%E8%A1%8Cspark%E4%BB%BB%E5%8A%A1%E5%8F%82%E6%95%B0%E8%AE%BE%E7%BD%AE/">sparkshell运行spark任务参数设置</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            之前初学spark用spark-shell执行小程序的时候, 每次执行action操作(比如count,collect或者println),都会报错:
 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
 同时如果去spark ui上(公司默认为ip:18080)会看到spark-shell为核数core为0:

原因是启动spark-shell的时候没有给他分配资源, 所以我们应该在启动spark-shell的时候这么写:
/home/mr/spark/bin/spark-shell --executor-memory 4G \ --total-executor-cores 10 \ --executor-cores 1  其中 :
--executor-memory 是指定每个executor(执行器)占用的内存
--total-executor-cores是所有executor总共使用的cpu核数
--executor-cores是每个executor使用的cpu核数
对于spark-shell还可以在yarn上执行:
--master yarn-client
这里必须是client,不同于spark-submit的yarn-cluster, 因为spark- shell作为一个与用户交互的命令行，必须将Driver运行在本地，而不是yarn上, 其他的参数与submit一样.
以上参数就限制了总cpu核数为10, executor数目为10
但是, 每次执行都要写这么多参数显然很麻烦, 我们也可以通过修改spark-shell的方法将以上参数改成默认, 方法如下:
spark-shell之前代码:
... ... function main() { ... else export SPARK_SUBMIT_OPTS &quot;$FWDIR&quot;/bin/spark-submit --class org.……
            <p class="readmore"><a href="https://zaina.newban.cn/posts/sparkshell%E8%BF%90%E8%A1%8Cspark%E4%BB%BB%E5%8A%A1%E5%8F%82%E6%95%B0%E8%AE%BE%E7%BD%AE/">阅读全文</a></p>
        </div>
    </article>
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/sparkshell%E8%BF%90%E8%A1%8C%E4%BB%BB%E5%8A%A1/">SparkShell运行任务</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            文章目录 * 1.Spark-Shell 交互式编程 * 1.1 启动命令 * 1.2 Spark-Shell中运行wordcount * 2\. spark-submit提交Job  开始本篇博客之前，请先准备好环境，参见 【上一篇 Spark集群部署】
1.Spark-Shell 交互式编程 1.1 启动命令 bin/spark-shell \ --master spark://l0:7077 \ --executor-memory 1g \ --total-executor-cores 2     参数 解释     –master 集群的master URL (如 spark://192.168.191.130:7077)   –executor-memory 1G 指定每个executor可用内存为1G   –total-executor-cores 2 指定每个executor使用的cup核数为2个   –jars 添加任务所需的其他依赖     如果启动spark shell时没有指定master地址，但是也可以正常启动spark shell和执行spark shell中的程序，其实是启动了spark的local模式，该模式仅在本机启动一个进程，没有与集群建立联系。
 Spark Shell中已经默认将SparkContext类初始化为对象 sc 。用户代码如果需要用到，则直接应用sc即可。……
            <p class="readmore"><a href="https://zaina.newban.cn/posts/sparkshell%E8%BF%90%E8%A1%8C%E4%BB%BB%E5%8A%A1/">阅读全文</a></p>
        </div>
    </article>
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/sparkshell%E8%BF%9E%E6%8E%A5%E5%BC%82%E5%B8%B8%E9%97%AE%E9%A2%98/">sparkshell连接异常问题</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            [root@node00 sbin]# /apps/spark-2.2.0-bin-hadoop2.7/bin/spark-shell --master spark://node00:7077 Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties Setting default log level to &quot;WARN&quot;. To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel). 18/11/05 11:48:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable 18/11/05 11:49:04 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0 18/11/05 11:49:04 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException java.……
            <p class="readmore"><a href="https://zaina.newban.cn/posts/sparkshell%E8%BF%9E%E6%8E%A5%E5%BC%82%E5%B8%B8%E9%97%AE%E9%A2%98/">阅读全文</a></p>
        </div>
    </article>
    

    



<ol class="page-navigator">
    
    <li class="prev">
        <a href="https://zaina.newban.cn/tags/shell/page/1248/">上一页</a>
    </li>
    

    

    
        
        
    
    

    
        
        
        <li >
            <a href="https://zaina.newban.cn/tags/shell/">1</a>
        </li>
        
    
        
        <li>
            <span>...</span>
        </li>
        
    
        
        
        <li >
            <a href="https://zaina.newban.cn/tags/shell/page/1247/">1247</a>
        </li>
        
    
        
        
        <li >
            <a href="https://zaina.newban.cn/tags/shell/page/1248/">1248</a>
        </li>
        
    
        
        
        <li  class="current">
            <a href="https://zaina.newban.cn/tags/shell/page/1249/">1249</a>
        </li>
        
    
        
        
        <li >
            <a href="https://zaina.newban.cn/tags/shell/page/1250/">1250</a>
        </li>
        
    
        
        
        <li >
            <a href="https://zaina.newban.cn/tags/shell/page/1251/">1251</a>
        </li>
        
    
        
        <li>
            <span>...</span>
        </li>
        
    
        
        
        <li >
            <a href="https://zaina.newban.cn/tags/shell/page/1621/">1621</a>
        </li>
        
    

    
    

    <li class="next">
        <a href="https://zaina.newban.cn/tags/shell/page/1250/">下一页</a>
    </li>
    
</ol>




</div>

                    <footer id="footer">
    <div>
        &copy; 2020 <a href="https://zaina.newban.cn">开发者问答集锦 By </a>
        
    </div>
    <br />
    <div>
        <div class="github-badge">
            <a href="https://gohugo.io/" target="_black" rel="nofollow"><span class="badge-subject">Powered by</span><span class="badge-value bg-blue">Hugo</span></a>
        </div>
        <div class="github-badge">
            <a href="https://www.flysnow.org/" target="_black"><span class="badge-subject">Design by</span><span class="badge-value bg-brightgreen">飞雪无情</span></a>
        </div>
        <div class="github-badge">
            <a href="https://github.com/flysnow-org/maupassant-hugo" target="_black"><span class="badge-subject">Theme</span><span class="badge-value bg-yellowgreen">Maupassant</span></a>
        </div>
    </div>
</footer>



<a id="rocket" href="#top"></a>
<script type="text/javascript" src='/js/totop.js?v=0.0.0' async=""></script>



    <script type="text/javascript" src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script>




                </div>

                <div id="secondary">
    <section class="widget">
        <form id="search" action='https://zaina.newban.cn/search/' method="get" accept-charset="utf-8" target="_blank" _lpchecked="1">
      
      <input type="text" name="q" maxlength="20" placeholder="Search">
      <input type="hidden" name="sitesearch" value="https://zaina.newban.cn">
      <button type="submit" class="submit icon-search"></button>
</form>
    </section>
    
    <section class="widget">
        <h3 class="widget-title">最近文章</h3>
<ul class="widget-list">
    
    <li>
        <a href="https://zaina.newban.cn/posts/001rubyruby%E4%B8%AD%E5%85%A8%E5%B1%80%E5%8F%98%E9%87%8F%E5%AE%9E%E4%BE%8B%E5%8F%98%E9%87%8F%E5%B1%80%E9%83%A8%E5%8F%98%E9%87%8F%E7%B1%BB%E5%8F%98%E9%87%8Fsymbol%E5%AF%B9%E6%AF%94/" title="001rubyRuby中全局变量实例变量局部变量类变量Symbol对比">001rubyRuby中全局变量实例变量局部变量类变量Symbol对比</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/007hadoop%E9%9B%86%E7%BE%A4%E9%85%8D%E7%BD%AEhadoop%E9%9B%86%E7%BE%A4%E7%9A%84%E5%90%AF%E5%8A%A8%E5%92%8C%E6%B5%8B%E8%AF%95ssh%E5%85%8D%E7%99%BB%E9%99%86%E9%85%8D%E7%BD%AEstartallshhdfs%E5%B8%B8%E7%94%A8%E7%9A%84shell/" title="007Hadoop集群配置Hadoop集群的启动和测试SSH免登陆配置startallshhdfs常用的shell">007Hadoop集群配置Hadoop集群的启动和测试SSH免登陆配置startallshhdfs常用的shell</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/009shell%E8%84%9A%E6%9C%AC%E4%B8%8B%E6%9D%A1%E4%BB%B6%E6%B5%8B%E8%AF%95eqne/" title="009Shell脚本下条件测试eqne">009Shell脚本下条件测试eqne</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/00pythonmanagepyshell%E5%92%8Cpython%E7%9A%84%E5%88%86%E6%9E%90/" title="00Pythonmanagepyshell和Python的分析">00Pythonmanagepyshell和Python的分析</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/010zookeeper%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5zookeeper%E7%9A%84%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BAzookeeper%E7%9A%84shell%E5%91%BD%E4%BB%A4/" title="010Zookeeper的基本概念Zookeeper的集群搭建Zookeeper的shell命令">010Zookeeper的基本概念Zookeeper的集群搭建Zookeeper的shell命令</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/018dockerfileshell/" title="018DockerfileSHELL">018DockerfileSHELL</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/01shell%E5%85%A5%E9%97%A801bashshell%E7%89%B9%E6%80%A7/" title="01Shell入门01bashShell特性">01Shell入门01bashShell特性</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/01shell%E5%8F%98%E9%87%8F/" title="01Shell变量">01Shell变量</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/01shell%E5%9F%BA%E7%A1%80%E6%A6%82%E8%BF%B0%E8%84%9A%E6%9C%AC%E6%89%A7%E8%A1%8C%E6%96%B9%E5%BC%8Fbash%E5%9F%BA%E6%9C%AC%E5%8A%9F%E8%83%BD/" title="01Shell基础概述脚本执行方式Bash基本功能">01Shell基础概述脚本执行方式Bash基本功能</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/01shell%E7%BC%96%E7%A8%8Bhelloworld/" title="01shell编程helloworld">01shell编程helloworld</a>
    </li>
    
</ul>
    </section>

    

    <section class="widget">
        <h3 class="widget-title"><a href="/categories">分类</a></h3>
<ul class="widget-list">
    
</ul>
    </section>

    <section class="widget">
        <h3 class="widget-title"><a href="/tags">标签</a></h3>
<div class="tagcloud">
    
    <a href="https://zaina.newban.cn/tags/ruby/">ruby</a>
    
    <a href="https://zaina.newban.cn/tags/shell/">shell</a>
    
</div>
    </section>

    

    <section class="widget">
        <h3 class="widget-title">其它</h3>
        <ul class="widget-list">
            <li><a href="https://zaina.newban.cn/index.xml">文章 RSS</a></li>
        </ul>
    </section>
</div>
            </div>
        </div>
    </div>
</body>

</html>