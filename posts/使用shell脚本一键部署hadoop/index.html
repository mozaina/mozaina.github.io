<!doctype html>
<html lang="en-us">
<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">


    <title>使用Shell脚本一键部署Hadoop | 开发者问答集锦</title>
    <meta property="og:title" content="使用Shell脚本一键部署Hadoop - 开发者问答集锦">
    <meta property="og:type" content="article">
        
    <meta property="article:published_time" content='2020-09-02T00:00:00&#43;08:00'>
        
        
    <meta property="article:modified_time" content='2020-09-02T00:00:00&#43;08:00'>
        
    <meta name="Keywords" content="">
    <meta name="description" content="使用Shell脚本一键部署Hadoop">
        
    <meta name="author" content="">
    <meta property="og:url" content="https://zaina.newban.cn/posts/%E4%BD%BF%E7%94%A8shell%E8%84%9A%E6%9C%AC%E4%B8%80%E9%94%AE%E9%83%A8%E7%BD%B2hadoop/">
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">

    <link rel="stylesheet" href='/css/normalize.css'>
    <link rel="stylesheet" href='/css/style.css'>
    <script type="text/javascript" src="//cdn.bootcdn.net/ajax/libs/jquery/3.4.1/jquery.min.js"></script>

    
    
    
    
    
    
</head>


<body>
    <header id="header" class="clearfix">
    <div class="container">
        <div class="col-group">
            <div class="site-name ">
                
                    <a id="logo" href="https://zaina.newban.cn">
                        开发者问答集锦
                    </a>
                
                
            </div>
            <div>
                <nav id="nav-menu" class="clearfix">
                    <a class="" href="https://zaina.newban.cn">首页</a>
                    
                </nav>
            </div>
        </div>
    </div>
</header>

    <div id="body">
        <div class="container">
            <div class="col-group">

                <div class="col-8" id="main">
                    
<div class="res-cons">
    
    <article class="post">
        <header>
            <h1 class="post-title">使用Shell脚本一键部署Hadoop</h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        
        <div class="post-meta">
            <span id="busuanzi_container_page_pv">|<span id="busuanzi_value_page_pv"></span><span>
                    阅读</span></span>
        </div>
        
        
        <div class="post-content">
            

<h1 id="测试环境">测试环境</h1>

<p>Linux系统版本：CentOS 7</p>

<hr />

<h1 id="实现功能">实现功能</h1>

<p>1、Java环境一键配置<br />
2、Hadoop单机版一键安装<br />
3、Hadoop伪分布式一键安装<br />
4、Hadoop集群部署<br />
5、伪分布式hadoop初始化<br />
6、集群设置SSH免密登录（使用hadoop用户操作）</p>

<hr />

<h1 id="脚本说明">脚本说明</h1>

<p>部署Hadoop环境过程比较繁琐，还容易出错，写了一个Shell脚本用来一键部署，废话不多说，下面直接上代码。</p>

<p><strong>集群部署的方法暂时还没进行全面测试，后面测试后会持续更新</strong></p>

<p>若在使用过程中遇到什么问题或者是有好的改进方案欢迎在评论区指出</p>

<hr />

<h1 id="脚本代码">脚本代码</h1>

<pre><code>#!/bin/bash

JDKLINK='http://download.oracle.com/otn-pub/java/jdk/8u191-b12/2787e4a523244c269598db4e85c51e0c/jdk-8u191-linux-x64.rpm'
HADOOPLINK='https://archive.apache.org/dist/hadoop/common/hadoop-2.7.3/hadoop-2.7.3.tar.gz'
localIP=$(ip a | grep ens33 | awk '$1~/^inet.*/{print $2}' | awk -F '/' '{print $1}')
ip_arrays=()

#初始化环境
installWget(){
    echo '初始化安装环境....'
    wget
    if [ $? -ne 1 ]; then
        echo '开始下载wget'
        yum -y install wget
    fi
}

#wget下载JDK进行安装
installJDK(){
    ls /usr/local | grep 'jdk.*[rpm]$'
    if [ $? -ne 0 ]; then
        echo '开始下载JDK.......'
        wget --no-check-certificate --no-cookies --header &quot;Cookie: oraclelicense=accept-securebackup-cookie&quot; $JDKLINK
        mv $(ls | grep 'jdk.*[rpm]$') /usr/local
    fi
    chmod 751 /usr/local/$(ls /usr/local | grep 'jdk.*[rpm]$')
    rpm -ivh /usr/local/$(ls /usr/local | grep 'jdk.*[rpm]$')
}

#JDK环境变量配置
pathJDK(){
    #PATH设置
    grep -q &quot;export PATH=&quot; /etc/profile
    if [ $? -ne 0 ]; then
        #末行插入
        echo 'export PATH=$PATH:$JAVA_HOME/bin'&gt;&gt;/etc/profile
    else
        #行尾添加
        sed -i '/^export PATH=.*/s/$/:\$JAVA_HOME\/bin/' /etc/profile
    fi

    grep -q &quot;export JAVA_HOME=&quot; /etc/profile
    if [ $? -ne 0 ]; then
        #导入配置
        filename=&quot;$(ls /usr/java | grep '^jdk.*[^rpm | gz]$' | sed -n '1p')&quot;
        sed -i &quot;/^export PATH=.*/i\export JAVA_HOME=\/usr\/java\/$filename&quot; /etc/profile
        sed -i '/^export PATH=.*/i\export JRE_HOME=$JAVA_HOME/jre' /etc/profile
        sed -i '/^export PATH=.*/i\export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar' /etc/profile
        #echo &quot;export JAVA_HOME=/usr/java/$filename&quot;&gt;&gt;/etc/profile
        #echo 'export JRE_HOME=$JAVA_HOME/jre'&gt;&gt;/etc/profile
        #echo 'export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar'&gt;&gt;/etc/profile
    else
        #替换原有配置
        filename=&quot;$(ls /usr/java | grep '^jdk.*[^rpm | gz]$' | sed -n '1p')&quot;
        sed -i &quot;s/^export JAVA_HOME=.*/export JAVA_HOME=\/usr\/java\/$filename/&quot; /etc/profile
    fi
    source /etc/profile
}

#wget下载Hadoop进行解压(单机版)
wgetHadoop(){
    ls /usr/local | grep 'hadoop.*[gz]$'
    if [ $? -ne 0 ]; then
        echo '开始下载hadoop安装包...'
        wget $HADOOPLINK
        mv $(ls | grep 'hadoop.*gz$') /usr/local
    fi
    tar -zxvf /usr/local/$(ls | grep 'hadoop.*[gz]$')
    mv /usr/local/$(ls | grep 'hadoop.*[^gz]$') /usr/local/hadoop
}

#hadoop环境变量配置
pathHadoop(){
    #PATH设置
    grep -q &quot;export PATH=&quot; /etc/profile
    if [ $? -ne 0 ]; then
        #末行插入
        echo 'export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin'&gt;&gt;/etc/profile
    else
        #行尾添加
        sed -i '/^export PATH=.*/s/$/:\$HADOOP_HOME\/bin:\$HADOOP_HOME\/sbin/' /etc/profile
    fi
    #HADOOP_HOME设置
    grep -q &quot;export HADOOP_HOME=&quot; /etc/profile
    if [ $? -ne 0 ]; then
        #在PATH前面一行插入HADOOP_HOME
        sed -i '/^export PATH=.*/i\export HADOOP_HOME=\/usr\/local\/hadoop' /etc/profile
    else
        #修改文件内的HADOOP_HOME
        sed -i 's/^export HADOOP_HOME=.*/export HADOOP_HOME=\/usr\/local\/hadoop/' /etc/profile
    fi
    source /etc/profile
}

#添加hadoop用户并设置权限
hadoopUserAdd(){
    echo '正在创建hadoop用户....'
    useradd hadoop
    echo '请设置hadoop用户密码....'
    passwd hadoop
    gpasswd -a hadoop root
    chmod 771 /usr
    chmod 771 /usr/local
    chown -R hadoop:hadoop /usr/local/hadoop
}

#单机版hadoop配置
installHadoop(){
    installWget
    wgetHadoop
    pathHadoop
    hadoopUserAdd
}

#伪分布式设置
setHadoop(){
echo '








        hadoop.tmp.dir
        file:/usr/local/hadoop/tmp
        指定hadoop运行时产生文件的存储路径


        fs.defaultFS
        hdfs://localhost:9000
        hdfs namenode的通信地址,通信端口


'&gt;$HADOOP_HOME/etc/hadoop/core-site.xml


echo '









        dfs.replication
        1
        指定HDFS存储数据的副本数目，默认情况下是3份


        dfs.namenode.name.dir
        file:/usr/local/hadoop/hadoopdata/namenode
        namenode存放数据的目录


        dfs.datanode.data.dir
        file:/usr/local/hadoop/hadoopdata/datanode
        datanode存放block块的目录


        dfs.permissions.enabled
        false
        关闭权限验证


'&gt;$HADOOP_HOME/etc/hadoop/hdfs-site.xml

echo '









        mapreduce.framework.name
        yarn
        指定mapreduce运行在yarn上


'&gt;$HADOOP_HOME/etc/hadoop/mapred-site.xml

echo '






        yarn.nodemanager.aux-services
        mapreduce_shuffle
        mapreduce执行shuffle时获取数据的方式


'&gt;$HADOOP_HOME/etc/hadoop/yarn-site.xml

    echo 'localhost'&gt;$HADOOP_HOME/etc/hadoop/slaves
    sed -i 's/export JAVA_HOME=.*/\#&amp;/' $HADOOP_HOME/etc/hadoop/hadoop-env.sh
    sed -i &quot;/#export JAVA_HOME=.*/a export JAVA_HOME=$JAVA_HOME&quot; $HADOOP_HOME/etc/hadoop/hadoop-env.sh
    chown -R hadoop:hadoop $HADOOP_HOME
}

#完全分布式设置
setHadoop2(){
echo '








        hadoop.tmp.dir
        file:/usr/local/hadoop/tmp
        指定hadoop运行时产生文件的存储路径


        fs.defaultFS
        hdfs://'$1':9000
        hdfs namenode的通信地址,通信端口


'&gt;$HADOOP_HOME/etc/hadoop/core-site.xml

echo '









        dfs.replication
        3
        指定HDFS存储数据的副本数目，默认情况下是3份


        dfs.namenode.name.dir
        file:/usr/local/hadoop/hadoopdata/namenode
        namenode存放数据的目录


        dfs.datanode.data.dir
        file:/usr/local/hadoop/hadoopdata/datanode
        datanode存放block块的目录


        dfs.secondary.http.address
        '$2':50090
        secondarynamenode 运行节点的信息，和 namenode 不同节点


        dfs.permissions.enabled
        false
        关闭权限验证


'&gt;$HADOOP_HOME/etc/hadoop/hdfs-site.xml

echo '









        mapreduce.framework.name
        yarn
        指定mapreduce运行在yarn上


'&gt;$HADOOP_HOME/etc/hadoop/mapred-site.xml

echo '





        yarn.resourcemanager.hostname
        '$1'
        yarn总管理器的IPC通讯地址


        yarn.nodemanager.aux-services
        mapreduce_shuffle
        mapreduce执行shuffle时获取数据的方式


'&gt;$HADOOP_HOME/etc/hadoop/yarn-site.xml
    rm -rf $HADOOP_HOME/etc/hadoop/slaves
    touch $HADOOP_HOME/etc/hadoop/slaves
    int=0
    while(( ${int}&lt;${#ip_arrays[*]} ))
    do
        #echo &quot;while is run&quot;
        echo &quot;${ip_arrays[$int]}&quot;&gt;&gt;$HADOOP_HOME/etc/hadoop/slaves
        if [ $? -ne 0 ]
        then
            echo '写入slaves配置失败'
            break
        fi
        let &quot;int++&quot;
    done
    sed -i 's/export JAVA_HOME=.*/\#&amp;/' $HADOOP_HOME/etc/hadoop/hadoop-env.sh
    sed -i &quot;/#export JAVA_HOME=.*/a export JAVA_HOME=$JAVA_HOME&quot; $HADOOP_HOME/etc/hadoop/hadoop-env.sh
    chown -R hadoop:hadoop $HADOOP_HOME
}

#关闭防火墙
stopFirewalld(){
    systemctl stop firewalld
    systemctl disable firewalld
}

#IP校验,返回值0校验合法，1不合法。
checkIPAddr(){
    echo $1|grep &quot;^[0-9]\{1,3\}\.\([0-9]\{1,3\}\.\)\{2\}[0-9]\{1,3\}$&quot; &gt; /dev/null; 
    #IP地址必须为全数字 
    if [ $? -ne 0 ] 
    then 
        return 1 
    fi 
    ipaddr=$1 
    a=`echo $ipaddr|awk -F . '{print $1}'`  #以&quot;.&quot;分隔，取出每个列的值 
    b=`echo $ipaddr|awk -F . '{print $2}'` 
    c=`echo $ipaddr|awk -F . '{print $3}'` 
    d=`echo $ipaddr|awk -F . '{print $4}'` 
    for num in $a $b $c $d 
    do 
        if [ $num -gt 255 ] || [ $num -lt 0 ]    #每个数值必须在0-255之间 
        then 
            return 1 
        fi 
    done 
        return 0 
}

#控制台输入集群IP
ipInput(){
    echo &quot;本机IP地址为：$localIP&quot;
    int=0
    echo '输入完成后，输入ip值为0可退出'
    while read -p &quot;输入第`expr ${int} + 1`台的IP:&quot; ip
    do      
        if [ &quot;$ip&quot; == &quot;0&quot; ]
        then
            break
        fi
        checkIPAddr $ip
        if [ $? -eq 0 ]
        then        
            ip_arrays[$int]=$ip
            #echo $int
        else
            echo '输入的IP不合法,重新进行配置....'
            ipInput
        fi
        let &quot;int++&quot;
    done

}

#scp设置免密登录
scpOutput(){
    int=0
    while(( ${int}&lt;${#ip_arrays[*]} ))
    do
        scp -r ~/.ssh ${ip_arrays[$int]}:~/
    let &quot;int++&quot;
    done
}

#SSH免密登录
setSSH(){
    echo '---------------配置ssh免密登录----------------------'
    echo '------------一路回车即可生成秘钥--------------------'
    ssh-keygen -t rsa
    echo '----------秘钥生成完成，开始生成公钥----------------'
    echo '根据提示输入相应的信息'
    echo '----------------------------------------------------'
    echo 'Are you sure you want to continue connecting (yes/no)?'
    echo '------------------输入&quot;yes&quot;-------------------------'
    echo 'hadoop@localhost s password:'
    echo '--------------输入hadoop用户密码--------------------'   
    ssh-copy-id localhost
}

#控制台选择本机角色
nameOrData(){
    echo '--------------------------'
    echo '1、namenode'
    echo '2、datanode'
    read -p '请选择本机的角色[1-2]:' n
    case $n in
        1)  return 0
        ;;
        2)  return 1
        ;;
        *)  echo '输入错误！！！'
            nameOrData
        ;;
    esac
}

#配置hosts文件
setHosts(){
    echo '开始配置/etc/hosts文件'
    echo '本机IP地址为：'$localIP''
    read -p '请输入本机主机名(hostname):' hostname
    echo -e ''$localIP'\t'$hostname''&gt;&gt;/etc/hosts
    echo '根据提示输入其他主机名(hostname)'
    echo '-----------------------------------'
    int=0
    while(( ${int}&lt;${#ip_arrays[*]} ))
    do
        echo 'IP：'${ip_arrays[$int]}''
        read -p &quot;请输入主机名：&quot; hostname
        echo -e ''${ip_arrays[$int]}'\t'$hostname''&gt;&gt;/etc/hosts
        echo '-----------------------------------'
        let &quot;int++&quot;
    done
}

#1、Java环境一键配置
javaInstall(){
    echo '开始检查本机环境'
    java -version
    if [ $? -ne 0 ]; then
        installWget         
        echo '开始配置JDK，请耐心等待......'
        installJDK
        pathJDK
        java -version
        if [ $? -eq 0 ]; then
            echo 'JDK配置完成'
        else
            echo '安装失败，请重新尝试或手动安装'
        fi
    else
        echo '已经配置该环境'
    fi
}
#2、Hadoop单机版一键安装
hadoopInstall(){
    javaInstall
    echo '开始检查本机环境'
    hadoop
    if [ $? -ne 0 ]; then
        installHadoop
        hadoop
        if [ $? -eq 0 ]; then
            echo 'hadoop单机版配置完成'
        else
            echo '安装失败，请重新尝试或手动安装'
        fi
    else
        echo '已经配置该环境'
    fi
}
#3、Hadoop伪分布式一键安装
hadoopInstall2(){
    javaInstall
    echo '开始检查本机环境'
    hadoop
    if [ $? -ne 0 ]; then
        installHadoop
        hadoop
        if [ $? -eq 0 ]; then
            echo 'hadoop单机版配置完成，开始配置伪分布式'
            setHadoop
            stopFirewalld
            echo '配置完成....使用hadoop用户初始化'
            su hadoop
        else
            echo '安装失败，请重新尝试或手动安装'
        fi
    else
        echo 'hadoop单机版已经安装，开始配置伪分布式'
        setHadoop
        stopFirewalld
        echo '配置完成....使用hadoop用户初始化'
        su hadoop
    fi
}
#4、Hadoop集群部署
hadoopInstall3(){
    nameOrData
    if [ $? -eq 0 ]
    then
        #记录IP
        echo '输入datanode的IP'
        ipInput
        #namenode配置
        #1安装单机版hadoop
        hadoopInstall
        #2导入集群配置文件
        echo '开始导入配置文件'
        setHadoop2 ${localIP} ${ip_arrays[0]}
        echo '配置导入完成'
        #3关闭防火墙
        stopFirewalld
        echo '防火墙已关闭'
        #上传主机配置到datanode
        int=0
        while(( ${int}&lt;${#ip_arrays[*]} ))
        do      
            echo &quot;开始给第`expr ${int} + 1`台datanode传送配置文件和安装包&quot;
            echo &quot;IP为：${ip_arrays[${int}]}&quot;
            echo &quot;传送过程需手动输入远程主机root密码&quot;
            #scp传送安装包
            scp $(pwd)/install.sh ${ip_arrays[$int]}:/usr/local
            scp /usr/local/$(ls | grep 'jdk.*[rpm]$') ${ip_arrays[$int]}:/usr/local
            scp -r /usr/local/hadoop ${ip_arrays[$int]}:/usr/local
            echo &quot;${ip_arrays[$int]}文件上传完成.....&quot;
            let &quot;int++&quot;
        done
        setHosts
        echo '请登录datanode主机执行该脚本继续完成datanode配置，脚本存储目录/usr/local'
    elif [ $? -eq 1 ]
    then
        #安装Java
        javaInstall
        #配置Hadoop环境变量
        echo '配置环境变量'
        pathHadoop
        echo '环境变量配置完成'
        #添加用户
        hadoopUserAdd
        #关闭防火墙
        stopFirewalld
        echo '防火墙已关闭'
        source /etc/profile
        echo '测试安装情况.....'
        java -version
        if [ $? -ne 0 ]; then
            echo '请手动执行source /etc/profile'
            echo '执行java -version确认JDK安装情况'
        fi
        hadoop version
        if [ $? -ne 0 ]; then
            echo '请手动执行source /etc/profile'
            echo '执行hadoop version确认hadoop安装情况'
        fi
        echo 'datanode配置完成'
    else
        echo '发生错误！！！'
    fi
}
#6、集群设置SSH免密登录（使用hadoop用户操作）
setSSHS(){
    #本机设置免密
    echo '开始设置本机免密....'
    setSSH
    #输入其他电脑IP
    echo '开始设置其他主机....'
    echo '输入其他主机ip'
    ipInput
    #用scp将秘钥发到其他主机
    echo '开始发送秘钥到其他主机...'
    scpOutput
}
#控制台输入选项
consoleInput(){
    echo '请输入选项[1-4]'
    echo '1、Java环境一键配置'
    echo '2、Hadoop单机版一键安装'
    echo '3、Hadoop伪分布式一键安装'
    echo '4、Hadoop集群部署'
    echo '5、hadoop初始化（在namenode主机上执行）'
    echo '6、集群设置SSH免密登录（使用hadoop用户操作）'
    echo '请输入选项[1-6]'
    read aNum
    case $aNum in
        1)  javaInstall
        ;;
        2)  hadoopInstall
        ;;
        3)  hadoopInstall2
        ;;
        4)  hadoopInstall3
        ;;
        5)  echo 'Hadoop初始化'
            hdfs namenode -format
        ;;
        6)  setSSHS
        ;;
        *)  echo '没有该选项，请重新输入!!!退出请按Ctrl+c'
            consoleInput
        ;;
    esac
}
echo '------------------欢迎使用一键安装------------------'
echo '为保证安装过程顺利进行，请使用root用户执行该脚本'
echo '该脚本增加了本地安装包自动安装'
echo '如果需要脚本安装本地安装包，请将安装包放在/usr/local下'
echo 'hadoop安装包要求以hadoop开头的.tar.gz包'
echo 'JDK安装包要求以jdk开头的.rpm包'
echo '----------------------------------------------------'
consoleInput
</code></pre>

        </div>

        


        

<div class="post-archive">
    <h2>See Also</h2>
    <ul class="listing">
        
        <li><a href="/posts/007hadoop%E9%9B%86%E7%BE%A4%E9%85%8D%E7%BD%AEhadoop%E9%9B%86%E7%BE%A4%E7%9A%84%E5%90%AF%E5%8A%A8%E5%92%8C%E6%B5%8B%E8%AF%95ssh%E5%85%8D%E7%99%BB%E9%99%86%E9%85%8D%E7%BD%AEstartallshhdfs%E5%B8%B8%E7%94%A8%E7%9A%84shell/">007Hadoop集群配置Hadoop集群的启动和测试SSH免登陆配置startallshhdfs常用的shell</a></li>
        
        <li><a href="/posts/009shell%E8%84%9A%E6%9C%AC%E4%B8%8B%E6%9D%A1%E4%BB%B6%E6%B5%8B%E8%AF%95eqne/">009Shell脚本下条件测试eqne</a></li>
        
        <li><a href="/posts/00pythonmanagepyshell%E5%92%8Cpython%E7%9A%84%E5%88%86%E6%9E%90/">00Pythonmanagepyshell和Python的分析</a></li>
        
        <li><a href="/posts/010zookeeper%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5zookeeper%E7%9A%84%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BAzookeeper%E7%9A%84shell%E5%91%BD%E4%BB%A4/">010Zookeeper的基本概念Zookeeper的集群搭建Zookeeper的shell命令</a></li>
        
        <li><a href="/posts/018dockerfileshell/">018DockerfileSHELL</a></li>
        
    </ul>
</div>


        <div class="post-meta meta-tags">
            
            <ul class="clearfix">
                
                <li><a href='https://zaina.newban.cn/tags/shell'>shell</a></li>
                
            </ul>
            
        </div>
    </article>
    
    

    
    
</div>

                    <footer id="footer">
    <div>
        &copy; 2020 <a href="https://zaina.newban.cn">开发者问答集锦 By </a>
        
    </div>
    <br />
    <div>
        <div class="github-badge">
            <a href="https://gohugo.io/" target="_black" rel="nofollow"><span class="badge-subject">Powered by</span><span class="badge-value bg-blue">Hugo</span></a>
        </div>
        <div class="github-badge">
            <a href="https://www.flysnow.org/" target="_black"><span class="badge-subject">Design by</span><span class="badge-value bg-brightgreen">飞雪无情</span></a>
        </div>
        <div class="github-badge">
            <a href="https://github.com/flysnow-org/maupassant-hugo" target="_black"><span class="badge-subject">Theme</span><span class="badge-value bg-yellowgreen">Maupassant</span></a>
        </div>
    </div>
</footer>


    
    <script type="text/javascript">
        window.MathJax = {
            tex2jax: {
                inlineMath: [['$', '$']],
                processEscapes: true
                }
            };
    </script>
    <script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML' async></script>

<a id="rocket" href="#top"></a>
<script type="text/javascript" src='/js/totop.js?v=0.0.0' async=""></script>



    <script type="text/javascript" src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script>




                </div>

                <div id="secondary">
    <section class="widget">
        <form id="search" action='https://zaina.newban.cn/search/' method="get" accept-charset="utf-8" target="_blank" _lpchecked="1">
      
      <input type="text" name="q" maxlength="20" placeholder="Search">
      <input type="hidden" name="sitesearch" value="https://zaina.newban.cn">
      <button type="submit" class="submit icon-search"></button>
</form>
    </section>
    
    <section class="widget">
        <h3 class="widget-title">最近文章</h3>
<ul class="widget-list">
    
    <li>
        <a href="https://zaina.newban.cn/posts/001rubyruby%E4%B8%AD%E5%85%A8%E5%B1%80%E5%8F%98%E9%87%8F%E5%AE%9E%E4%BE%8B%E5%8F%98%E9%87%8F%E5%B1%80%E9%83%A8%E5%8F%98%E9%87%8F%E7%B1%BB%E5%8F%98%E9%87%8Fsymbol%E5%AF%B9%E6%AF%94/" title="001rubyRuby中全局变量实例变量局部变量类变量Symbol对比">001rubyRuby中全局变量实例变量局部变量类变量Symbol对比</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/007hadoop%E9%9B%86%E7%BE%A4%E9%85%8D%E7%BD%AEhadoop%E9%9B%86%E7%BE%A4%E7%9A%84%E5%90%AF%E5%8A%A8%E5%92%8C%E6%B5%8B%E8%AF%95ssh%E5%85%8D%E7%99%BB%E9%99%86%E9%85%8D%E7%BD%AEstartallshhdfs%E5%B8%B8%E7%94%A8%E7%9A%84shell/" title="007Hadoop集群配置Hadoop集群的启动和测试SSH免登陆配置startallshhdfs常用的shell">007Hadoop集群配置Hadoop集群的启动和测试SSH免登陆配置startallshhdfs常用的shell</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/009shell%E8%84%9A%E6%9C%AC%E4%B8%8B%E6%9D%A1%E4%BB%B6%E6%B5%8B%E8%AF%95eqne/" title="009Shell脚本下条件测试eqne">009Shell脚本下条件测试eqne</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/00pythonmanagepyshell%E5%92%8Cpython%E7%9A%84%E5%88%86%E6%9E%90/" title="00Pythonmanagepyshell和Python的分析">00Pythonmanagepyshell和Python的分析</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/010zookeeper%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5zookeeper%E7%9A%84%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BAzookeeper%E7%9A%84shell%E5%91%BD%E4%BB%A4/" title="010Zookeeper的基本概念Zookeeper的集群搭建Zookeeper的shell命令">010Zookeeper的基本概念Zookeeper的集群搭建Zookeeper的shell命令</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/018dockerfileshell/" title="018DockerfileSHELL">018DockerfileSHELL</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/01shell%E5%85%A5%E9%97%A801bashshell%E7%89%B9%E6%80%A7/" title="01Shell入门01bashShell特性">01Shell入门01bashShell特性</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/01shell%E5%8F%98%E9%87%8F/" title="01Shell变量">01Shell变量</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/01shell%E5%9F%BA%E7%A1%80%E6%A6%82%E8%BF%B0%E8%84%9A%E6%9C%AC%E6%89%A7%E8%A1%8C%E6%96%B9%E5%BC%8Fbash%E5%9F%BA%E6%9C%AC%E5%8A%9F%E8%83%BD/" title="01Shell基础概述脚本执行方式Bash基本功能">01Shell基础概述脚本执行方式Bash基本功能</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/01shell%E7%BC%96%E7%A8%8Bhelloworld/" title="01shell编程helloworld">01shell编程helloworld</a>
    </li>
    
</ul>
    </section>

    

    <section class="widget">
        <h3 class="widget-title"><a href="/categories">分类</a></h3>
<ul class="widget-list">
    
</ul>
    </section>

    <section class="widget">
        <h3 class="widget-title"><a href="/tags">标签</a></h3>
<div class="tagcloud">
    
    <a href="https://zaina.newban.cn/tags/ruby/">ruby</a>
    
    <a href="https://zaina.newban.cn/tags/shell/">shell</a>
    
</div>
    </section>

    

    <section class="widget">
        <h3 class="widget-title">其它</h3>
        <ul class="widget-list">
            <li><a href="https://zaina.newban.cn/index.xml">文章 RSS</a></li>
        </ul>
    </section>
</div>
            </div>
        </div>
    </div>
</body>

</html>