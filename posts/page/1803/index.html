<!doctype html>
<html lang="en-us">
<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">


    <title>Posts | 开发者问答集锦</title>
    <meta property="og:title" content="Posts - 开发者问答集锦">
    <meta property="og:type" content="article">
        
        
    <meta name="Keywords" content="">
    <meta name="description" content="Posts">
        
    <meta name="author" content="">
    <meta property="og:url" content="https://zaina.newban.cn/posts/">
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">

    <link rel="stylesheet" href='/css/normalize.css'>
    <link rel="stylesheet" href='/css/style.css'>
    <link rel="alternate" type="application/rss+xml+xml" href="https://zaina.newban.cn/posts/index.xml" title="开发者问答集锦" />
    <script type="text/javascript" src="//cdn.bootcdn.net/ajax/libs/jquery/3.4.1/jquery.min.js"></script>

    
    
    
    
    
    
</head>


<body>
    <header id="header" class="clearfix">
    <div class="container">
        <div class="col-group">
            <div class="site-name ">
                
                    <a id="logo" href="https://zaina.newban.cn">
                        开发者问答集锦
                    </a>
                
                
            </div>
            <div>
                <nav id="nav-menu" class="clearfix">
                    <a class="" href="https://zaina.newban.cn">首页</a>
                    
                </nav>
            </div>
        </div>
    </div>
</header>

    <div id="body">
        <div class="container">
            <div class="col-group">

                <div class="col-8" id="main">
                    
<div class="res-cons">
    
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/hadoop%E4%B9%8Bmapreduce%E8%B0%83%E5%BA%A6%E9%80%9A%E8%BF%87shell%E8%BF%9B%E8%A1%8C%E5%A4%9A%E6%97%A5%E6%9C%9F%E7%9A%84%E4%B8%B2%E8%A1%8C%E8%B7%91%E6%89%B9%E7%BB%9F%E8%AE%A1/" title="Hadoop之MapReduce调度通过shell进行多日期的串行跑批统计">Hadoop之MapReduce调度通过shell进行多日期的串行跑批统计</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            **1、统计对应链接访问量的Python脚本
** 由于业务上暂用不到reduce过程，所以只有一个mapper脚本。
**/Users/nisj/PycharmProjects/BiDataProc/hitsCalc3/filter_mapperOnly.py
**
#!/usr/bin/env python # encoding: utf-8 import sys # 输入为标准输入stdin for line in sys.stdin: if '/room/m-1015.htm' in line: print '%s' % (line)  **2、按天调度的shell脚本
** **/Users/nisj/PycharmProjects/BiDataProc/hitsCalc3/mpBatResultGet.sh
**
#!/usr/bin/env bash rm -rf result.txt for dataDate in 2017-08-21 2017-08-22 2017-08-23 2017-08-24 2017-08-25 2017-08-26 2017-08-27 2017-08-28; do echo $dataDate hadoop dfs -rm -r -skipTrash /nisj/mp_result; hadoop jar /opt/apps/hadoop-2.7.2/share/hadoop/tools/lib/hadoop-streaming-2.7.2.jar \ -mapper /home/hadoop/nisj/hitsCalc3/filter_mapperOnly.py -file /home/hadoop/nisj/hitsCalc3/filter_mapperOnly.py \ -input /tmp/oss_access/$dataDate/*_localhost_access_log.$dataDate.*.txt \ -output /nisj/mp_result #hadoop dfs -cat /nisj/mp_result/* hitsNum=`hadoop dfs -cat /nisj/mp_result/* |grep -v &quot;^$&quot;|wc -l` echo $dataDate '---&gt;' $hitsNum &gt;&gt; result.……
        </div>
        <p class="readmore"><a href="https://zaina.newban.cn/posts/hadoop%E4%B9%8Bmapreduce%E8%B0%83%E5%BA%A6%E9%80%9A%E8%BF%87shell%E8%BF%9B%E8%A1%8C%E5%A4%9A%E6%97%A5%E6%9C%9F%E7%9A%84%E4%B8%B2%E8%A1%8C%E8%B7%91%E6%89%B9%E7%BB%9F%E8%AE%A1/">阅读全文</a></p>
    </article>
    
    
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/hadoop%E4%B9%8Bhdfs%E7%9A%84shell%E8%84%9A%E6%9C%AC%E5%91%BD%E4%BB%A4%E6%80%BB%E7%BB%93/" title="Hadoop之HDFS的Shell脚本命令总结">Hadoop之HDFS的Shell脚本命令总结</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            一、HDFS的Shell的基本概念
1.调用文件系统(FS)Shell命令应使用 bin/hadoop fs 命令或 bin/hdfs dfs 命令的形式。[为了简便，一般将bin目录添加到path中]
2.所有的FS shell命令使用URI路径作为参数。
URI格式是scheme://authority/path。HDFS的scheme是hdfs，对本地文件系统，scheme是file。其中scheme和authority参数都是可选的，如果未加指定，就会使用配置中指定的默认scheme。例如：hdfs://namenode:namenodePort/parent/child，可以表示成/parent/child（假设配置文件是namenode:namenodePort）
3.大多数FS Shell命令的行为和对应的LINUX Shell命令类似。
二、HDFS的Shell命令
-help [cmd] //显示命令的帮助信息
-ls&reg; //显示当前目录下所有文件
-du(s) //显示目录中所有文件大小
-count[-q] //显示目录中文件数量
-mv //移动多个文件到目标目录
-cp //复制多个文件到目标目录
-rm&reg; //删除文件(夹)
-put //本地文件复制到hdfs
-copyFromLocal //同put
-moveFromLocal //从本地文件移动到hdfs
-get [-ignoreCrc] //复制文件到本地，可以忽略crc校验
-getmerge //将源目录中的所有文件排序合并到一个文件中
-cat //在终端显示文件内容
-text //在终端显示文件内容
-copyToLocal [-ignoreCrc] //复制到本地
-moveToLocal
-mkdir //创建文件夹
-touchz //创建一个空文件
三、HDFS的Shell命令(练习)
#hadoop fs -ls / 查看HDFS根目录
#hadoop fs -mkdir /test 在根目录创建一个目录test
#hadoop fs -put ./test.txt /test 或 #hadoop fs -copyFromLocal /test.……
        </div>
        <p class="readmore"><a href="https://zaina.newban.cn/posts/hadoop%E4%B9%8Bhdfs%E7%9A%84shell%E8%84%9A%E6%9C%AC%E5%91%BD%E4%BB%A4%E6%80%BB%E7%BB%93/">阅读全文</a></p>
    </article>
    
    
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/hadoop%E4%B8%89hdfs%E8%AF%BB%E5%86%99%E5%8E%9F%E7%90%86%E4%B8%8Eshell%E5%91%BD%E4%BB%A4/" title="Hadoop三HDFS读写原理与shell命令">Hadoop三HDFS读写原理与shell命令</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            一 HDFS概述 1.1 HDFS产生背景 随着数据量越来越大，在一个操作系统管辖的范围内存不下了，那么就分配到更多的操作系统管理的磁盘中，但是不方便管理和维护，迫切需要一种系统来管理多台机器上的文件，这就是分布式文件管理系统。HDFS只是分布式文件管理系统中的一种。
1.2 HDFS概念 HDFS，它是一个文件系统，用于存储文件，通过目录树来定位文件；其次，它是分布式的，由很多服务器联合起来实现其功能，集群中的服务器有各自的角色。
HDFS的设计适合一次写入，多次读出的场景，且不支持文件的修改。适合用来做数据分析，并不适合用来做网盘应用。
1.3 HDFS优缺点 1.3.1 优点
1）高容错性
（1）数据自动保存多个副本。它通过增加副本的形式，提高容错性。
（2）某一个副本丢失以后，它可以自动恢复。
2）适合大数据处理
（1）数据规模：能够处理数据规模达到 GB、TB、甚至PB级别的数据。
（2）文件规模：能够处理百万规模以上的文件数量，数量相当之大。
3）流式数据访问
（1）一次写入，多次读取，不能修改，只能追加。
（2）它能保证数据的一致性。
4）可构建在廉价机器上，通过多副本机制，提高可靠性。
1.3.2 缺点
1）不适合低延时数据访问，比如毫秒级的存储数据，是做不到的。
2）无法高效的对大量小文件进行存储
（1）存储大量小文件的话，它会占用 NameNode大量的内存来存储文件、目录和块信息。这样是不可取的，因为NameNode的内存总是有限的。
（2）小文件存储的寻道时间会超过读取时间，它违反了HDFS的设计目标。
3）并发写入、文件随机修改
（1）一个文件只能有一个写，不允许多个线程同时写。
（2）仅支持数据 append（追加），不支持文件的随机修改。
抛出问题：HDFS文件系统为什么不适用于存储小文件？ 这是和HDFS系统底层设计实现有关系的，HDFS本身的设计就是用来解决海量大文件数据的存储.，他天生喜欢大数据的处理，大文件存储在HDFS中，会被切分成很多的小数据块，任何一个文件不管有多小，都是一个独立的数据块，而这些数据块的信息则是保存在元数据中的，在之前的博客HDFS基础里面介绍过在HDFS集群的namenode中会存储元数据的信息，这里再说一下，元数据的信息主要包括以下3部分：
1）抽象目录树
2）文件和数据块的映射关系，一个数据块的元数据大小大约是150byte
3）数据块的多个副本存储地
而元数据的存储在磁盘（1和2）和内存中（1、2和3），而服务器中的内存是有上限的，举个例子：
有100个1M的文件存储进入HDFS系统，那么数据块的个数就是100个，元数据的大小就是100*150byte，消耗了15000byte的内存，但是只存储了100M的数据。
有1个100M的文件存储进入HDFS系统，那么数据块的个数就是1个，元数据的大小就是150byte，消耗量150byte的内存，存储量100M的数据。
所以说HDFS文件系统不适用于存储小文件。
1.4 HDFS架构 ### 
###
1）Client：就是客户端。
（1）文件切分。文件上传 HDFS 的时候，Client 将文件切分成一个一个的Block，然后进行存储。
（2）与NameNode交互，获取文件的位置信息。
（3）与DataNode交互，读取或者写入数据。
（4）Client提供一些命令来管理HDFS，比如启动或者关闭HDFS。
（5）Client可以通过一些命令来访问HDFS。
2）NameNode：就是master，它是一个主管、管理者。
（1）管理HDFS的名称空间。
（2）管理数据块（Block）映射信息
（3）配置副本策略
（4）处理客户端读写请求。
3） DataNode：就是Slave。NameNode下达命令，DataNode执行实际的操作。
（1）存储实际的数据块。
（2）执行数据块的读/写操作。
4） Secondary NameNode：并非NameNode的热备。当NameNode挂掉的时候，它并不能马上替换NameNode并提供服务。……
        </div>
        <p class="readmore"><a href="https://zaina.newban.cn/posts/hadoop%E4%B8%89hdfs%E8%AF%BB%E5%86%99%E5%8E%9F%E7%90%86%E4%B8%8Eshell%E5%91%BD%E4%BB%A4/">阅读全文</a></p>
    </article>
    
    
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/hadoopshell%E6%89%A7%E8%A1%8C%E7%A4%BA%E4%BE%8Bwordcountjar%E5%8C%85/" title="hadoopshell执行示例wordcountjar包">hadoopshell执行示例wordcountjar包</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            创建用户目录
bin/hdfs dfs -mkdir -p /user/hadoop
创建input目录
bin/hdfs dfs -mkdir input
导入数据
bin/hdfs dfs -put etc/hadoop/*.xml input
Hadoop运行程序时，默认输出目录不能存在，删除output文件夹
bin/hdfs dfs -rm -r /user/hadoop/output
执行jar包
bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-*.jar grep input output &lsquo;dfs[a-z.]+&rsquo;
(1)bin/hadoop：${HADOOP_HOME}/bin下的shell脚本名。
(2) jar：hadoop脚本需要的command参数。
(3) share/hadoop/mapreduce/hadoop-mapreduce- examples-*.jar：要执行的jar包在本地文件系统中的完整路径，参递给RunJar类。
(4) grep：main方法所在的类，参递给RunJar类。
(5) input：传递给WordCount类，作为DFS文件系统的路径，指示输入数据来源。
(6)output ：传递给WordCount类，作为DFS文件系统的路径，指示输出数据路径。
查看hdfs中的输出结果
bin/hdfs dfs -cat output/*
将输出结果导到本地
rm -R ./output
bin/hdfs dfs -get output output # 将 HDFS 上的 output 文件夹拷贝到本机
cat ./output/*
在程序中输出前删除输出目录代码
onfiguration conf = new Configuration();……
        </div>
        <p class="readmore"><a href="https://zaina.newban.cn/posts/hadoopshell%E6%89%A7%E8%A1%8C%E7%A4%BA%E4%BE%8Bwordcountjar%E5%8C%85/">阅读全文</a></p>
    </article>
    
    
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/hadoopshell%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/" title="hadoopshell常用命令">hadoopshell常用命令</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            ……
        </div>
        <p class="readmore"><a href="https://zaina.newban.cn/posts/hadoopshell%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/">阅读全文</a></p>
    </article>
    
    
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/hadoopshell%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3/" title="HADOOPSHELL官方文档">HADOOPSHELL官方文档</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            ……
        </div>
        <p class="readmore"><a href="https://zaina.newban.cn/posts/hadoopshell%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3/">阅读全文</a></p>
    </article>
    
    
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/hadoopshell%E5%91%BD%E4%BB%A4%E8%AF%A6%E8%A7%A3/" title="hadoopShell命令详解">hadoopShell命令详解</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            ……
        </div>
        <p class="readmore"><a href="https://zaina.newban.cn/posts/hadoopshell%E5%91%BD%E4%BB%A4%E8%AF%A6%E8%A7%A3/">阅读全文</a></p>
    </article>
    
    
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/hadoopshell%E5%91%BD%E4%BB%A4%E6%93%8D%E4%BD%9C/" title="hadoopshell命令操作">hadoopshell命令操作</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            先看我服务器情况：
shizhan01有 ResourceManager 和 NameNode

shizhan02 03 04里是我的 NodeManager 和 DataNode



访问 http://shizhan01:50070

DataNode是存放数据的，hdfs把我的数据都存成两份（我们在hdfs-site.xml里配置的是2），如果数据太大
超过128M时，hdfs就会把我的数据给拆开，按偏移量0-128M的存一份，剩下的存一份。
我们来复现一下这个理论。
先看一下hdfs的根目录有哪些东西，执行
hadoop fs -ls /

可以看到啥都没有，那我们在shizhan02上上传一下文件

我们创建了一个文件，把他上传到hdfs根目录，然后ls可以看到文件
当然我们看 图形界面的客户端，也能看到我们上传的 bigdata.avi 文件，看下图

其实我们把文件上传到hdfs，hdfs就会把我们的文件 重命名，存到两个地方；
也就是说我们把现在的bigdata删除也没事，因为hdfs已经把文件存起来了。
那存到了什么地方呢？
**
**
这个是我们之前在core-site.xml 里配的hadoop.tmp.dir目录
****hdfs把我们的bigdata.avi文件重命名成 blk_1073741825（块_id），放在这个目录下
/home/hadoop/hdpdata/dfs/data/current/BP-1186906364-192.168.116.128-1531575944333/current/finalized/subdir0/subdir0
那因为是存两份，我们再去其他服务器里找下
shizhan03 里没有

shizhan04里有

那这就验证了我们上面说的，hdfs把我们的文件重命名，存了两份，分别在两台服务器上。
那我们再来验证下当文件超过128M了之后的情况：
我在发现shizhan01服务器上有个hadoop的安装包 超过了128M

那我们就把这个安装包上传到hdfs里

图形界面里也能看到

因为超过了128M，所以文件是被hdfs拆分了，我们来找一下
shizhan02上

blk_1073741825是我们之前上传的bigdata文件，下面的26 27是我们上传的hadoop安装包，因为大于128M，
所以被拆分成两个文件
由下图可知，副本被存在了shizhan03上

那shizhan04上，肯定就不会有啦，看下图，25是我们之前存的 bigdata文件……
        </div>
        <p class="readmore"><a href="https://zaina.newban.cn/posts/hadoopshell%E5%91%BD%E4%BB%A4%E6%93%8D%E4%BD%9C/">阅读全文</a></p>
    </article>
    
    
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/hadoopshell%E5%91%BD%E4%BB%A4%E5%AD%97%E5%85%B8%E5%8F%AF%E6%94%B6%E8%97%8F/" title="HadoopShell命令字典可收藏">HadoopShell命令字典可收藏</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            ……
        </div>
        <p class="readmore"><a href="https://zaina.newban.cn/posts/hadoopshell%E5%91%BD%E4%BB%A4%E5%AD%97%E5%85%B8%E5%8F%AF%E6%94%B6%E8%97%8F/">阅读全文</a></p>
    </article>
    
    
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/hadoopshell%E5%91%BD%E4%BB%A4%E5%A4%84%E7%90%86hdfs%E4%B8%8A%E9%94%99%E8%AF%AF%E7%9A%84block%E5%9D%97%E5%B9%B6%E4%BF%AE%E5%A4%8D/" title="Hadoopshell命令处理hdfs上错误的block块并修复">Hadoopshell命令处理hdfs上错误的block块并修复</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            情景：运行Spark程序出现报错
1、报错信息：
17/05/09 14:30:58 WARN scheduler.TaskSetManager: Lost task 28162.1 in stage 0.0 (TID 30490, 127.0.0.1): java.io.IOException: Cannot obtain block length for LocatedBlock{BP-203532773-dfsfdf-1476004795661:blk_1080431162_6762963; getBlockSize()=411; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:1004,DS-e9905a06-4607-4113-b717-709a087b8b96,DISK], DatanodeInfoWithStorage[127.0.0.1:1004,DS-a5046b43-4416-45d9-8ff6-44891bcdf3b8,DISK], DatanodeInfoWithStorage[127.0.0.1:1004,DS-f6b04bbe-9555-4ac8-b06a-3317eb229511,DISK]]}
2、解决参考：
https://community.hortonworks.com/questions/37412/cannot-obtain-block-length- for-locatedblock.html
3、开始检查文件
执行命令检查的结果：注意红色字体
hdfs fsck /user/admin/data/cdn/20170509 -locations -blocks -files Status: HEALTHY Total size: 2115443944 B (Total open files size: 7684855 B) Total dirs: 1 Total files: 67353 Total symlinks: 0 (Files currently being written: 367) Total blocks (validated): 67339 (avg. block size 31414 B) (Total open file blocks (not validated): **357** ) Minimally replicated blocks: 67339 (100.……
        </div>
        <p class="readmore"><a href="https://zaina.newban.cn/posts/hadoopshell%E5%91%BD%E4%BB%A4%E5%A4%84%E7%90%86hdfs%E4%B8%8A%E9%94%99%E8%AF%AF%E7%9A%84block%E5%9D%97%E5%B9%B6%E4%BF%AE%E5%A4%8D/">阅读全文</a></p>
    </article>
    
    
    



<ol class="page-navigator">
    
    <li class="prev">
        <a href="https://zaina.newban.cn/posts/page/1802/">上一页</a>
    </li>
    

    

    
        
        
    
    

    
        
        
        <li >
            <a href="https://zaina.newban.cn/posts/">1</a>
        </li>
        
    
        
        <li>
            <span>...</span>
        </li>
        
    
        
        
        <li >
            <a href="https://zaina.newban.cn/posts/page/1801/">1801</a>
        </li>
        
    
        
        
        <li >
            <a href="https://zaina.newban.cn/posts/page/1802/">1802</a>
        </li>
        
    
        
        
        <li  class="current">
            <a href="https://zaina.newban.cn/posts/page/1803/">1803</a>
        </li>
        
    
        
        
        <li >
            <a href="https://zaina.newban.cn/posts/page/1804/">1804</a>
        </li>
        
    
        
        
        <li >
            <a href="https://zaina.newban.cn/posts/page/1805/">1805</a>
        </li>
        
    
        
        <li>
            <span>...</span>
        </li>
        
    
        
        
        <li >
            <a href="https://zaina.newban.cn/posts/page/1960/">1960</a>
        </li>
        
    

    
    

    <li class="next">
        <a href="https://zaina.newban.cn/posts/page/1804/">下一页</a>
    </li>
    
</ol>




</div>

                    <footer id="footer">
    <div>
        &copy; 2020 <a href="https://zaina.newban.cn">开发者问答集锦 By </a>
        
    </div>
    <br />
    <div>
        <div class="github-badge">
            <a href="https://gohugo.io/" target="_black" rel="nofollow"><span class="badge-subject">Powered by</span><span class="badge-value bg-blue">Hugo</span></a>
        </div>
        <div class="github-badge">
            <a href="https://www.flysnow.org/" target="_black"><span class="badge-subject">Design by</span><span class="badge-value bg-brightgreen">飞雪无情</span></a>
        </div>
        <div class="github-badge">
            <a href="https://github.com/flysnow-org/maupassant-hugo" target="_black"><span class="badge-subject">Theme</span><span class="badge-value bg-yellowgreen">Maupassant</span></a>
        </div>
    </div>
</footer>



<a id="rocket" href="#top"></a>
<script type="text/javascript" src='/js/totop.js?v=0.0.0' async=""></script>



    <script type="text/javascript" src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script>




                </div>

                <div id="secondary">
    <section class="widget">
        <form id="search" action='https://zaina.newban.cn/search/' method="get" accept-charset="utf-8" target="_blank" _lpchecked="1">
      
      <input type="text" name="q" maxlength="20" placeholder="Search">
      <input type="hidden" name="sitesearch" value="https://zaina.newban.cn">
      <button type="submit" class="submit icon-search"></button>
</form>
    </section>
    
    <section class="widget">
        <h3 class="widget-title">最近文章</h3>
<ul class="widget-list">
    
    <li>
        <a href="https://zaina.newban.cn/posts/001rubyruby%E4%B8%AD%E5%85%A8%E5%B1%80%E5%8F%98%E9%87%8F%E5%AE%9E%E4%BE%8B%E5%8F%98%E9%87%8F%E5%B1%80%E9%83%A8%E5%8F%98%E9%87%8F%E7%B1%BB%E5%8F%98%E9%87%8Fsymbol%E5%AF%B9%E6%AF%94/" title="001rubyRuby中全局变量实例变量局部变量类变量Symbol对比">001rubyRuby中全局变量实例变量局部变量类变量Symbol对比</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/007hadoop%E9%9B%86%E7%BE%A4%E9%85%8D%E7%BD%AEhadoop%E9%9B%86%E7%BE%A4%E7%9A%84%E5%90%AF%E5%8A%A8%E5%92%8C%E6%B5%8B%E8%AF%95ssh%E5%85%8D%E7%99%BB%E9%99%86%E9%85%8D%E7%BD%AEstartallshhdfs%E5%B8%B8%E7%94%A8%E7%9A%84shell/" title="007Hadoop集群配置Hadoop集群的启动和测试SSH免登陆配置startallshhdfs常用的shell">007Hadoop集群配置Hadoop集群的启动和测试SSH免登陆配置startallshhdfs常用的shell</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/009shell%E8%84%9A%E6%9C%AC%E4%B8%8B%E6%9D%A1%E4%BB%B6%E6%B5%8B%E8%AF%95eqne/" title="009Shell脚本下条件测试eqne">009Shell脚本下条件测试eqne</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/00pythonmanagepyshell%E5%92%8Cpython%E7%9A%84%E5%88%86%E6%9E%90/" title="00Pythonmanagepyshell和Python的分析">00Pythonmanagepyshell和Python的分析</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/010zookeeper%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5zookeeper%E7%9A%84%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BAzookeeper%E7%9A%84shell%E5%91%BD%E4%BB%A4/" title="010Zookeeper的基本概念Zookeeper的集群搭建Zookeeper的shell命令">010Zookeeper的基本概念Zookeeper的集群搭建Zookeeper的shell命令</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/018dockerfileshell/" title="018DockerfileSHELL">018DockerfileSHELL</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/01shell%E5%85%A5%E9%97%A801bashshell%E7%89%B9%E6%80%A7/" title="01Shell入门01bashShell特性">01Shell入门01bashShell特性</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/01shell%E5%8F%98%E9%87%8F/" title="01Shell变量">01Shell变量</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/01shell%E5%9F%BA%E7%A1%80%E6%A6%82%E8%BF%B0%E8%84%9A%E6%9C%AC%E6%89%A7%E8%A1%8C%E6%96%B9%E5%BC%8Fbash%E5%9F%BA%E6%9C%AC%E5%8A%9F%E8%83%BD/" title="01Shell基础概述脚本执行方式Bash基本功能">01Shell基础概述脚本执行方式Bash基本功能</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/01shell%E7%BC%96%E7%A8%8Bhelloworld/" title="01shell编程helloworld">01shell编程helloworld</a>
    </li>
    
</ul>
    </section>

    

    <section class="widget">
        <h3 class="widget-title"><a href="/categories">分类</a></h3>
<ul class="widget-list">
    
</ul>
    </section>

    <section class="widget">
        <h3 class="widget-title"><a href="/tags">标签</a></h3>
<div class="tagcloud">
    
    <a href="https://zaina.newban.cn/tags/ruby/">ruby</a>
    
    <a href="https://zaina.newban.cn/tags/shell/">shell</a>
    
</div>
    </section>

    

    <section class="widget">
        <h3 class="widget-title">其它</h3>
        <ul class="widget-list">
            <li><a href="https://zaina.newban.cn/index.xml">文章 RSS</a></li>
        </ul>
    </section>
</div>
            </div>
        </div>
    </div>
</body>

</html>