<!doctype html>
<html lang="en-us">
<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">


    <title>Posts | 开发者问答集锦</title>
    <meta property="og:title" content="Posts - 开发者问答集锦">
    <meta property="og:type" content="article">
        
        
    <meta name="Keywords" content="">
    <meta name="description" content="Posts">
        
    <meta name="author" content="">
    <meta property="og:url" content="https://zaina.newban.cn/posts/">
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">

    <link rel="stylesheet" href='/css/normalize.css'>
    <link rel="stylesheet" href='/css/style.css'>
    <link rel="alternate" type="application/rss+xml+xml" href="https://zaina.newban.cn/posts/index.xml" title="开发者问答集锦" />
    <script type="text/javascript" src="//cdn.bootcdn.net/ajax/libs/jquery/3.4.1/jquery.min.js"></script>

    
    
    
    
    
    
</head>


<body>
    <header id="header" class="clearfix">
    <div class="container">
        <div class="col-group">
            <div class="site-name ">
                
                    <a id="logo" href="https://zaina.newban.cn">
                        开发者问答集锦
                    </a>
                
                
            </div>
            <div>
                <nav id="nav-menu" class="clearfix">
                    <a class="" href="https://zaina.newban.cn">首页</a>
                    
                </nav>
            </div>
        </div>
    </div>
</header>

    <div id="body">
        <div class="container">
            <div class="col-group">

                <div class="col-8" id="main">
                    
<div class="res-cons">
    
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/screen%E5%91%BD%E4%BB%A4%E5%92%8Cshell%E8%84%9A%E6%9C%AC%E5%9F%BA%E7%A1%80/" title="screen命令和shell脚本基础">screen命令和shell脚本基础</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            问题背景 如果你要运行一个时间很长的 job 你会怎么办？这个问题可以转变为当一个任务运行时间非常长，你如何保证操作系统不自动中断它。答案取决与运行环境，如果是台式机 + windows 的桌面系统就注意一下人离开的时候锁屏，而不要注销用户或者关机即可；而当你使用 Mac 或者远程连接 Linux 的时候要如何处理？我做过一件很傻的事情就是即使要从宿舍走到图书馆也一直把屏幕开着，本想着校园里处处都有 Wi-Fi 应该没事，但连接还是在路上断开了，导致之前的工作必须重新来过。
解决方案 要运行这个 job 之前先建一个 screen:
screen -S [name of your screen]  比如你可以用 screen -S my-screen 创立一个叫”my-screen”的对话，运行你的 job, 然后按下 Ctrl+A, Ctrl+D （先按+A，再按+D). 你就从那个对话中抽身出来，此时命令行会提示一行 “[detached]“，表示这个 job 已经在后台运行了。
你可以通过
screen -list  来得到建立的所有 screen 的列表，如果要回到某个 screen 就使用 screen -r [screen-id] . 这里的 id 能够在 list 中找到……
        </div>
        <p class="readmore"><a href="https://zaina.newban.cn/posts/screen%E5%91%BD%E4%BB%A4%E5%92%8Cshell%E8%84%9A%E6%9C%AC%E5%9F%BA%E7%A1%80/">阅读全文</a></p>
    </article>
    
    
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/scrapy%E7%BB%88%E7%AB%AFscrapyshell/" title="Scrapy终端Scrapyshell">Scrapy终端Scrapyshell</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            ……
        </div>
        <p class="readmore"><a href="https://zaina.newban.cn/posts/scrapy%E7%BB%88%E7%AB%AFscrapyshell/">阅读全文</a></p>
    </article>
    
    
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/scrapy%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E4%BA%8Citempipeline%E7%AE%A1%E9%81%93%E5%92%8Cscrapyshell/" title="Scrapy框架学习二ItemPipeline管道和ScrapyShell">Scrapy框架学习二ItemPipeline管道和ScrapyShell</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            Scrapy框架学习（二）—-Item Pipeline(管道)和Scrapy Shell Item Pipeline（管道） 当Item在Spider中被收集之后，它将会被传递到Item Pipeline，一些组件会按照一定的顺序执行对Item进行处理。
每个Item Pipeline都是实现了简单方法的Python类，比如决定此Item是丢弃而存储。以下是Item Pipeline的典型应用：
 验证爬取的数据（检查爬取的数据是否包含某些字段，数据清洗）
 查重（重复的数据丢弃）
 将爬取的结果保存到文件或数据库
  编写Item Pipeline类
在pipelines.py文件中定义一个Pipeline类，同时 必须 实现下面的方法：
process_item(self,item,spider)  每个item pipeline组件都需要调用该方法，这个方法 必须返回一个Item对象，或是抛出DropItem异常 ，被丢弃的item将不会被之后的pipeline组件处理。
代码如下：
import json class BaiduPipeline(object): def process_item(self, item, spider): &quot;&quot;&quot; 处理item的方法，处理业务逻辑，保存数据，返回item :param item: 是items.py中定义item类 :param spider: 是spiders目录中定义的Spider类 :return: 返回需要的item数据（经过清洗，业务逻辑处理后的item数据） &quot;&quot;&quot; print(spider) # 输出 print(type(spider)) # 输出 print(spider.name) # 输出 baidu print(item) # 输出 {'title': '百度一下'} print(type(item)) # 输出 with open('baidu.json', 'w') as f: jsondata = json.……
        </div>
        <p class="readmore"><a href="https://zaina.newban.cn/posts/scrapy%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E4%BA%8Citempipeline%E7%AE%A1%E9%81%93%E5%92%8Cscrapyshell/">阅读全文</a></p>
    </article>
    
    
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/scrapy%E6%A1%86%E6%9E%B6%E4%B9%8Bshell/" title="scrapy框架之shell">scrapy框架之shell</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            scrapy shell scrapy shell是一个交互式shell，您可以在其中快速调试 scrape 代码，而不必运行spider。它本来是用来测试数据提取代码的，但实际上您可以使用它来测试任何类型的代码，因为它也是一个常规的Python shell。
shell用于测试xpath或css表达式，并查看它们是如何工作的，以及它们从您试图抓取的网页中提取的数据。它允许您在编写spider时交互地测试表达式，而不必运行spider来测试每个更改。
一旦你熟悉了 Scrapy Shell，你就会发现它是开发和调试蜘蛛的宝贵工具。
配置shell 如果你有 IPython 安装后，scrapy shell将使用它（而不是标准的python控制台）。这个 IPython 控制台功能更强大，提供智能自动完成和彩色输出等功能。
通过Scrapy的设置，您可以将其配置为使用 ipython ， bpython 或标准 python shell，无论安装了什么。这是通过设置 SCRAPY_PYTHON_SHELL 环境变量；或通过在 scrapy.cfg ；
[settings] shell = bpython  启动shell 使用 shell 命令如下：
scrapy shell # 是要抓取的url  shell 也适用于本地文件。如果你想玩一个网页的本地副本，这很方便。 shell 了解本地文件的以下语法：
# UNIX-style scrapy shell ./path/to/file.html scrapy shell ../other/path/to/file.html scrapy shell /absolute/path/to/file.html # File URI scrapy shell file:///absolute/path/to/file.html  使用相对文件路径时，请使用 ./ （或） ../ 表示文件存储的路径……
        </div>
        <p class="readmore"><a href="https://zaina.newban.cn/posts/scrapy%E6%A1%86%E6%9E%B6%E4%B9%8Bshell/">阅读全文</a></p>
    </article>
    
    
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/scrapy%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7shell%E4%BD%BF%E7%94%A8/" title="Scrapy命令行工具shell使用">Scrapy命令行工具shell使用</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            * 配置 shell 使用的终端  登录 shell 使用 shell  可用方法 可用对象 示例  在 spider 内调用 shell   shell 作为 Scrapy 内置的有力交互工具，在其内进行爬取调试和解析验证非常方便。
配置 shell 使用的终端 若系统安装 IPython，则使用它替换默认的 Python 终端。可在工程内的 scrapy.cfg 文件内指定终端，如：
[settings] shell = bpython  登录 shell 使用命令：
scrapy shell &lt;url&gt;  进入 shell，其中 url 支持本地文件：
# UNIX-style scrapy shell ./path/to/file.html scrapy shell ../other/path/to/file.html scrapy shell /absolute/path/to/file.html # File URI scrapy shell file:///absolute/path/to/file.html  使用 shell 可用方法  shelp(): 打印可用的对象和方法 fetch(url[, redirect=True]): 爬取新的 URL 并更新相关对象 fetch(request): 通过 request 爬取，并更新相关对象 view(response): 使用本地浏览器打开爬取的页面  可用对象  crawler: Crawler 对象 spider: 爬取使用的 spider request: 请求 response: 响应 settings: 设置  示例 $ scrapy shell 'http://scrapy.……
        </div>
        <p class="readmore"><a href="https://zaina.newban.cn/posts/scrapy%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7shell%E4%BD%BF%E7%94%A8/">阅读全文</a></p>
    </article>
    
    
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/scrapy%E4%B9%8Bscrapyshell/" title="Scrapy之Scrapyshell">Scrapy之Scrapyshell</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            Scrapy Shell Scrapy终端是一个交互终端，我们可以在未启动spider的情况下尝试及调试代码，也可以用来测试XPath或CSS表达式，查看他们的工作方式，方便我们爬取的网页中提取的数据。
如果安装了 IPython ，Scrapy终端将使用 IPython (替代标准Python终端)。 IPython 终端与其他相比更为强大，提供智能的自动补全，高亮输出，及其他特性。（推荐安装IPython）
启动Scrapy Shell 进入项目的根目录，执行下列命令来启动shell:
scrapy shell &quot;http://www.itcast.cn/channel/teacher.shtml&quot;  Scrapy Shell根据下载的页面会自动创建一些方便使用的对象，例如 Response 对象，以及 Selector 对象 (对HTML及XML内容)。
 当shell载入后，将得到一个包含response数据的本地 response 变量，输入 response.body将输出response的包体，输出 response.headers 可以看到response的包头。
 输入 response.selector 时， 将获取到一个response 初始化的类 Selector 的对象，此时可以通过使用 response.selector.xpath()或response.selector.css() 来对 response 进行查询。
 Scrapy也提供了一些快捷方式, 例如 response.xpath()或response.css()同样可以生效（如之前的案例）。
  Selectors选择器 Scrapy Selectors 内置 XPath 和 CSS Selector 表达式机制 Selector有四个基本的方法，最常用的还是xpath:
 xpath(): 传入xpath表达式，返回该表达式所对应的所有节点的selector list列表 extract(): 序列化该节点为Unicode字符串并返回list css(): 传入CSS表达式，返回该表达式所对应的所有节点的selector list列表，语法同 BeautifulSoup4 re(): 根据传入的正则表达式对数据进行提取，返回Unicode字符串list列表  XPath表达式的例子及对应的含义: /html/head/title: 选择&lt;HTML&gt;文档中 &lt;head&gt; 标签内的 &lt;title&gt; 元素 /html/head/title/text(): 选择上面提到的 &lt;title&gt; 元素的文字 //td: 选择所有的 &lt;td&gt; 元素 //div[@class=&quot;mine&quot;]: 选择所有具有 class=&quot;mine&quot; 属性的 div 元素  尝试Selector 我们用腾讯社招的网站http://hr.……
        </div>
        <p class="readmore"><a href="https://zaina.newban.cn/posts/scrapy%E4%B9%8Bscrapyshell/">阅读全文</a></p>
    </article>
    
    
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/scrapy%E4%B8%ADshell%E5%87%BA%E7%8E%B0403%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/" title="scrapy中shell出现403解决方案">scrapy中shell出现403解决方案</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            我们使用scrapy shell来进行调试是很方便的，但是有时会出现403错误的问题，我们来解决这个问题： 出现403，表示网站拒绝提供服务
因为有的网站有反爬机制，当你使用scrapy shell的时候是以是scrapy爬虫的标识进行访问网站的，这时候网站会拒绝为爬虫提供服务，这时候就会返回403错误
下面列举三个方案来解决这个问题，三个方案的原理都是一样的，即修改user-agent的值，使用浏览器的标识来对网站进行访问，这样网站就不会拒绝服务了
方案一：只治标. 在使用scrapy shell的时候，在其后面加上-s USER_AGENT=&lsquo;Mozills/5.0’
eg: 我们要对百度进行scrapy shell的时候
scrapy shell http://www.baidu.com -s USER_AGENT='Mozills/5.0'  成功！！！
方案二：半治标半治本. 修改scrapy项目里的settings.py USER_AGENT
把settings.py里的USER_AGENT的属性启用并修改
修改前：
#USER_AGENT = 'yi (+http://www.yourdomain.com)'  修改后：
USER_AGENT = 'Mozilla/5.0 (Windows NT 5.1; rv:5.0) Gecko/20100101 Firefox/5.0'  再次使用scrapy shell：
（注意：这里的scrapy shell只能在项目里使用，直接在cmd中使用是不生效的，这也是为什么说半治标的原因）
scrapy shell https://movie.douban.com/top250  我们看一下返回的信息:
response &lt;200 https://movie.douban.com/top250&gt;  返回200， 成功！！！

方案三： 治本. 修改整个python的default_settings.py文件里的默认USER_AGENT值
 之后在不管是在项目中还是在cmd中使用scrapy shell，都是以浏览器的标识符来进行访问的了
 找一下default_settings.py文件的位置
我的default_settings.py文件在C:\ProgramData\Anaconda3\Lib\site- packages\scrapy\settings下
找到文件位置后，打开文件，修改 USER_AGENT的值……
        </div>
        <p class="readmore"><a href="https://zaina.newban.cn/posts/scrapy%E4%B8%ADshell%E5%87%BA%E7%8E%B0403%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/">阅读全文</a></p>
    </article>
    
    
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/scrapyshell%E8%B0%83%E8%AF%95%E8%BF%94%E5%9B%9E403%E9%94%99%E8%AF%AF/" title="Scrapyshell调试返回403错误">Scrapyshell调试返回403错误</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            一、问题描述
有时候用scrapy shell来调试很方便,但是有些网站有防爬虫机制,所以使用scrapy shell会返回403,比如下面
C:\Users\fendo&gt;scrapy shell https://book.douban.com/subject/26805083/ 2017-04-17 15:18:53 [scrapy.utils.log] INFO: Scrapy 1.3.3 started (bot: scrapybot) 2017-04-17 15:18:53 [scrapy.utils.log] INFO: Overridden settings: {'DUPEFILTER_CLASS': 'scrapy.dupefilters.BaseDupeFilter', 'LOGSTATS_INTERVAL': 0} 2017-04-17 15:18:53 [scrapy.middleware] INFO: Enabled extensions: ['scrapy.extensions.corestats.CoreStats', 'scrapy.extensions.telnet.TelnetConsole'] 2017-04-17 15:18:54 [scrapy.middleware] INFO: Enabled downloader middlewares: ['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware', 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware', 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware', 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware', 'scrapy.downloadermiddlewares.retry.RetryMiddleware', 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware', 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware', 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware', 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware', 'scrapy.downloadermiddlewares.stats.DownloaderStats'] 2017-04-17 15:18:54 [scrapy.middleware] INFO: Enabled spider middlewares: ['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware', 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware', 'scrapy.spidermiddlewares.referer.RefererMiddleware', 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware', 'scrapy.spidermiddlewares.depth.DepthMiddleware'] 2017-04-17 15:18:54 [scrapy.middleware] INFO: Enabled item pipelines: [] 2017-04-17 15:18:54 [scrapy.……
        </div>
        <p class="readmore"><a href="https://zaina.newban.cn/posts/scrapyshell%E8%B0%83%E8%AF%95%E8%BF%94%E5%9B%9E403%E9%94%99%E8%AF%AF/">阅读全文</a></p>
    </article>
    
    
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/scrapyshell%E8%B0%83%E8%AF%95%E6%8A%A5%E9%94%99typeerrormoduleinittakesatmost2arguments3given/" title="scrapyshell调试报错TypeErrormoduleinittakesatmost2arguments3given">scrapyshell调试报错TypeErrormoduleinittakesatmost2arguments3given</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            1、使用scrapy shell的时候本人之前安装了ipython，使用shell调式格式从&gt;&gt;&gt;变成了【1】这种带有ipython的格式，结果整齐度看起来比较舒服。
2、现在创建了crawl spider，同时进入到项目目录，使用scrapy shell xxxxxxxx在cmd或者cmder中进行调式的报错TypeError: module.init() takes at most 2 arguments (3 g iven)，说明了应该是ipython直接运行了pycharm中项目的代码，在某一个项目中的一项显示出了类型错误，后来在cmd或者cmder的创始目录进行scrapy shell xxxxxxxx调式的时候，可以进入其中，可以调式response.css或者response.xpath。……
        </div>
        <p class="readmore"><a href="https://zaina.newban.cn/posts/scrapyshell%E8%B0%83%E8%AF%95%E6%8A%A5%E9%94%99typeerrormoduleinittakesatmost2arguments3given/">阅读全文</a></p>
    </article>
    
    
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/scrapyshell%E8%B0%83%E8%AF%95%E4%BB%A3%E7%A0%81/" title="ScrapyShell调试代码">ScrapyShell调试代码</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            Scrapy Shell
Scrapy终端是一个交互终端，我们可以在未启动spider的情况下尝试及调试代码，也可以用来测试XPath或CSS表达式，查看他们的工作方式，方便我们爬取的网页中提取的数据。
启动Scrapy Shell
进入cmd输入命令行：
scrapy shell &quot;http://quotes.toscrape.com/&quot;  
状态码200，表示请求成功。
在爬取一个网站的时候，最好是使用shell来查看下是否有反爬机制，如果返回的状态码不是200，多半是有反爬机制。如果在不知道的前提下强行爬取可能会导致爬虫中断需要登录后才可访问网站，严重的甚至是ip被封。
测试XPath
&gt;&gt;&gt; response.xpath('//div[@class=&quot;quote&quot;]//small/text()') [, , , , , , , , , ] &gt;&gt;&gt; response.xpath('//div[@class=&quot;quote&quot;]//small/text()').extract() ['Albert Einstein', 'J.K. Rowling', 'Albert Einstein', 'Jane Austen', 'Marilyn Monroe', 'Albert Einstein', 'André Gide', 'Thomas A. Edison', 'Eleanor Roosevelt', 'Steve Martin'] &gt;&gt;&gt; response.xpath('//div[@class=&quot;quote&quot;][1]//small/text()').extract() ['Albert Einstein'] &gt;&gt;&gt; response.xpath('//div[@class=&quot;quote&quot;][1]//small/text()').extract()[0] 'Albert Einstein'  以后做数据提取的时候，可以把现在Scrapy Shell中测试，测试通过后再应用到代码中。……
        </div>
        <p class="readmore"><a href="https://zaina.newban.cn/posts/scrapyshell%E8%B0%83%E8%AF%95%E4%BB%A3%E7%A0%81/">阅读全文</a></p>
    </article>
    
    
    



<ol class="page-navigator">
    
    <li class="prev">
        <a href="https://zaina.newban.cn/posts/page/1189/">上一页</a>
    </li>
    

    

    
        
        
    
    

    
        
        
        <li >
            <a href="https://zaina.newban.cn/posts/">1</a>
        </li>
        
    
        
        <li>
            <span>...</span>
        </li>
        
    
        
        
        <li >
            <a href="https://zaina.newban.cn/posts/page/1188/">1188</a>
        </li>
        
    
        
        
        <li >
            <a href="https://zaina.newban.cn/posts/page/1189/">1189</a>
        </li>
        
    
        
        
        <li  class="current">
            <a href="https://zaina.newban.cn/posts/page/1190/">1190</a>
        </li>
        
    
        
        
        <li >
            <a href="https://zaina.newban.cn/posts/page/1191/">1191</a>
        </li>
        
    
        
        
        <li >
            <a href="https://zaina.newban.cn/posts/page/1192/">1192</a>
        </li>
        
    
        
        <li>
            <span>...</span>
        </li>
        
    
        
        
        <li >
            <a href="https://zaina.newban.cn/posts/page/1960/">1960</a>
        </li>
        
    

    
    

    <li class="next">
        <a href="https://zaina.newban.cn/posts/page/1191/">下一页</a>
    </li>
    
</ol>




</div>

                    <footer id="footer">
    <div>
        &copy; 2020 <a href="https://zaina.newban.cn">开发者问答集锦 By </a>
        
    </div>
    <br />
    <div>
        <div class="github-badge">
            <a href="https://gohugo.io/" target="_black" rel="nofollow"><span class="badge-subject">Powered by</span><span class="badge-value bg-blue">Hugo</span></a>
        </div>
        <div class="github-badge">
            <a href="https://www.flysnow.org/" target="_black"><span class="badge-subject">Design by</span><span class="badge-value bg-brightgreen">飞雪无情</span></a>
        </div>
        <div class="github-badge">
            <a href="https://github.com/flysnow-org/maupassant-hugo" target="_black"><span class="badge-subject">Theme</span><span class="badge-value bg-yellowgreen">Maupassant</span></a>
        </div>
    </div>
</footer>



<a id="rocket" href="#top"></a>
<script type="text/javascript" src='/js/totop.js?v=0.0.0' async=""></script>



    <script type="text/javascript" src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script>




                </div>

                <div id="secondary">
    <section class="widget">
        <form id="search" action='https://zaina.newban.cn/search/' method="get" accept-charset="utf-8" target="_blank" _lpchecked="1">
      
      <input type="text" name="q" maxlength="20" placeholder="Search">
      <input type="hidden" name="sitesearch" value="https://zaina.newban.cn">
      <button type="submit" class="submit icon-search"></button>
</form>
    </section>
    
    <section class="widget">
        <h3 class="widget-title">最近文章</h3>
<ul class="widget-list">
    
    <li>
        <a href="https://zaina.newban.cn/posts/001rubyruby%E4%B8%AD%E5%85%A8%E5%B1%80%E5%8F%98%E9%87%8F%E5%AE%9E%E4%BE%8B%E5%8F%98%E9%87%8F%E5%B1%80%E9%83%A8%E5%8F%98%E9%87%8F%E7%B1%BB%E5%8F%98%E9%87%8Fsymbol%E5%AF%B9%E6%AF%94/" title="001rubyRuby中全局变量实例变量局部变量类变量Symbol对比">001rubyRuby中全局变量实例变量局部变量类变量Symbol对比</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/007hadoop%E9%9B%86%E7%BE%A4%E9%85%8D%E7%BD%AEhadoop%E9%9B%86%E7%BE%A4%E7%9A%84%E5%90%AF%E5%8A%A8%E5%92%8C%E6%B5%8B%E8%AF%95ssh%E5%85%8D%E7%99%BB%E9%99%86%E9%85%8D%E7%BD%AEstartallshhdfs%E5%B8%B8%E7%94%A8%E7%9A%84shell/" title="007Hadoop集群配置Hadoop集群的启动和测试SSH免登陆配置startallshhdfs常用的shell">007Hadoop集群配置Hadoop集群的启动和测试SSH免登陆配置startallshhdfs常用的shell</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/009shell%E8%84%9A%E6%9C%AC%E4%B8%8B%E6%9D%A1%E4%BB%B6%E6%B5%8B%E8%AF%95eqne/" title="009Shell脚本下条件测试eqne">009Shell脚本下条件测试eqne</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/00pythonmanagepyshell%E5%92%8Cpython%E7%9A%84%E5%88%86%E6%9E%90/" title="00Pythonmanagepyshell和Python的分析">00Pythonmanagepyshell和Python的分析</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/010zookeeper%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5zookeeper%E7%9A%84%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BAzookeeper%E7%9A%84shell%E5%91%BD%E4%BB%A4/" title="010Zookeeper的基本概念Zookeeper的集群搭建Zookeeper的shell命令">010Zookeeper的基本概念Zookeeper的集群搭建Zookeeper的shell命令</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/018dockerfileshell/" title="018DockerfileSHELL">018DockerfileSHELL</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/01shell%E5%85%A5%E9%97%A801bashshell%E7%89%B9%E6%80%A7/" title="01Shell入门01bashShell特性">01Shell入门01bashShell特性</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/01shell%E5%8F%98%E9%87%8F/" title="01Shell变量">01Shell变量</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/01shell%E5%9F%BA%E7%A1%80%E6%A6%82%E8%BF%B0%E8%84%9A%E6%9C%AC%E6%89%A7%E8%A1%8C%E6%96%B9%E5%BC%8Fbash%E5%9F%BA%E6%9C%AC%E5%8A%9F%E8%83%BD/" title="01Shell基础概述脚本执行方式Bash基本功能">01Shell基础概述脚本执行方式Bash基本功能</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/01shell%E7%BC%96%E7%A8%8Bhelloworld/" title="01shell编程helloworld">01shell编程helloworld</a>
    </li>
    
</ul>
    </section>

    

    <section class="widget">
        <h3 class="widget-title"><a href="/categories">分类</a></h3>
<ul class="widget-list">
    
</ul>
    </section>

    <section class="widget">
        <h3 class="widget-title"><a href="/tags">标签</a></h3>
<div class="tagcloud">
    
    <a href="https://zaina.newban.cn/tags/ruby/">ruby</a>
    
    <a href="https://zaina.newban.cn/tags/shell/">shell</a>
    
</div>
    </section>

    

    <section class="widget">
        <h3 class="widget-title">其它</h3>
        <ul class="widget-list">
            <li><a href="https://zaina.newban.cn/index.xml">文章 RSS</a></li>
        </ul>
    </section>
</div>
            </div>
        </div>
    </div>
</body>

</html>