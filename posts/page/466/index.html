<!doctype html>
<html lang="en-us">
<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">


    <title>Posts | 开发者问答集锦</title>
    <meta property="og:title" content="Posts - 开发者问答集锦">
    <meta property="og:type" content="article">
        
        
    <meta name="Keywords" content="">
    <meta name="description" content="Posts">
        
    <meta name="author" content="">
    <meta property="og:url" content="https://zaina.newban.cn/posts/">
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">

    <link rel="stylesheet" href='/css/normalize.css'>
    <link rel="stylesheet" href='/css/style.css'>
    <link rel="alternate" type="application/rss+xml+xml" href="https://zaina.newban.cn/posts/index.xml" title="开发者问答集锦" />
    <script type="text/javascript" src="//cdn.bootcdn.net/ajax/libs/jquery/3.4.1/jquery.min.js"></script>

    
    
    
    
    
    
</head>


<body>
    <header id="header" class="clearfix">
    <div class="container">
        <div class="col-group">
            <div class="site-name ">
                
                    <a id="logo" href="https://zaina.newban.cn">
                        开发者问答集锦
                    </a>
                
                
            </div>
            <div>
                <nav id="nav-menu" class="clearfix">
                    <a class="" href="https://zaina.newban.cn">首页</a>
                    
                </nav>
            </div>
        </div>
    </div>
</header>

    <div id="body">
        <div class="container">
            <div class="col-group">

                <div class="col-8" id="main">
                    
<div class="res-cons">
    
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/spark%E7%A8%8B%E5%BA%8F%E6%8F%90%E4%BA%A4%E6%89%A7%E8%A1%8Csparkshell%E7%AE%97%E5%AD%90/" title="spark程序提交执行sparkshell算子">spark程序提交执行sparkshell算子</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            文章目录  spark-shell  spark-shell里的内容 spark-submit spark-class  spark的一些函数  两种方法读文件 transformations和actions  综合程序  打包 提交   把上一次编译后的包解压。

本地启动spark，可以在4040看到sparkUI

spark默认程序名字

spark-shell spark-shell里的内容 调用spark-submit，默认名字Spark shell，$@相当于获取用户输入的模式（比如local）
&quot;${SPARK_HOME}&quot;/bin/spark-submit --class org.apache.spark.repl.Main --name &quot;Spark shell&quot; &quot;$@&quot;  spark-submit 调用了spark-class，传给spark-shell的参数被继承下来了
exec &quot;${SPARK_HOME}&quot;/bin/spark-class org.apache.spark.deploy.SparkSubmit &quot;$@&quot;  spark-class 加载spark-env，环境参数
. &quot;${SPARK_HOME}&quot;/bin/load-spark-env.sh  spark的一些函数 import org.apache.spark.{SparkConf, SparkContext} object Spark02 { def main(args: Array[String]): Unit = { val sparkConf=new SparkConf() //在spark-shell运行的时候再指定，这里的优先级要比在shell里更高，appname可以默认 //shell里有内置 //.setMaster(&quot;local[2]&quot;).setAppName(&quot;Spark02&quot;) val sc =new SparkContext(sparkConf) //创建rdd方法1，第一个参数是数组，第二个参数是默认切片 // val rdd = sc.……
        </div>
        <p class="readmore"><a href="https://zaina.newban.cn/posts/spark%E7%A8%8B%E5%BA%8F%E6%8F%90%E4%BA%A4%E6%89%A7%E8%A1%8Csparkshell%E7%AE%97%E5%AD%90/">阅读全文</a></p>
    </article>
    
    
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/spark%E7%9A%84shell%E7%95%8C%E9%9D%A2%E6%93%8D%E4%BD%9Crdd%E7%AE%97%E5%AD%90%E7%B1%BB%E5%9E%8B%E8%BD%AC%E6%8D%A2%E7%AE%97%E5%AD%90%E6%89%A7%E8%A1%8C%E7%AE%97%E5%AD%90%E6%8E%A7%E5%88%B6%E7%AE%97%E5%AD%90/" title="Spark的shell界面操作RDD算子类型转换算子执行算子控制算子">Spark的shell界面操作RDD算子类型转换算子执行算子控制算子</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            目录
一、HADOOP和Spark生态圈
二、Spark Shell 中算子的操作 （转换算子，执行算子，控制算子）
2.1、Tansformation算子/函数 延迟执行 转换算子
2.2、Action 立刻执行 行动算子
2.3、控制算子 主要是为了对数据进行缓存 详细介绍：https://blog.csdn.net/qq_44472134/article/details/104166577
三、进入shell界面操作算子的两种进入方式（spark的三种模式安装 链接：https://blog.csdn.net/qq_44472134/article/details/104339585）
3.1、spark基于standload的进入方式
3.2、spark基于yarn调度的进入方式
一、HADOOP和Spark生态圈 
二、Spark Shell 中算子的操作 （转换算子，执行算子，控制算子） 2.1、Tansformation算子/函数 延迟执行 转换算子 1、map 窄依赖
2、filter 窄依赖
3、flatMap 窄依赖
4、coalesce (分区数,true) rdd7.partitions.size 查看rdd的分区数 val rdd5=rdd4.coalesce(3,true)
可以增加分区，可以减少分区，有 shuffle（一个父RDD到多个子RDD） 所以是宽依赖
5、repartition (分区数) 不管允不允许都会进行 shuffle val rdd5=rdd4.repartition(4)
可以增加分区，可以减少分区，有shuffle 所以是宽依赖 分区
6、groupByKey（） RDD[String,Iterable(Int)]
7、reduceBykey（_+） val rdd8=rdd7.reduceByKey(+_) 宽依赖
8、sortBykey（） 根据K排序，要求RDD 中必须是KV的，宽依赖
9、sortBy（_._2,false） 以value排序，进行倒序排序
2.2、Action 立刻执行 行动算子 1、collect
2、sum（） 返回Double类型……
        </div>
        <p class="readmore"><a href="https://zaina.newban.cn/posts/spark%E7%9A%84shell%E7%95%8C%E9%9D%A2%E6%93%8D%E4%BD%9Crdd%E7%AE%97%E5%AD%90%E7%B1%BB%E5%9E%8B%E8%BD%AC%E6%8D%A2%E7%AE%97%E5%AD%90%E6%89%A7%E8%A1%8C%E7%AE%97%E5%AD%90%E6%8E%A7%E5%88%B6%E7%AE%97%E5%AD%90/">阅读全文</a></p>
    </article>
    
    
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/spark%E7%9A%84python%E5%92%8Cscalashell%E4%BB%8B%E7%BB%8D%E7%BF%BB%E8%AF%91%E8%87%AAlearningsparklightningfastbigdataanalysis/" title="Spark的Python和Scalashell介绍翻译自LearningSparkLightningFastBigDataAnalysis">Spark的Python和Scalashell介绍翻译自LearningSparkLightningFastBigDataAnalysis</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            ……
        </div>
        <p class="readmore"><a href="https://zaina.newban.cn/posts/spark%E7%9A%84python%E5%92%8Cscalashell%E4%BB%8B%E7%BB%8D%E7%BF%BB%E8%AF%91%E8%87%AAlearningsparklightningfastbigdataanalysis/">阅读全文</a></p>
    </article>
    
    
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/spark%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2sparkshell%E7%8E%AF%E5%A2%83%E4%B8%8B%E9%85%8D%E7%BD%AE%E6%9C%AC%E5%9C%B0%E8%AF%BB%E5%85%A5%E6%96%87%E6%9C%AC%E4%BF%A1%E6%81%AF%E6%97%B6%E5%87%BA%E7%8E%B0%E6%8A%A5%E9%94%99console17errornotfoundvaluesc/" title="Spark环境部署sparkshell环境下配置本地读入文本信息时出现报错console17errornotfoundvaluesc">Spark环境部署sparkshell环境下配置本地读入文本信息时出现报错console17errornotfoundvaluesc</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            Spark环境部署,配置本地读入文本信息时出现报错：
**Caused by: org.apache.hadoop.ipc.RemoteException: Cannot create directory /tmp/hive/root/648867dc-0554-406f-8a02-233cef6b6cf2. Name node is in safe mode.
The reported blocks 71 needs additional 2 blocks to reach the threshold 0.9990 of total blocks 73.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1335)
at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3874)
at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol 2. c a l l B l o c k i n g M e t h o d ( C l i e n t N a m e n o d e P r o t o c o l P r o t o s .……
        </div>
        <p class="readmore"><a href="https://zaina.newban.cn/posts/spark%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2sparkshell%E7%8E%AF%E5%A2%83%E4%B8%8B%E9%85%8D%E7%BD%AE%E6%9C%AC%E5%9C%B0%E8%AF%BB%E5%85%A5%E6%96%87%E6%9C%AC%E4%BF%A1%E6%81%AF%E6%97%B6%E5%87%BA%E7%8E%B0%E6%8A%A5%E9%94%99console17errornotfoundvaluesc/">阅读全文</a></p>
    </article>
    
    
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/spark%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B8%80sparkshell%E5%90%AF%E5%8A%A8%E8%84%9A%E6%9C%AC%E6%97%B6%E5%80%99%E8%BF%87%E7%A8%8B/" title="spark源码分析一sparkshell启动脚本时候过程">spark源码分析一sparkshell启动脚本时候过程</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            当我们在命令行中输入spark-shell的时候，会自动转为spark shell界面。这个界面中我们可以完成spark的操作。那么，这个过程是怎么进行的呢？
当我们在命令行中输入spark-shell的时候，调用的是spark/bin/spark-shell脚本。以下是spark-shell脚本中的部分代码：
function main() { if $cygwin; then stty -icanonmin 1 -echo &gt; /dev/null 2&gt;&amp;1 export SPARK_SUBMIT_OPTS=&quot;$SPARK_SUBMIT_OPTS -Djline.terminal=unix&quot; &quot;$FWDIR&quot;/bin/spark-submit --class org.apache.spark.repl.Main &quot;${SUBMISSION_OPTS[@]}&quot; spark-shell &quot;${APPLICATION_OPTS[@]}&quot; sttyicanon echo &gt; /dev/null 2&gt;&amp;1 else export SPARK_SUBMIT_OPTS &quot;$FWDIR&quot;/bin/spark-submit --class org.apache.spark.repl.Main &quot;${SUBMISSION_OPTS[@]}&quot; spark-shell &quot;${APPLICATION_OPTS[@]}&quot; fi }  通过上方代码我们可以清楚的看见，main()方法调用了spark-submit脚本。我们前往spark-submit脚本去查看，发现spark- submit又调用了spark-class脚本。
exec &quot;$SPARK_HOME&quot;/bin/spark-class org.apache.spark.deploy.SparkSubmit &quot;${ORIG_ARGS[@]}&quot;  调用了spark-class脚本，并传入若干个参数，其中一个参数是org.apache.spark.deploy.SparkSubmit。spark- class脚本接收到传入的参数，并执行下述语句。
if [ -n &quot;${JAVA_HOME}&quot; ]; then RUNNER=&quot;${JAVA_HOME}/bin/java&quot; else if [ `command -v java` ]; then RUNNER=&quot;java&quot; else echo &quot;JAVA_HOME is not set&quot; &gt;&amp;2 exit 1 fi fi exec &quot;$RUNNER&quot; -cp &quot;$CLASSPATH&quot; $JAVA_OPTS &quot;$@&quot;  上述语句的最后一条表示启动java程序（org.……
        </div>
        <p class="readmore"><a href="https://zaina.newban.cn/posts/spark%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B8%80sparkshell%E5%90%AF%E5%8A%A8%E8%84%9A%E6%9C%AC%E6%97%B6%E5%80%99%E8%BF%87%E7%A8%8B/">阅读全文</a></p>
    </article>
    
    
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/spark%E6%93%8D%E4%BD%9Csparkshell/" title="spark操作sparkshell">spark操作sparkshell</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            读取HDFS 上文件命令，
spark.read.textFile(&ldquo;/user/ssy.097&rdquo;).count
spark.read.wholeTextFiles
SparkContext.wholeTextFiles 能够读取指定目录下的许多小文本文件
spark.read.textFile(&ldquo;/user/ssy.097&rdquo;).map(_.split(&rdquo;\u001,-1&rdquo;)).show //相当于把每一行的内容看做一个map
spark.read.parquet(&ldquo;/user/ssy.097&rdquo;).createOrReplaceTempView(&ldquo;&rdquo;) // createOrReplaceTempView注册为临时表 注册完临时表就可以写sql语句去查询你需要的信息了
val df = sqlContext.read.json(&ldquo;file:///usr/local/spark/examples/src/main/resources/people.json&rdquo;) 读取 JSON 格式的数据
DataFrames 处理结构化数据
df.select(&ldquo;name&rdquo;).show() // 只显示 &ldquo;name&rdquo; 列
df.select(df(&ldquo;name&rdquo;), df(&ldquo;age&rdquo;) + 1).show() // 将 &ldquo;age&rdquo; 加 1
df.filter(df(&ldquo;age&rdquo;) &gt; 21).show() //条件语句
df.groupBy(&ldquo;age&rdquo;).count().show() // groupBy 操作
SQL 语句来进行操作
df.registerTempTable(&ldquo;people&rdquo;) // 将 DataFrame 注册为临时表 people
val result = sqlContext.sql(&ldquo;SELECT name, age FROM people WHERE age &gt;= 13 AND age &lt;= 19&rdquo;) // 执行 SQL 查询……
        </div>
        <p class="readmore"><a href="https://zaina.newban.cn/posts/spark%E6%93%8D%E4%BD%9Csparkshell/">阅读全文</a></p>
    </article>
    
    
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/spark%E6%8F%90%E4%BA%A4submit%E4%BB%BB%E5%8A%A1%E7%9A%84shell%E8%84%9A%E6%9C%AC/" title="spark提交submit任务的shell脚本">spark提交submit任务的shell脚本</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            sudo -u hdfs /usr/hdp/2.6.5.0-292/spark2/bin/spark-submit
–master yarn
–deploy-mode cluster
–driver-cores 1
–driver-memory 2g
–num-executors 3
–executor-memory 1g
–executor-cores 1
–class main.scala.controllers.test.TestDealData
–conf spark.default.parallelism=9
–conf spark.storage.memoryFraction=0.4
–conf spark.shuffle.memoryFraction=0.4
/bigdata/app_jars/bigdataCount.jar……
        </div>
        <p class="readmore"><a href="https://zaina.newban.cn/posts/spark%E6%8F%90%E4%BA%A4submit%E4%BB%BB%E5%8A%A1%E7%9A%84shell%E8%84%9A%E6%9C%AC/">阅读全文</a></p>
    </article>
    
    
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/spark%E5%AE%9A%E5%88%B6%E4%B9%8B%E4%B8%80shell%E5%90%AF%E5%8A%A8/" title="spark定制之一shell启动">spark定制之一shell启动</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            通过定制可以让spark接口更友好。
shell启动脚本：
#!/bin/bash SPARK_HOME=${SPARK_HOME:-/sysdir/spark-1.0.0} StartFile=&quot;${SPARK_HOME}/bin/start.scala&quot; StartStr=&quot;-i:${StartFile}&quot; ExitFile=&quot;${SPARK_HOME}/bin/exit.scala&quot; ExitStr=&quot;&quot; NoExit=0 declare -a args i=0 while [[ $# -gt 0 ]] do case &quot;$1&quot; in -start:*) parafile=$1 StartStr=&quot;-i:${parafile#*:}&quot; ;; -nostart) StartStr=&quot;&quot; ;; -i:*) eval args[${i}]=$1 i=$((${i}+1)) if [[ NoExit -eq 0 ]]; then ExitStr=&quot;-i:${ExitFile}&quot; fi ;; -noexit) NoExit=1 ExitStr=&quot;&quot; ;; *) eval args[${i}]=$1 i=$((${i}+1)) ;; esac shift done ${SPARK_HOME}/bin/spark-shell &quot;${StartStr}&quot; &quot;${args[@]}&quot; &quot;${ExitStr}&quot;  exit.scala很简单，只有一行代码：
sys.exit()……
        </div>
        <p class="readmore"><a href="https://zaina.newban.cn/posts/spark%E5%AE%9A%E5%88%B6%E4%B9%8B%E4%B8%80shell%E5%90%AF%E5%8A%A8/">阅读全文</a></p>
    </article>
    
    
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/spark%E5%AD%A6%E4%B9%A0%E4%B9%8B%E4%BD%BF%E7%94%A8sparkshell%E8%AF%BB%E5%8F%96mysql%E6%95%B0%E6%8D%AE%E5%BA%93/" title="Spark学习之使用sparkshell读取mysql数据库">Spark学习之使用sparkshell读取mysql数据库</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
             启动spark
cd /export/server/spark/sbin
start-all.sh
查看spark
jps
确保有worker进程
 执行命令：
spark-shell &ndash;master spark://node2:7077 &ndash;executor-memory 1g &ndash;total-executor-cores 2 &ndash;jars /export/server/hive/lib/mysql-connector-java-5.1.32.jar &ndash;driver-class-path /export/server/hive/lib/mysql-connector-java-5.1.32.jar
 读取mysql文件，返回一个dataFrame
val mysqlDF = spark.read.format(&ldquo;jdbc&rdquo;).options(Map(&ldquo;url&rdquo; -&gt; &ldquo;jdbc:mysql://192.168.214.101:3306/test&rdquo;, &ldquo;driver&rdquo; -&gt; &ldquo;com.mysql.jdbc.Driver&rdquo;, &ldquo;dbtable&rdquo; -&gt; &ldquo;iplocation&rdquo;, &ldquo;user&rdquo; -&gt; &ldquo;root&rdquo;, &ldquo;password&rdquo; -&gt; &ldquo;root&rdquo;)).load()
  指定mysql服务器地址，用户名和密码，还有表名，数据库名
 查看mysqlDF数据
mysqlDF.show  ……
        </div>
        <p class="readmore"><a href="https://zaina.newban.cn/posts/spark%E5%AD%A6%E4%B9%A0%E4%B9%8B%E4%BD%BF%E7%94%A8sparkshell%E8%AF%BB%E5%8F%96mysql%E6%95%B0%E6%8D%AE%E5%BA%93/">阅读全文</a></p>
    </article>
    
    
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/spark%E5%AD%A6%E4%B9%A0%E4%B9%8Bsparkshell%E5%85%A5%E9%97%A8/" title="spark学习之sparkshell入门">spark学习之sparkshell入门</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            spark shell 是spark自带的一个快速原型开发的工具，在spark目录下面的bin目录下面，
1.进入spark shell ：
[hadoop@localhost bin]$ MASTER=spark://localhost:7077 ./spark-shell  或者直接输入
[hadoop@localhost bin]$ ./spark-shell 14/05/23 15:14:00 INFO spark.HttpServer: Starting HTTP Server 14/05/23 15:14:00 INFO server.Server: jetty-7.x.y-SNAPSHOT 14/05/23 15:14:00 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:53024 Welcome to ____ __ / __/__ ___ _____/ /__ _\ \/ _ \/ _ `/ __/ '_/ /___/ .__/\_,_/_/ /_/\_\ version 0.9.1 /_/ Using Scala version 2.10.3 (Java HotSpot(TM) 64-Bit Server VM, Java 1.7.0_55) Type in expressions to have them evaluated.……
        </div>
        <p class="readmore"><a href="https://zaina.newban.cn/posts/spark%E5%AD%A6%E4%B9%A0%E4%B9%8Bsparkshell%E5%85%A5%E9%97%A8/">阅读全文</a></p>
    </article>
    
    
    



<ol class="page-navigator">
    
    <li class="prev">
        <a href="https://zaina.newban.cn/posts/page/465/">上一页</a>
    </li>
    

    

    
        
        
    
    

    
        
        
        <li >
            <a href="https://zaina.newban.cn/posts/">1</a>
        </li>
        
    
        
        <li>
            <span>...</span>
        </li>
        
    
        
        
        <li >
            <a href="https://zaina.newban.cn/posts/page/464/">464</a>
        </li>
        
    
        
        
        <li >
            <a href="https://zaina.newban.cn/posts/page/465/">465</a>
        </li>
        
    
        
        
        <li  class="current">
            <a href="https://zaina.newban.cn/posts/page/466/">466</a>
        </li>
        
    
        
        
        <li >
            <a href="https://zaina.newban.cn/posts/page/467/">467</a>
        </li>
        
    
        
        
        <li >
            <a href="https://zaina.newban.cn/posts/page/468/">468</a>
        </li>
        
    
        
        <li>
            <span>...</span>
        </li>
        
    
        
        
        <li >
            <a href="https://zaina.newban.cn/posts/page/1960/">1960</a>
        </li>
        
    

    
    

    <li class="next">
        <a href="https://zaina.newban.cn/posts/page/467/">下一页</a>
    </li>
    
</ol>




</div>

                    <footer id="footer">
    <div>
        &copy; 2020 <a href="https://zaina.newban.cn">开发者问答集锦 By </a>
        
    </div>
    <br />
    <div>
        <div class="github-badge">
            <a href="https://gohugo.io/" target="_black" rel="nofollow"><span class="badge-subject">Powered by</span><span class="badge-value bg-blue">Hugo</span></a>
        </div>
        <div class="github-badge">
            <a href="https://www.flysnow.org/" target="_black"><span class="badge-subject">Design by</span><span class="badge-value bg-brightgreen">飞雪无情</span></a>
        </div>
        <div class="github-badge">
            <a href="https://github.com/flysnow-org/maupassant-hugo" target="_black"><span class="badge-subject">Theme</span><span class="badge-value bg-yellowgreen">Maupassant</span></a>
        </div>
    </div>
</footer>



<a id="rocket" href="#top"></a>
<script type="text/javascript" src='/js/totop.js?v=0.0.0' async=""></script>



    <script type="text/javascript" src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script>




                </div>

                <div id="secondary">
    <section class="widget">
        <form id="search" action='https://zaina.newban.cn/search/' method="get" accept-charset="utf-8" target="_blank" _lpchecked="1">
      
      <input type="text" name="q" maxlength="20" placeholder="Search">
      <input type="hidden" name="sitesearch" value="https://zaina.newban.cn">
      <button type="submit" class="submit icon-search"></button>
</form>
    </section>
    
    <section class="widget">
        <h3 class="widget-title">最近文章</h3>
<ul class="widget-list">
    
    <li>
        <a href="https://zaina.newban.cn/posts/001rubyruby%E4%B8%AD%E5%85%A8%E5%B1%80%E5%8F%98%E9%87%8F%E5%AE%9E%E4%BE%8B%E5%8F%98%E9%87%8F%E5%B1%80%E9%83%A8%E5%8F%98%E9%87%8F%E7%B1%BB%E5%8F%98%E9%87%8Fsymbol%E5%AF%B9%E6%AF%94/" title="001rubyRuby中全局变量实例变量局部变量类变量Symbol对比">001rubyRuby中全局变量实例变量局部变量类变量Symbol对比</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/007hadoop%E9%9B%86%E7%BE%A4%E9%85%8D%E7%BD%AEhadoop%E9%9B%86%E7%BE%A4%E7%9A%84%E5%90%AF%E5%8A%A8%E5%92%8C%E6%B5%8B%E8%AF%95ssh%E5%85%8D%E7%99%BB%E9%99%86%E9%85%8D%E7%BD%AEstartallshhdfs%E5%B8%B8%E7%94%A8%E7%9A%84shell/" title="007Hadoop集群配置Hadoop集群的启动和测试SSH免登陆配置startallshhdfs常用的shell">007Hadoop集群配置Hadoop集群的启动和测试SSH免登陆配置startallshhdfs常用的shell</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/009shell%E8%84%9A%E6%9C%AC%E4%B8%8B%E6%9D%A1%E4%BB%B6%E6%B5%8B%E8%AF%95eqne/" title="009Shell脚本下条件测试eqne">009Shell脚本下条件测试eqne</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/00pythonmanagepyshell%E5%92%8Cpython%E7%9A%84%E5%88%86%E6%9E%90/" title="00Pythonmanagepyshell和Python的分析">00Pythonmanagepyshell和Python的分析</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/010zookeeper%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5zookeeper%E7%9A%84%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BAzookeeper%E7%9A%84shell%E5%91%BD%E4%BB%A4/" title="010Zookeeper的基本概念Zookeeper的集群搭建Zookeeper的shell命令">010Zookeeper的基本概念Zookeeper的集群搭建Zookeeper的shell命令</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/018dockerfileshell/" title="018DockerfileSHELL">018DockerfileSHELL</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/01shell%E5%85%A5%E9%97%A801bashshell%E7%89%B9%E6%80%A7/" title="01Shell入门01bashShell特性">01Shell入门01bashShell特性</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/01shell%E5%8F%98%E9%87%8F/" title="01Shell变量">01Shell变量</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/01shell%E5%9F%BA%E7%A1%80%E6%A6%82%E8%BF%B0%E8%84%9A%E6%9C%AC%E6%89%A7%E8%A1%8C%E6%96%B9%E5%BC%8Fbash%E5%9F%BA%E6%9C%AC%E5%8A%9F%E8%83%BD/" title="01Shell基础概述脚本执行方式Bash基本功能">01Shell基础概述脚本执行方式Bash基本功能</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/01shell%E7%BC%96%E7%A8%8Bhelloworld/" title="01shell编程helloworld">01shell编程helloworld</a>
    </li>
    
</ul>
    </section>

    

    <section class="widget">
        <h3 class="widget-title"><a href="/categories">分类</a></h3>
<ul class="widget-list">
    
</ul>
    </section>

    <section class="widget">
        <h3 class="widget-title"><a href="/tags">标签</a></h3>
<div class="tagcloud">
    
    <a href="https://zaina.newban.cn/tags/ruby/">ruby</a>
    
    <a href="https://zaina.newban.cn/tags/shell/">shell</a>
    
</div>
    </section>

    

    <section class="widget">
        <h3 class="widget-title">其它</h3>
        <ul class="widget-list">
            <li><a href="https://zaina.newban.cn/index.xml">文章 RSS</a></li>
        </ul>
    </section>
</div>
            </div>
        </div>
    </div>
</body>

</html>