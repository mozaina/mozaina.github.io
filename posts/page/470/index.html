<!doctype html>
<html lang="en-us">
<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">


    <title>Posts | 开发者问答集锦</title>
    <meta property="og:title" content="Posts - 开发者问答集锦">
    <meta property="og:type" content="article">
        
        
    <meta name="Keywords" content="">
    <meta name="description" content="Posts">
        
    <meta name="author" content="">
    <meta property="og:url" content="https://zaina.newban.cn/posts/">
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">

    <link rel="stylesheet" href='/css/normalize.css'>
    <link rel="stylesheet" href='/css/style.css'>
    <link rel="alternate" type="application/rss+xml+xml" href="https://zaina.newban.cn/posts/index.xml" title="开发者问答集锦" />
    <script type="text/javascript" src="//cdn.bootcdn.net/ajax/libs/jquery/3.4.1/jquery.min.js"></script>

    
    
    
    
    
    
</head>


<body>
    <header id="header" class="clearfix">
    <div class="container">
        <div class="col-group">
            <div class="site-name ">
                
                    <a id="logo" href="https://zaina.newban.cn">
                        开发者问答集锦
                    </a>
                
                
            </div>
            <div>
                <nav id="nav-menu" class="clearfix">
                    <a class="" href="https://zaina.newban.cn">首页</a>
                    
                </nav>
            </div>
        </div>
    </div>
</header>

    <div id="body">
        <div class="container">
            <div class="col-group">

                <div class="col-8" id="main">
                    
<div class="res-cons">
    
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/sparkshell%E5%A6%82%E4%BD%95%E7%B2%98%E8%B4%B4%E6%8D%A2%E8%A1%8C%E4%BB%A3%E7%A0%81/" title="sparkshell如何粘贴换行代码">sparkshell如何粘贴换行代码</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            前言 平时经常性的有一些临时统计数据需求，用hive虽然很方便，但是等待时间有点长，spark- shell成为了我常用的一种方式，不过，一般我都是在IDEA把代码写好，然后复制到spark-shell上面，这个时候就会出现如下问题：
比如我复制如下代码（ 有换行 ）：
sql(sqlText = &quot;select statis_month,count(*) from ods.ods_app_score_m where statis_month &quot; + &quot;like '2019%' group by statis_month&quot;) .show()  spark-shell中竟然显示如下：
scala&gt; sql(sqlText = &quot;select statis_month,count(*) from ods.ods_app_score_m where statis_month &quot; + | &quot;like '2019%' group by statis_month&quot;) res0: org.apache.spark.sql.DataFrame = [statis_month: string, count(1): bigint] scala&gt; .show()  显然sql中的部分，它自动识别了换行，dataset的算子部分它并没有识别出来，就默认为是另一段代码了
如何解决 直接看操作
scala&gt; :paste // Entering paste mode (ctrl-D to finish) sql(sqlText = &quot;select statis_month,count(*) from ods.ods_app_score_m where statis_month &quot; + &quot;like '2019%' group by statis_month&quot;) .……
        </div>
        <p class="readmore"><a href="https://zaina.newban.cn/posts/sparkshell%E5%A6%82%E4%BD%95%E7%B2%98%E8%B4%B4%E6%8D%A2%E8%A1%8C%E4%BB%A3%E7%A0%81/">阅读全文</a></p>
    </article>
    
    
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/sparkshell%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0/" title="sparkshell基础操作持续更新">sparkshell基础操作持续更新</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            1.概述
Spark SQL 是 Spark 处理结构化数据的一个模块。与基础的 Spark RDD API 不同，Spark SQL 提供了 查询结构化数据 及 计算结果 等信息的接口。在内部，Spark SQL 使用这个额外的信息去执行额外的优化。有几种方式可以跟 Spark SQL 进行交互，包括 SQL 和 Dataset API。当使用相同执行引擎进行计算时，无论使用哪种 API / 语言都可以快速的计算。这种统一意味着开发人员能够在基于提供最自然的方式来表达一个给定的 transformation API 之间实现轻松的来回切换不同的 。
2.SQL
Spark SQL 的功能之一是执行 SQL 查询。Spark SQL 也能够被用于从已存在的 Hive 环境中读取数据，不过需要进行hive配置（关于这部分不再我们讨论范围内，请自行百度）。Spark SQL也可以直接从本地读取文件。
3.Datasets 和 DataFrames
一个 Dataset 是一个分布式的数据集合。Dataset 是在 Spark 1.6 中被添加的新接口，它提供了 RDD 的优点（强类型化，能够使用强大的 lambda 函数）与 Spark SQL 优化的执行引擎的好处。一个 Dataset 可以从 JVM 对象来构造并且使用转换功能（map，flatMap，filter，等等）。Dataset API 在 Scala 和 Java 中是可用的。Python 不支持 Dataset API。但是由于 Python 的动态特性，许多 Dataset API 的有点已经可用了（也就是说，你可能通过 name 天生的 row.……
        </div>
        <p class="readmore"><a href="https://zaina.newban.cn/posts/sparkshell%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0/">阅读全文</a></p>
    </article>
    
    
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/sparkshell%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95/" title="sparkshell基本用法">sparkshell基本用法</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            spark-shell 是 scala 语言的 REPL（Read-Eval-Print-Loop，通俗地理解就是命令行模式） 环境，同时针对 spark 做了一些拓展。
 退出 spark-shell：scala&gt; :quit  0. 常见参数  --master spark://xx:7077：指定master节点； --executor-memory 512m：每一个执行节点所需的内存； --total-executor-cores 2：集群用到的 CPU 核数；  1. 启动 spark-shell 的方法  本机
$ spark-shell --master local[N]  $ spark-shell &ndash;master local[*]
  通过设定local[N]参数来启动本地 Spark 集群，其中 N 表示运行的线程数，或者用 * 表示使用机器上所有可用的核数。
在本地模式设定内存，如设置本地进程使用 2GB 内存。
 $ spark-shell --driver-memory 2g --master local[*]   启动在 hdfs 上
 在 yarn 上启动
  如果你有一个 hadoop 集群，并且 hadoop 版本支持 yarn，通过为 Spark master 设定 yarn-client 参数值，便可在集群上启动 spark 作业：……
        </div>
        <p class="readmore"><a href="https://zaina.newban.cn/posts/sparkshell%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95/">阅读全文</a></p>
    </article>
    
    
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/sparkshell%E5%9C%A8yarn%E4%B8%8A%E5%8D%96%E5%BC%84%E5%90%AF%E5%8A%A8%E6%97%B6%E6%8A%A5%E9%94%99thespecifieddatastoredrivercommysqljdbcdriverwasnotfound/" title="sparkshell在yarn上卖弄启动时报错ThespecifieddatastoredrivercommysqljdbcDriverwasnotfound">sparkshell在yarn上卖弄启动时报错ThespecifieddatastoredrivercommysqljdbcDriverwasnotfound</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            在安装好的Hadoop集群和spark集群中安装好hive。但是在利用yarn启动spark-shell时候，报了以下错误：
The specified datastore driver (&ldquo;com.mysql.jdbc.Driver&rdquo;) was not found 。。。。。
这个时候与找不到了MySQL的驱动，所以需要在spark-defaults.conf中进行指定配置。
spark.executor.extraClassPath /home/hadoop/jars/mysql-connector-java-5.1.46-bin.jar spark.driver.extraClassPath /home/hadoop/jars/mysql-connector-java-5.1.46-bin.jar  然后启动即可：
[bing@hadoop102 spark]$ bin/spark-shell &ndash;master yarn
启动成功：……
        </div>
        <p class="readmore"><a href="https://zaina.newban.cn/posts/sparkshell%E5%9C%A8yarn%E4%B8%8A%E5%8D%96%E5%BC%84%E5%90%AF%E5%8A%A8%E6%97%B6%E6%8A%A5%E9%94%99thespecifieddatastoredrivercommysqljdbcdriverwasnotfound/">阅读全文</a></p>
    </article>
    
    
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/sparkshell%E5%92%8Cscala%E9%94%99%E8%AF%AF/" title="sparkshell和scala错误">sparkshell和scala错误</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            ……
        </div>
        <p class="readmore"><a href="https://zaina.newban.cn/posts/sparkshell%E5%92%8Cscala%E9%94%99%E8%AF%AF/">阅读全文</a></p>
    </article>
    
    
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/sparkshell%E5%90%AF%E5%8A%A8%E7%9A%84%E6%97%B6%E5%80%99%E6%8A%A5%E9%94%99errorsparksparkcontexterrorinitializingsparkcontextconnectexception/" title="sparkShell启动的时候报错ERRORsparkSparkContextErrorinitializingSparkContextConnectException">sparkShell启动的时候报错ERRORsparkSparkContextErrorinitializingSparkContextConnectException</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            spark Shell启动的时候报错：ERROR spark.SparkContext: Error initializing SparkContext.ConnectException: Call From hadoop202/192.168.1.202 to hadoop202:9000 failed on connection exception: java.net.ConnectException: 拒绝连接; For more details see:
spark连接HDFS拒绝连接，其实是犯了一个很低级的错误：
hadoop的hdfs-site.xml里面配置的HDFS集群端口是8020，在spark-defaults.conf和spark- env.sh写的却是9000，看似简单的问题对于新手来说却不容易发现。
具体报错信息如下：
ERROR spark.SparkContext: Error initializing SparkContext. java.net.ConnectException: Call From hadoop202/192.168.1.202 to hadoop202:9000 failed on connection exception: java.net.ConnectException: 拒绝连接; For more details see: http://wiki.apache.org/hadoop/ConnectionRefused at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:423) at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792) at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732) at org.apache.hadoop.ipc.Client.call(Client.java:1479) at org.apache.hadoop.ipc.Client.call(Client.java:1412) at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229) at com.sun.proxy.$Proxy15.getFileInfo(Unknown Source) at org.……
        </div>
        <p class="readmore"><a href="https://zaina.newban.cn/posts/sparkshell%E5%90%AF%E5%8A%A8%E7%9A%84%E6%97%B6%E5%80%99%E6%8A%A5%E9%94%99errorsparksparkcontexterrorinitializingsparkcontextconnectexception/">阅读全文</a></p>
    </article>
    
    
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/sparkshell%E5%90%AF%E5%8A%A8%E7%9A%84%E6%97%B6%E5%80%99%E6%8A%A5errorwhileinstantiatingorgapachesparksqlhivehivesessionstatebuilder%E9%94%99%E8%AF%AF/" title="Sparkshell启动的时候报ErrorwhileinstantiatingorgapachesparksqlhiveHiveSessionStateBuilder错误">Sparkshell启动的时候报ErrorwhileinstantiatingorgapachesparksqlhiveHiveSessionStateBuilder错误</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            版权声明：未经允许，随意转载，请附上本文链接谢谢（づ￣3￣）づ╭❤～
https://blog.csdn.net/xiaoduan_/article/details/79815692
Spark-shell启动的时候报java.lang.IllegalArgumentException: Error while instantiating ‘org.apache.spark.sql.hive.HiveSessionStateBuilder’和error: not found: value spark，error: not found: value spark错误
具体报错信息如下
o adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel). 18/04/04 12:14:18 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable 18/04/04 12:14:23 WARN conf.HiveConf: HiveConf of name hive.metastore.scheame.verification does not exist 18/04/04 12:14:26 WARN conf.HiveConf: HiveConf of name hive.metastore.scheame.verification does not exist java.lang.IllegalArgumentException: Error while instantiating 'org.……
        </div>
        <p class="readmore"><a href="https://zaina.newban.cn/posts/sparkshell%E5%90%AF%E5%8A%A8%E7%9A%84%E6%97%B6%E5%80%99%E6%8A%A5errorwhileinstantiatingorgapachesparksqlhivehivesessionstatebuilder%E9%94%99%E8%AF%AF/">阅读全文</a></p>
    </article>
    
    
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/sparkshell%E5%90%AF%E5%8A%A8%E6%8A%A5%E9%94%99%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95/" title="sparkshell启动报错解决办法">sparkshell启动报错解决办法</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            spark-shell启动报错解决办法:
scala版本不兼容问题
这是因为加入了项目依赖库到/usr/cwgis/app/spark/jars/lib/中
删除相关的scala开头的jar文件即可启动spark-shell
[root@node111 ~]# runCmd.sh &quot;rm /usr/cwgis/app/spark/jars/lib/scala*.jar&quot; all  错误: 找不到或无法加载主类 org.apache.spark.deploy.yarn.ExecutorLauncher
SparkException: Yarn application has already ended! It might have been killed or unable to launch application master
spark1.0版本
[hadoop@localhost spark-1.0.1-bin-hadoop2]$ export SPARK_JAR=lib/spark-assembly-1.0.1-hadoop2.2.0.jar  spark other version
创建压缩jar文件方法:
生成一个spark-libs.jar文件，打包/spark/jars目录下所有jar文件和子目录jar文件
jar cv0f spark-libs.jar -C /usr/cwgis/app/spark/jars/ .  在spark-default.conf中设置 spark.yarn.archive=hdfs://mycluster:8020/spark/spark- libs.jar
或者 spark.yarn.jars=hdfs://mycluster:8020/spark/spark-libs.jar……
        </div>
        <p class="readmore"><a href="https://zaina.newban.cn/posts/sparkshell%E5%90%AF%E5%8A%A8%E6%8A%A5%E9%94%99%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95/">阅读全文</a></p>
    </article>
    
    
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/sparkshell%E5%90%AF%E5%8A%A8%E6%8A%A5%E9%94%99%E7%9A%84%E5%9D%91/" title="sparkShell启动报错的坑">sparkShell启动报错的坑</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            部署spark版本2.4.1（包为spark-2.4.1-bin-without-hadoop.tgz）时，启动spark-shell报错
错误信息是：Exception in thread &ldquo;main&rdquo; java.lang.NoSuchMethodError: jline.console.completer.CandidateListCompletionHandler.setPrintSpaceAfterFullCompletion(Z)V，查了一下午，发现可能是spark2.4.1的bug
详细看：
http://mail-archives.apache.org/mod_mbox/spark- issues/201810.mbox/%3CJIRA.13192953.1539979697000.165392.1540166400377@Atlassian.JIRA%3E
解决办法：换到spark2.3.3版本，启动正常……
        </div>
        <p class="readmore"><a href="https://zaina.newban.cn/posts/sparkshell%E5%90%AF%E5%8A%A8%E6%8A%A5%E9%94%99%E7%9A%84%E5%9D%91/">阅读全文</a></p>
    </article>
    
    
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/sparkshell%E5%90%AF%E5%8A%A8%E6%8A%A5%E9%94%99yarnapplicationhasalreadyendeditmighthavebeenkilledorunabletolaunch/" title="sparkshell启动报错YarnapplicationhasalreadyendedItmighthavebeenkilledorunabletolaunch">sparkshell启动报错YarnapplicationhasalreadyendedItmighthavebeenkilledorunabletolaunch</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            前半部分转自：https://www.cnblogs.com/tibit/p/7337045.html （后半原创）
spark-shell不支持yarn cluster，以yarn client方式启动
spark-shell --master=yarn --deploy-mode=client  启动日志，错误信息如下

其中“Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME”，只是一个警告，官方的解释如下：
To make Spark runtime jars accessible from YARN side, you can specify spark.yarn.archive or spark.yarn.jars. For details please refer to Spark Properties. If neither spark.yarn.archive nor spark.yarn.jars is specified, Spark will create a zip file with all jars under$SPARK_HOME/jars and upload it to the distributed cache.……
        </div>
        <p class="readmore"><a href="https://zaina.newban.cn/posts/sparkshell%E5%90%AF%E5%8A%A8%E6%8A%A5%E9%94%99yarnapplicationhasalreadyendeditmighthavebeenkilledorunabletolaunch/">阅读全文</a></p>
    </article>
    
    
    



<ol class="page-navigator">
    
    <li class="prev">
        <a href="https://zaina.newban.cn/posts/page/469/">上一页</a>
    </li>
    

    

    
        
        
    
    

    
        
        
        <li >
            <a href="https://zaina.newban.cn/posts/">1</a>
        </li>
        
    
        
        <li>
            <span>...</span>
        </li>
        
    
        
        
        <li >
            <a href="https://zaina.newban.cn/posts/page/468/">468</a>
        </li>
        
    
        
        
        <li >
            <a href="https://zaina.newban.cn/posts/page/469/">469</a>
        </li>
        
    
        
        
        <li  class="current">
            <a href="https://zaina.newban.cn/posts/page/470/">470</a>
        </li>
        
    
        
        
        <li >
            <a href="https://zaina.newban.cn/posts/page/471/">471</a>
        </li>
        
    
        
        
        <li >
            <a href="https://zaina.newban.cn/posts/page/472/">472</a>
        </li>
        
    
        
        <li>
            <span>...</span>
        </li>
        
    
        
        
        <li >
            <a href="https://zaina.newban.cn/posts/page/1960/">1960</a>
        </li>
        
    

    
    

    <li class="next">
        <a href="https://zaina.newban.cn/posts/page/471/">下一页</a>
    </li>
    
</ol>




</div>

                    <footer id="footer">
    <div>
        &copy; 2020 <a href="https://zaina.newban.cn">开发者问答集锦 By </a>
        
    </div>
    <br />
    <div>
        <div class="github-badge">
            <a href="https://gohugo.io/" target="_black" rel="nofollow"><span class="badge-subject">Powered by</span><span class="badge-value bg-blue">Hugo</span></a>
        </div>
        <div class="github-badge">
            <a href="https://www.flysnow.org/" target="_black"><span class="badge-subject">Design by</span><span class="badge-value bg-brightgreen">飞雪无情</span></a>
        </div>
        <div class="github-badge">
            <a href="https://github.com/flysnow-org/maupassant-hugo" target="_black"><span class="badge-subject">Theme</span><span class="badge-value bg-yellowgreen">Maupassant</span></a>
        </div>
    </div>
</footer>



<a id="rocket" href="#top"></a>
<script type="text/javascript" src='/js/totop.js?v=0.0.0' async=""></script>



    <script type="text/javascript" src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script>




                </div>

                <div id="secondary">
    <section class="widget">
        <form id="search" action='https://zaina.newban.cn/search/' method="get" accept-charset="utf-8" target="_blank" _lpchecked="1">
      
      <input type="text" name="q" maxlength="20" placeholder="Search">
      <input type="hidden" name="sitesearch" value="https://zaina.newban.cn">
      <button type="submit" class="submit icon-search"></button>
</form>
    </section>
    
    <section class="widget">
        <h3 class="widget-title">最近文章</h3>
<ul class="widget-list">
    
    <li>
        <a href="https://zaina.newban.cn/posts/001rubyruby%E4%B8%AD%E5%85%A8%E5%B1%80%E5%8F%98%E9%87%8F%E5%AE%9E%E4%BE%8B%E5%8F%98%E9%87%8F%E5%B1%80%E9%83%A8%E5%8F%98%E9%87%8F%E7%B1%BB%E5%8F%98%E9%87%8Fsymbol%E5%AF%B9%E6%AF%94/" title="001rubyRuby中全局变量实例变量局部变量类变量Symbol对比">001rubyRuby中全局变量实例变量局部变量类变量Symbol对比</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/007hadoop%E9%9B%86%E7%BE%A4%E9%85%8D%E7%BD%AEhadoop%E9%9B%86%E7%BE%A4%E7%9A%84%E5%90%AF%E5%8A%A8%E5%92%8C%E6%B5%8B%E8%AF%95ssh%E5%85%8D%E7%99%BB%E9%99%86%E9%85%8D%E7%BD%AEstartallshhdfs%E5%B8%B8%E7%94%A8%E7%9A%84shell/" title="007Hadoop集群配置Hadoop集群的启动和测试SSH免登陆配置startallshhdfs常用的shell">007Hadoop集群配置Hadoop集群的启动和测试SSH免登陆配置startallshhdfs常用的shell</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/009shell%E8%84%9A%E6%9C%AC%E4%B8%8B%E6%9D%A1%E4%BB%B6%E6%B5%8B%E8%AF%95eqne/" title="009Shell脚本下条件测试eqne">009Shell脚本下条件测试eqne</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/00pythonmanagepyshell%E5%92%8Cpython%E7%9A%84%E5%88%86%E6%9E%90/" title="00Pythonmanagepyshell和Python的分析">00Pythonmanagepyshell和Python的分析</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/010zookeeper%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5zookeeper%E7%9A%84%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BAzookeeper%E7%9A%84shell%E5%91%BD%E4%BB%A4/" title="010Zookeeper的基本概念Zookeeper的集群搭建Zookeeper的shell命令">010Zookeeper的基本概念Zookeeper的集群搭建Zookeeper的shell命令</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/018dockerfileshell/" title="018DockerfileSHELL">018DockerfileSHELL</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/01shell%E5%85%A5%E9%97%A801bashshell%E7%89%B9%E6%80%A7/" title="01Shell入门01bashShell特性">01Shell入门01bashShell特性</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/01shell%E5%8F%98%E9%87%8F/" title="01Shell变量">01Shell变量</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/01shell%E5%9F%BA%E7%A1%80%E6%A6%82%E8%BF%B0%E8%84%9A%E6%9C%AC%E6%89%A7%E8%A1%8C%E6%96%B9%E5%BC%8Fbash%E5%9F%BA%E6%9C%AC%E5%8A%9F%E8%83%BD/" title="01Shell基础概述脚本执行方式Bash基本功能">01Shell基础概述脚本执行方式Bash基本功能</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/01shell%E7%BC%96%E7%A8%8Bhelloworld/" title="01shell编程helloworld">01shell编程helloworld</a>
    </li>
    
</ul>
    </section>

    

    <section class="widget">
        <h3 class="widget-title"><a href="/categories">分类</a></h3>
<ul class="widget-list">
    
</ul>
    </section>

    <section class="widget">
        <h3 class="widget-title"><a href="/tags">标签</a></h3>
<div class="tagcloud">
    
    <a href="https://zaina.newban.cn/tags/ruby/">ruby</a>
    
    <a href="https://zaina.newban.cn/tags/shell/">shell</a>
    
</div>
    </section>

    

    <section class="widget">
        <h3 class="widget-title">其它</h3>
        <ul class="widget-list">
            <li><a href="https://zaina.newban.cn/index.xml">文章 RSS</a></li>
        </ul>
    </section>
</div>
            </div>
        </div>
    </div>
</body>

</html>