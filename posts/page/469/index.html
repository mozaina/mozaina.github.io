<!doctype html>
<html lang="en-us">
<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">


    <title>Posts | 开发者问答集锦</title>
    <meta property="og:title" content="Posts - 开发者问答集锦">
    <meta property="og:type" content="article">
        
        
    <meta name="Keywords" content="">
    <meta name="description" content="Posts">
        
    <meta name="author" content="">
    <meta property="og:url" content="https://zaina.newban.cn/posts/">
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">

    <link rel="stylesheet" href='/css/normalize.css'>
    <link rel="stylesheet" href='/css/style.css'>
    <link rel="alternate" type="application/rss+xml+xml" href="https://zaina.newban.cn/posts/index.xml" title="开发者问答集锦" />
    <script type="text/javascript" src="//cdn.bootcdn.net/ajax/libs/jquery/3.4.1/jquery.min.js"></script>

    
    
    
    
    
    
</head>


<body>
    <header id="header" class="clearfix">
    <div class="container">
        <div class="col-group">
            <div class="site-name ">
                
                    <a id="logo" href="https://zaina.newban.cn">
                        开发者问答集锦
                    </a>
                
                
            </div>
            <div>
                <nav id="nav-menu" class="clearfix">
                    <a class="" href="https://zaina.newban.cn">首页</a>
                    
                </nav>
            </div>
        </div>
    </div>
</header>

    <div id="body">
        <div class="container">
            <div class="col-group">

                <div class="col-8" id="main">
                    
<div class="res-cons">
    
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/sparkshell%E8%AF%BB%E5%8F%96hadoophdfs%E4%B8%8A%E6%96%87%E6%9C%AC%E6%96%87%E4%BB%B6%E7%BB%9F%E8%AE%A1wordcount%E7%9A%84%E6%96%B9%E6%B3%95/" title="sparkshell读取hadoophdfs上文本文件统计wordcount的方法">sparkshell读取hadoophdfs上文本文件统计wordcount的方法</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            spark shell读取hadoop hdfs上文本文件统计wordcount的方法
hellospark文件内容如下所示：
[hadoop3@master app]$ hdfs dfs -cat /spark/hellospark hello spark hello world hello spark!  统计结果为：
scala&gt; count.collect(); res0: Array[(String, Int)] = Array((spark!,1), (spark,1), (hello,3), (world,1))  启动spark-shell控制台
[hadoop3@master app]$ spark-shell 2018-08-17 14:37:57 WARN NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable Setting default log level to &quot;WARN&quot;. To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel). Spark context Web UI available at http://master:4040 Spark context available as 'sc' (master = local[*], app id = local-1534487889053).……
        </div>
        <p class="readmore"><a href="https://zaina.newban.cn/posts/sparkshell%E8%AF%BB%E5%8F%96hadoophdfs%E4%B8%8A%E6%96%87%E6%9C%AC%E6%96%87%E4%BB%B6%E7%BB%9F%E8%AE%A1wordcount%E7%9A%84%E6%96%B9%E6%B3%95/">阅读全文</a></p>
    </article>
    
    
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/sparkshell%E8%84%9A%E6%9C%AC%E6%89%B9%E9%87%8F%E6%89%A7%E8%A1%8C%E5%91%BD%E4%BB%A4%E5%91%BD%E4%BB%A4%E8%A1%8C%E6%89%B9%E9%87%8F%E6%89%A7%E8%A1%8C%E5%91%BD%E4%BB%A4/" title="Sparkshell脚本批量执行命令命令行批量执行命令">Sparkshell脚本批量执行命令命令行批量执行命令</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            spark-shell 执行脚本，批量执行命令
#!/bin/bash source /etc/profile exec spark-shell --name spark-sql-test --executor-cores 8 --executor-memory 8g --num-executors 1 --conf spark.cleaner.ttl=240000 &lt;  ……
        </div>
        <p class="readmore"><a href="https://zaina.newban.cn/posts/sparkshell%E8%84%9A%E6%9C%AC%E6%89%B9%E9%87%8F%E6%89%A7%E8%A1%8C%E5%91%BD%E4%BB%A4%E5%91%BD%E4%BB%A4%E8%A1%8C%E6%89%B9%E9%87%8F%E6%89%A7%E8%A1%8C%E5%91%BD%E4%BB%A4/">阅读全文</a></p>
    </article>
    
    
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/sparkshell%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8/" title="SparkShell简单使用">SparkShell简单使用</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            基础
Spark的shell作为一个强大的交互式数据分析工具，提供了一个简单的方式学习API。它可以使用Scala(在Java虚拟机上运行现有的Java库的一个很好方式)或Python。在Spark目录里使用下面的方式开始运行：
./bin/spark-shell  在Spark Shell中，有一个专有的SparkContext已经为您创建好了，变量名叫做sc。自己创建的SparkContext将无法工作。可以用&ndash; master参数来设置SparkContext要连接的集群，用&ndash; jars来设置需要添加到CLASSPATH的jar包，如果有多个jar包，可以使用逗号分隔符连接它们。例如，在一个拥有4核的环境上运行spark- shell，使用：
./bin/spark-shell --master local[4]  或在CLASSPATH中添加code.jar，使用：
./bin/spark-shell --master local[4] --jars code.jar  可以执行spark-shell &ndash;help获取完整的选项列表。
Spark最主要的抽象是叫Resilient Distributed Dataset(RDD)的弹性分布式集合。RDDs可以使用Hadoop InputFormats(例如HDFS文件)创建，也可以从其他的RDDs转换。让我们在Spark源代码目录里从README.md文本文件中创建一个新的RDD。
scala&gt; val textFile = sc.textFile(&quot;file:///home/hadoop/hadoop/spark/README.md&quot;) 16/07/24 03:30:53 INFO storage.MemoryStore: ensureFreeSpace(217040) called with curMem=321016, maxMem=280248975 16/07/24 03:30:53 INFO storage.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 212.0 KB, free 266.8 MB) 16/07/24 03:30:53 INFO storage.MemoryStore: ensureFreeSpace(20024) called with curMem=538056, maxMem=280248975 16/07/24 03:30:53 INFO storage.……
        </div>
        <p class="readmore"><a href="https://zaina.newban.cn/posts/sparkshell%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8/">阅读全文</a></p>
    </article>
    
    
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/sparkshell%E7%9A%84%E8%AF%8D%E9%A2%91%E7%BB%9F%E8%AE%A1%E5%8E%BB%E9%87%8D%E6%8E%92%E5%BA%8F%E5%8F%8A%E5%90%88%E5%B9%B6%E5%9A%AF%E5%95%8A%E5%9A%AF/" title="sparkshell的词频统计去重排序及合并嚯啊嚯">sparkshell的词频统计去重排序及合并嚯啊嚯</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            Spark技术  RDD算子  本地文件上传至HDFS RDD保存文件至HDFS HDFS保存文件到本地 spark-shell基础操作 wordcount统计 去重distinct 排序sortByKey 合并join 求平均值   RDD算子 RDD有两种类型的操作 ，分别是Transformation（返回一个新的RDD）和Action（返回values）。
1.Transformation：根据已有RDD创建新的RDD数据集build
（1）map(func)：对调用map的RDD数据集中的每个element都使用func，然后返回一个新的RDD，这个返回的数据集是分布式的数据集。
（2）filter(func) ：对调用filter的RDD数据集中的每个元素都使用func，然后返回一个包含使func为true的元素构成的RDD。
（3）flatMap(func)：和map很像，但是flatMap生成的是多个结果。
（4）mapPartitions(func)：和map很像，但是map是每个element，而mapPartitions是每个partition。
（5）mapPartitionsWithSplit(func)：和mapPartitions很像，但是func作用的是其中一个split上，所以func中应该有index。
（6）sample(withReplacement,faction,seed)：抽样。
（7）union(otherDataset)：返回一个新的dataset，包含源dataset和给定dataset的元素的集合。
（8）distinct([numTasks])：返回一个新的dataset，这个dataset含有的是源dataset中的distinct的element。
（9）groupByKey(numTasks)：返回(K,Seq[V])，也就是Hadoop中reduce函数接受的key-valuelist。
（10）reduceByKey(func,[numTasks])：就是用一个给定的reduce func再作用在groupByKey产生的(K,Seq[V])，比如求和，求平均数。
（11）sortByKey([ascending],[numTasks])：按照key来进行排序，是升序还是降序，ascending是boolean类型。
2.Action：在RDD数据集运行计算后，返回一个值或者将结果写入外部存储
（1）reduce(func)：就是聚集，但是传入的函数是两个参数输入返回一个值，这个函数必须是满足交换律和结合律的。
（2）collect()：一般在filter或者足够小的结果的时候，再用collect封装返回一个数组。
（3）count()：返回的是dataset中的element的个数。
（4）first()：返回的是dataset中的第一个元素。
（5）take(n)：返回前n个elements。
（6）takeSample(withReplacement，num，seed)：抽样返回一个dataset中的num个元素，随机种子seed。
（7）saveAsTextFile（path）：把dataset写到一个textfile中，或者HDFS，或者HDFS支持的文件系统中，Spark把每条记录都转换为一行记录，然后写到file中。
（8）saveAsSequenceFile(path)：只能用在key-value对上，然后生成SequenceFile写到本地或者Hadoop文件系统。
（9）countByKey()：返回的是key对应的个数的一个map，作用于一个RDD。
（10）foreach(func)：对dataset中的每个元素都使用func。
本地文件上传至HDFS 在启动spark-shell之前，需将数据文件上传至hdfs上
hadoop fs -mkdir -p /dir hadoop fs -put /data/file /dir  RDD保存文件至HDFS 在spark-shell上操作
rdd.repartition(1).saveAsTextFile(&quot;hdfs://localhost:9000/dir/out.txt&quot;)  HDFS保存文件到本地 mkdir -p /data hadoop fs -get /dir/out.txt/part-00000 /data/ans20_ans1.txt  spark-shell基础操作 使用Spark shell对数据进行WordCount统计、去重、排序、求平均值以及Join操作。……
        </div>
        <p class="readmore"><a href="https://zaina.newban.cn/posts/sparkshell%E7%9A%84%E8%AF%8D%E9%A2%91%E7%BB%9F%E8%AE%A1%E5%8E%BB%E9%87%8D%E6%8E%92%E5%BA%8F%E5%8F%8A%E5%90%88%E5%B9%B6%E5%9A%AF%E5%95%8A%E5%9A%AF/">阅读全文</a></p>
    </article>
    
    
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/sparkshell%E7%9A%84%E4%BD%BF%E7%94%A8/" title="SparkShell的使用">SparkShell的使用</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            前言 前一章中我们介绍了Spark的Standalone模式的安装. 本章我们介绍下Spark Shell操作窗口的基本的安装.
 基本启动与使用 基本算子使用  基本启动与使用  本地启动
进入./bin目录, 使用spark-shell即可启动. 未链接集群, 直接启动了一个Worker结点. 可以通过 http://localhost:4040 进行访问.
localhost:bin Sean$ spark-shell Picked up JAVA_TOOL_OPTIONS: -Dfile.encoding=UTF-8 Picked up JAVA_TOOL_OPTIONS: -Dfile.encoding=UTF-8 Using Spark&rsquo;s default log4j profile: org/apache/spark/log4j-defaults.properties Setting default log level to &ldquo;WARN&rdquo;. To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel). 19/03/29 17:15:00 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform&hellip; using builtin-java classes where applicable 19/03/29 17:15:01 WARN Utils: Your hostname, localhost resolves to a loopback address: 127.……
        </div>
        <p class="readmore"><a href="https://zaina.newban.cn/posts/sparkshell%E7%9A%84%E4%BD%BF%E7%94%A8/">阅读全文</a></p>
    </article>
    
    
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/sparkshell%E7%94%B1%E4%BA%8Escala%E7%BC%96%E8%AF%91%E5%99%A8%E5%8E%9F%E5%9B%A0%E4%B8%8D%E8%83%BD%E6%AD%A3%E5%B8%B8%E5%90%AF%E5%8A%A8/" title="SparkShell由于Scala编译器原因不能正常启动">SparkShell由于Scala编译器原因不能正常启动</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            ……
        </div>
        <p class="readmore"><a href="https://zaina.newban.cn/posts/sparkshell%E7%94%B1%E4%BA%8Escala%E7%BC%96%E8%AF%91%E5%99%A8%E5%8E%9F%E5%9B%A0%E4%B8%8D%E8%83%BD%E6%AD%A3%E5%B8%B8%E5%90%AF%E5%8A%A8/">阅读全文</a></p>
    </article>
    
    
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/sparkshell%E6%95%B0%E6%8D%AE%E6%96%87%E4%BB%B6%E8%AF%BB%E6%88%90%E8%A1%A8%E7%9A%84%E4%B8%A4%E7%A7%8D%E6%96%B9%E5%BC%8F%E7%9B%B8%E5%AF%B9%E8%B7%AF%E5%BE%84hdfsdfsls/" title="sparkshell数据文件读成表的两种方式相对路径hdfsdfsls">sparkshell数据文件读成表的两种方式相对路径hdfsdfsls</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            park SQL应用 Spark Shell启动后，就可以用Spark SQL API执行数据分析查询。 在第一个示例中，我们将从文本文件中加载用户数据并从数据集中创建一个DataFrame对象。然后运行DataFrame函数，执行特定的数据选择查询。 文本文件customers.txt中的内容如下： 100, John Smith, Austin, TX, 78727 200, Joe Johnson, Dallas, TX, 75201 300, Bob Jones, Houston, TX, 77028 400, Andy Davis, San Antonio, TX, 78227 500, James Williams, Austin, TX, 78727 下述代码片段展示了可以在Spark Shell终端执行的Spark SQL命令。 // 首先用已有的Spark Context对象创建SQLContext对象 val sqlContext = new org.apache.spark.sql.SQLContext(sc); // 导入语句，可以隐式地将RDD转化成DataFrame import sqlContext.implicits._ // 创建一个表示客户的自定义类 case class Customer(customer_id: Int, name: String, city: String, state: String, zip_code: String) // 用数据集文本文件创建一个Customer对象的DataFrame val dfCustomers = sc.……
        </div>
        <p class="readmore"><a href="https://zaina.newban.cn/posts/sparkshell%E6%95%B0%E6%8D%AE%E6%96%87%E4%BB%B6%E8%AF%BB%E6%88%90%E8%A1%A8%E7%9A%84%E4%B8%A4%E7%A7%8D%E6%96%B9%E5%BC%8F%E7%9B%B8%E5%AF%B9%E8%B7%AF%E5%BE%84hdfsdfsls/">阅读全文</a></p>
    </article>
    
    
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/sparkshell%E6%8F%90%E4%BA%A4/" title="sparkshell提交">sparkshell提交</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            spark-shell（REPL） （1.）直接运行spark-shell启动的是本地的
命令：
[root@bigdata111 ~]#spark-shell  Spark context available as &lsquo;sc&rsquo; (master = local[*], app id = local-1577740473039).
scala&gt; sc.textFile(&quot;/opt/module/test/one&quot;).flatMap(_.split(&quot; &quot;)).map((_,1)).reduceByKey(_+_).collect res0: Array[(String, Int)] = Array((is,2), (you,1), (plus,1), (name,2), (hadoop,1), (hi,1), (jh,1), (do,1), (HP,1), (hello,1), (java,2), (my,2))  （2.）运行spark-shell &ndash;master spark://bigdata111:7077 启动集群模式的spark-shell
命令：
[root@bigdata111 ~]#spark-shell --master spark://bigdata111:7077  Spark context available as &lsquo;sc&rsquo; (master = spark://bigdata111:7077, app id = app-20191231051535-0002)
scala&gt; sc.textFile(&quot;hdfs://bigdata111:9000/one&quot;).flatMap(_.split(&quot; &quot;)).map((_,1)).reduceByKey(_+_).collect res0: Array[(String, Int)] = Array((is,2), (plus,1), (jh,1), (HP,1), (hello,1), (java,2), (my,2), (you,1), (name,2), (hadoop,1), (hi,1), (do,1)) scala&gt; sc.……
        </div>
        <p class="readmore"><a href="https://zaina.newban.cn/posts/sparkshell%E6%8F%90%E4%BA%A4/">阅读全文</a></p>
    </article>
    
    
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/sparkshell%E5%AE%9E%E9%AA%8C1%E7%AE%80%E5%8D%95%E7%9A%84shell%E6%93%8D%E4%BD%9C/" title="Sparkshell实验1简单的shell操作">Sparkshell实验1简单的shell操作</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            某大学计算机系的成绩，数据格式如下所示：
Tom,DataBase,80
Tom,Algorithm,50
Tom,DataStructure,60
Jim,DataBase,90
Jim,Algorithm,60
Jim,DataStructure,80
……
请根据给定的实验数据，在 spark-shell 中通过编程来计算以下内容：
（1）该系总共有多少学生；
val lines=sc.textFile(&quot;/test/Data1.txt&quot;)//打开文件 val par=lines.map(row=&gt;row.split(&quot;,&quot;)(0))//切分取第一数值 val distinct_par=par.distinct()//去重 distinct_par.count//输出  （2）Tom 同学的总成绩平均分是多少；
val lines=sc.textFile(&quot;/test/Data1.txt&quot;)//打开文件 val pare=lines.filter(row=&gt;row.split(&quot;,&quot;)(0)==&quot;Tom&quot;)//fileter pare.foreach(println)//输出内容 /*Tom,DataBase,26 Tom,Algorithm,12 Tom,OperatingSystem,16 Tom,Python,40 Tom,Software,60*/ pare.map(row=&gt;(row.split(&quot;,&quot;)(0),row.split(&quot;,&quot;)(2).toInt)).mapValues(x=&gt;(x,1)).reduceByKey((x,y)=&gt;(x._1+y._1,x._2+y._2)).mapValues(x=&gt;(x._1/x._2)).collect() //res13: Array[(String, Int)] = Array((Tom,30))  （4）求每名同学的选修的课程门数；
val lines=sc.textFile(&quot;/test/Data1.txt&quot;) val pare=lines.map(row=&gt;(row.spilt(&quot;,&quot;)(0),row.split(&quot;,&quot;)(1))) pare.mapValues(x=&gt;(x,1)).reduceByKey((x,y)=&gt;(&quot; &quot;,x._2+y._2)).mapValues(x =&gt;x._2).foreach(println)  （5）该系 DataBase 课程共有多少人选修；
val pare=lines.filter(row=&gt;row.split(&quot;,&quot;)(1)==&quot;DataBase&quot;) pare.count  （6）各门课程的平均分是多少；
val par=lines.map(row=&gt;(row.split(&quot;,&quot;)(1),row.split(&quot;,&quot;)(2).toInt)) par.mapValues(x=&gt;(x,1)).reduceByKey((x,y)=&gt;(x._1+y._1,x._2+y._2)).mapValues(x=&gt;(x._1/x._2)).collect()  （7）使用累加器计算共有多少人选了 DataBase 这门课
val pare=lines.filter(row=&gt;row.split(&quot;,&quot;)(1)==&quot;DataBase&quot;).map(row=&gt;(row.split(&quot;,&quot;)(1),1)) val accum=sc.longAccumulator(&quot;My Accumulator&quot;) pare.values.foreach(x=&gt;accum.add(x)) accum.value  转载于:https://www.……
        </div>
        <p class="readmore"><a href="https://zaina.newban.cn/posts/sparkshell%E5%AE%9E%E9%AA%8C1%E7%AE%80%E5%8D%95%E7%9A%84shell%E6%93%8D%E4%BD%9C/">阅读全文</a></p>
    </article>
    
    
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/sparkshell%E5%AE%9E%E7%8E%B0pagerank/" title="sparkshell实现PageRank">sparkshell实现PageRank</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            ……
        </div>
        <p class="readmore"><a href="https://zaina.newban.cn/posts/sparkshell%E5%AE%9E%E7%8E%B0pagerank/">阅读全文</a></p>
    </article>
    
    
    



<ol class="page-navigator">
    
    <li class="prev">
        <a href="https://zaina.newban.cn/posts/page/468/">上一页</a>
    </li>
    

    

    
        
        
    
    

    
        
        
        <li >
            <a href="https://zaina.newban.cn/posts/">1</a>
        </li>
        
    
        
        <li>
            <span>...</span>
        </li>
        
    
        
        
        <li >
            <a href="https://zaina.newban.cn/posts/page/467/">467</a>
        </li>
        
    
        
        
        <li >
            <a href="https://zaina.newban.cn/posts/page/468/">468</a>
        </li>
        
    
        
        
        <li  class="current">
            <a href="https://zaina.newban.cn/posts/page/469/">469</a>
        </li>
        
    
        
        
        <li >
            <a href="https://zaina.newban.cn/posts/page/470/">470</a>
        </li>
        
    
        
        
        <li >
            <a href="https://zaina.newban.cn/posts/page/471/">471</a>
        </li>
        
    
        
        <li>
            <span>...</span>
        </li>
        
    
        
        
        <li >
            <a href="https://zaina.newban.cn/posts/page/1960/">1960</a>
        </li>
        
    

    
    

    <li class="next">
        <a href="https://zaina.newban.cn/posts/page/470/">下一页</a>
    </li>
    
</ol>




</div>

                    <footer id="footer">
    <div>
        &copy; 2020 <a href="https://zaina.newban.cn">开发者问答集锦 By </a>
        
    </div>
    <br />
    <div>
        <div class="github-badge">
            <a href="https://gohugo.io/" target="_black" rel="nofollow"><span class="badge-subject">Powered by</span><span class="badge-value bg-blue">Hugo</span></a>
        </div>
        <div class="github-badge">
            <a href="https://www.flysnow.org/" target="_black"><span class="badge-subject">Design by</span><span class="badge-value bg-brightgreen">飞雪无情</span></a>
        </div>
        <div class="github-badge">
            <a href="https://github.com/flysnow-org/maupassant-hugo" target="_black"><span class="badge-subject">Theme</span><span class="badge-value bg-yellowgreen">Maupassant</span></a>
        </div>
    </div>
</footer>



<a id="rocket" href="#top"></a>
<script type="text/javascript" src='/js/totop.js?v=0.0.0' async=""></script>



    <script type="text/javascript" src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script>




                </div>

                <div id="secondary">
    <section class="widget">
        <form id="search" action='https://zaina.newban.cn/search/' method="get" accept-charset="utf-8" target="_blank" _lpchecked="1">
      
      <input type="text" name="q" maxlength="20" placeholder="Search">
      <input type="hidden" name="sitesearch" value="https://zaina.newban.cn">
      <button type="submit" class="submit icon-search"></button>
</form>
    </section>
    
    <section class="widget">
        <h3 class="widget-title">最近文章</h3>
<ul class="widget-list">
    
    <li>
        <a href="https://zaina.newban.cn/posts/001rubyruby%E4%B8%AD%E5%85%A8%E5%B1%80%E5%8F%98%E9%87%8F%E5%AE%9E%E4%BE%8B%E5%8F%98%E9%87%8F%E5%B1%80%E9%83%A8%E5%8F%98%E9%87%8F%E7%B1%BB%E5%8F%98%E9%87%8Fsymbol%E5%AF%B9%E6%AF%94/" title="001rubyRuby中全局变量实例变量局部变量类变量Symbol对比">001rubyRuby中全局变量实例变量局部变量类变量Symbol对比</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/007hadoop%E9%9B%86%E7%BE%A4%E9%85%8D%E7%BD%AEhadoop%E9%9B%86%E7%BE%A4%E7%9A%84%E5%90%AF%E5%8A%A8%E5%92%8C%E6%B5%8B%E8%AF%95ssh%E5%85%8D%E7%99%BB%E9%99%86%E9%85%8D%E7%BD%AEstartallshhdfs%E5%B8%B8%E7%94%A8%E7%9A%84shell/" title="007Hadoop集群配置Hadoop集群的启动和测试SSH免登陆配置startallshhdfs常用的shell">007Hadoop集群配置Hadoop集群的启动和测试SSH免登陆配置startallshhdfs常用的shell</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/009shell%E8%84%9A%E6%9C%AC%E4%B8%8B%E6%9D%A1%E4%BB%B6%E6%B5%8B%E8%AF%95eqne/" title="009Shell脚本下条件测试eqne">009Shell脚本下条件测试eqne</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/00pythonmanagepyshell%E5%92%8Cpython%E7%9A%84%E5%88%86%E6%9E%90/" title="00Pythonmanagepyshell和Python的分析">00Pythonmanagepyshell和Python的分析</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/010zookeeper%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5zookeeper%E7%9A%84%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BAzookeeper%E7%9A%84shell%E5%91%BD%E4%BB%A4/" title="010Zookeeper的基本概念Zookeeper的集群搭建Zookeeper的shell命令">010Zookeeper的基本概念Zookeeper的集群搭建Zookeeper的shell命令</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/018dockerfileshell/" title="018DockerfileSHELL">018DockerfileSHELL</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/01shell%E5%85%A5%E9%97%A801bashshell%E7%89%B9%E6%80%A7/" title="01Shell入门01bashShell特性">01Shell入门01bashShell特性</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/01shell%E5%8F%98%E9%87%8F/" title="01Shell变量">01Shell变量</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/01shell%E5%9F%BA%E7%A1%80%E6%A6%82%E8%BF%B0%E8%84%9A%E6%9C%AC%E6%89%A7%E8%A1%8C%E6%96%B9%E5%BC%8Fbash%E5%9F%BA%E6%9C%AC%E5%8A%9F%E8%83%BD/" title="01Shell基础概述脚本执行方式Bash基本功能">01Shell基础概述脚本执行方式Bash基本功能</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/01shell%E7%BC%96%E7%A8%8Bhelloworld/" title="01shell编程helloworld">01shell编程helloworld</a>
    </li>
    
</ul>
    </section>

    

    <section class="widget">
        <h3 class="widget-title"><a href="/categories">分类</a></h3>
<ul class="widget-list">
    
</ul>
    </section>

    <section class="widget">
        <h3 class="widget-title"><a href="/tags">标签</a></h3>
<div class="tagcloud">
    
    <a href="https://zaina.newban.cn/tags/ruby/">ruby</a>
    
    <a href="https://zaina.newban.cn/tags/shell/">shell</a>
    
</div>
    </section>

    

    <section class="widget">
        <h3 class="widget-title">其它</h3>
        <ul class="widget-list">
            <li><a href="https://zaina.newban.cn/index.xml">文章 RSS</a></li>
        </ul>
    </section>
</div>
            </div>
        </div>
    </div>
</body>

</html>