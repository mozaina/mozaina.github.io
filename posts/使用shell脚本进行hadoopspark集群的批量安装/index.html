<!doctype html>
<html lang="en-us">
<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">


    <title>使用Shell脚本进行HadoopSpark集群的批量安装 | 开发者问答集锦</title>
    <meta property="og:title" content="使用Shell脚本进行HadoopSpark集群的批量安装 - 开发者问答集锦">
    <meta property="og:type" content="article">
        
    <meta property="article:published_time" content='2020-09-02T00:00:00&#43;08:00'>
        
        
    <meta property="article:modified_time" content='2020-09-02T00:00:00&#43;08:00'>
        
    <meta name="Keywords" content="">
    <meta name="description" content="使用Shell脚本进行HadoopSpark集群的批量安装">
        
    <meta name="author" content="">
    <meta property="og:url" content="https://zaina.newban.cn/posts/%E4%BD%BF%E7%94%A8shell%E8%84%9A%E6%9C%AC%E8%BF%9B%E8%A1%8Chadoopspark%E9%9B%86%E7%BE%A4%E7%9A%84%E6%89%B9%E9%87%8F%E5%AE%89%E8%A3%85/">
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">

    <link rel="stylesheet" href='/css/normalize.css'>
    <link rel="stylesheet" href='/css/style.css'>
    <script type="text/javascript" src="//cdn.bootcdn.net/ajax/libs/jquery/3.4.1/jquery.min.js"></script>

    
    
    
    
    
    
</head>


<body>
    <header id="header" class="clearfix">
    <div class="container">
        <div class="col-group">
            <div class="site-name ">
                
                    <a id="logo" href="https://zaina.newban.cn">
                        开发者问答集锦
                    </a>
                
                
            </div>
            <div>
                <nav id="nav-menu" class="clearfix">
                    <a class="" href="https://zaina.newban.cn">首页</a>
                    
                </nav>
            </div>
        </div>
    </div>
</header>

    <div id="body">
        <div class="container">
            <div class="col-group">

                <div class="col-8" id="main">
                    
<div class="res-cons">
    
    <article class="post">
        <header>
            <h1 class="post-title">使用Shell脚本进行HadoopSpark集群的批量安装</h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        
        <div class="post-meta">
            <span id="busuanzi_container_page_pv">|<span id="busuanzi_value_page_pv"></span><span>
                    阅读</span></span>
        </div>
        
        
        <div class="post-content">
            

<p>虽然有一些自动化安装的工具，但是功能越多，越专业的工具，可能也需要越高的学习成本，而我们并非专业运维，但是又必须做这些事情的话，不妨选择用 Shell
脚本来完成集群的安装。</p>

<p>当然了，现在也有很多使用 docker 的做法，安装与部署也非常方便。</p>

<p>整个过程其实很简单，就是对安装过程中的一些手动操作使用 Shell
脚本进行替代。对脚本比较熟悉的话，应该很容易看懂。推荐一个网站，explainshell, 输入 Shell 命令，它会对命令的各部分进行详细的解释。</p>

<p>以下内容虽在 Ubuntu 16.04 试用过，但有些细节可能由于时间因素，难免会有偏差。如有问题，欢迎指正。</p>

<p>其他系统要安装的话可适当参照，步骤上大致相同，只是有些细节需要针对性调整。在所有安装步骤中， <strong>最重要的一步是配置 SSH 无密码登录</strong>
。如果不明白脚本的内容，不要使用我的安装脚本，明白可以抽取部分自用。</p>

<p>对安装过程不太熟的话，建议先跟着厦门大学的教程做：Spark2.1.0入门：Spark的安装和使用，里面涉及了 Hadoop 与 Spark
等各种软件的安装，十分详细，对新手很友好。只有对手动安装的整个过程了然于心，自动化安装才能得心应手。</p>

<p>为了避免因为用户权限要求输入密码的麻烦，以下所有操作均在 <strong>root 用户</strong> ，全新系统环境下执行。</p>

<p>以下所涉及的所有脚本我都已经放到了 GitHub 上，点击 这里
查看，距离脚本写完已经有一段时间，懒得对代码结构进行优化了:)。如果对某个脚本有疑问，可以自行单独拿出来，在本地进行测试与验证。</p>

<p>另外，集群的安装基本上都差不多，这里是陈天奇在 EC2 上安装 yarn 集群的脚本：<a href="https://github.com/tqchen/yarn-ec2">https://github.com/tqchen/yarn-ec2</a>
，有兴趣可以看一下。</p>

<p>用到主要工具有 rsync 和 expect, rsync 用于同步文件，expect 用于处理需要手动输入的情况。</p>

<h3 id="1-安装必要的软件">1. 安装必要的软件</h3>

<p>比如 Java，openssh-server，expect（用于自动处理一些交互, 只在<br />
Master 节点上安装即可），vim 等。在 Master 和 Slave 都要安装这些软件，可以将在配置好 ssh 无密码登录后，将安装脚本同步到各
Slave 进行安装。</p>

<h4 id="基本的软件安装">基本的软件安装</h4>

<p>pre-install.sh:</p>

<pre><code>#!/usr/bin/env bash

# 安装 Vim8，方便修改配置文件
apt install software-properties-common
add-apt-repository ppa:jonathonf/vim
apt update
apt install vim

# 安装 git, expect, openssh-server
apt install git expect openssh-server

# Install Java8
apt install openjdk-8-jre openjdk-8-jdk

# Set JAVA_HOME
JAVA_PATH=$(update-alternatives --list java)
JAVA_HOME=${JAVA_PATH%/jre/bin*}
echo &quot;export JAVA_HOME=$JAVA_HOME&quot; &gt;&gt; &quot;$HOME/.bashrc&quot;
</code></pre>

<h4 id="安装-hadoop">安装 Hadoop</h4>

<p>安装 Hadoop, 大致为 wget 下载 Hadoop，然后解压到 /usr/local/hadoop。install-hadoop.sh:</p>

<pre><code>#!/usr/bin/env bash

HADOOP_DOWNLOAD_URL=https://mirrors.cnnic.cn/apache/hadoop/common/stable/hadoop-2.7.3.tar.gz
HADOOP_TAR_GZ=${HADOOP_DOWNLOAD_URL##*/} # hadoop-2.7.3.tar.gz
HADOOP_VER=${HADOOP_TAR_GZ%%.tar.gz}     # hadoop-2.7.3


if [ ! -d /usr/local/hadoop ]; then
    [ ! -f /tmp/$HADOOP_TAR_GZ ] &amp;&amp; wget -P /tmp --no-check-certificate $HADOOP_DOWNLOAD_URL
    tar -zxf /tmp/$HADOOP_TAR_GZ -C /usr/local
    mv /usr/local/$HADOOP_VER /usr/local/hadoop
else
    echo &quot;&gt;&gt;&gt;&gt; /usr/local/hadoop already exists.&quot;
fi


[ -z &quot;${HADOOP_HOME}&quot; ] &amp;&amp; echo &quot;export HADOOP_HOME=/usr/local/hadoop&quot; &gt;&gt; &quot;$HOME/.bashrc&quot;
[ -z &quot;${HADOOP_COMMON_LIB_NATIVE_DIR}&quot; ] &amp;&amp; echo &quot;export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native&quot; &gt;&gt; &quot;$HOME/.bashrc&quot;


# Set JAVA_HOME in hadoop-env.sh
JAVA_PATH=$(update-alternatives --list java)
JAVA_HOME=${JAVA_PATH%/jre/bin*}
HADOOP_ENV=/usr/local/hadoop/etc/hadoop/hadoop-env.sh
[ -f $HADOOP_ENV ] &amp;&amp; echo &quot;export JAVA_HOME=$JAVA_HOME&quot; &gt;&gt; &quot;$HADOOP_ENV&quot;
</code></pre>

<h4 id="安装-spark">安装 Spark</h4>

<p>安装 Spark，步骤类似，先下载再解压到指定目录，install-spark.sh:</p>

<pre><code>#!/usr/bin/env bash

SPARK_DOWNLOAD_URL=https://d3kbcqa49mib13.cloudfront.net/spark-2.2.0-bin-hadoop2.7.tgz
SPARK_TGZ=${SPARK_DOWNLOAD_URL##*/} # spark-2.2.0-bin-hadoop2.7.tgz
SPARK_VER=${SPARK_TGZ%%.tgz}        # spark-2.2.0-bin-hadoop2.7

if [ ! -d /usr/local/spark ]; then
    [ ! -f /tmp/$SPARK_TGZ ] &amp;&amp; wget -P /tmp --no-check-certificate $SPARK_DOWNLOAD_URL
    tar -zxf /tmp/$SPARK_TGZ -C /usr/local
    mv /usr/local/$SPARK_VER /usr/local/spark
else
    echo &quot;&gt;&gt;&gt;&gt; /usr/local/spark already exists.&quot;
fi
</code></pre>

<h4 id="安装-hbase">安装 HBase</h4>

<p>安装 HBase，install-hbase.sh:</p>

<pre><code>#!/usr/bin/env bash

HBASE_DOWNLOAD_URL=http://apache.mirror.vexxhost.com/hbase/stable/hbase-1.2.6-bin.tar.gz
HBASE_TAR_GZ=${HBASE_DOWNLOAD_URL##*/} # hbase-1.2.6-bin.tar.gz
HBASE_VER=${HBASE_TAR_GZ%%-bin.tar.gz} # hbase-1.2.6

if [ ! -d /usr/local/hbase ]; then
    [ ! -f /tmp/$HBASE_TAR_GZ ] &amp;&amp; wget -P /tmp --no-check-certificate $HBASE_DOWNLOAD_URL
    tar -zxf /tmp/$HBASE_TAR_GZ -C /usr/local
    mv /usr/local/$HBASE_VER /usr/local/hbase
else
    echo &quot;&gt;&gt;&gt;&gt; /usr/local/hbase already exists.&quot;
fi
</code></pre>

<h3 id="2-配置-master-节点可以无密码-ssh-登陆各个-slave-节点">2. 配置 Master 节点可以无密码 SSH 登陆各个 Slave 节点</h3>

<p>这一步非常重要，如果 Master 无法无密码 SSH 登录 Slave，下面进一步的修改 hostname，hosts 等也就无法自动完成了。关于 SSH
登录的原理，可以查看 SSH原理与运用（一）：远程登录。</p>

<p>配置 Master 无密码 SSH 登录 Slave，主要分为两步：</p>

<ol>
<li>在 Master 节点上使用 <code>ssh-keygen</code> 生成无密码的密钥对，主要是 id_rsa 与 id_rsa.pub 两个文件。</li>
</ol>

<p>默认情况下，<code>/root/.ssh</code> 不存在。</p>

<p>由于在操作过程中，可能会需要输入一些信息，我们使用 expect 来完成这些信息的自动输入。可自行了解 expect 的更多内容。</p>

<pre><code># Generate pubkey in remote host
# Usage: generate_pub user host password
generate_pub() {
    local username=$1
    local host=$2
    local password=$3

    expect &lt;&lt; EOF
spawn ssh $username@$host &quot;mkdir -p ~/.ssh; cd ~/.ssh; rm ./id_rsa*; ssh-keygen -t rsa&quot;
while 1 {
    expect {
        &quot;*assword:&quot;                            { send &quot;$password\n&quot; }
        &quot;yes/no*&quot;                              { send &quot;yes\n&quot;       }
        &quot;Enter file in which to save the key*&quot; { send &quot;\n&quot;          }
        &quot;Enter passphrase*&quot;                    { send &quot;\n&quot;          }
        &quot;Enter same passphrase again:&quot;         { send &quot;\n&quot;          }
        &quot;Overwrite (y/n)&quot;                      { send &quot;y\n&quot;         }
        eof                                    { exit               }
    }
}
EOF
}
</code></pre>

<ol>
<li><p>将生成的公钥文件 id_rsa.pub 拷贝到每个 Slave 节点的 <code>~/.ssh/authorized_keys</code>. authorized_keys 默认不存在，需要自行创建。</p>

<h1 id="append-id-rsa-pub-to-authorized-keys-in-remote-host">Append id_rsa.pub to authorized_keys in remote host</h1>

<h1 id="usage-append-pub-user-host-password">Usage: append_pub user host password</h1>

<p>append_pub() {
    src_pub=&ldquo;$(cat /tmp/id_rsa.pub)&rdquo;</p>

<pre><code>local username=$1
local host=$2
local password=$3

expect &lt;&lt; EOF
</code></pre>

<p>spawn ssh $username@$host &ldquo;mkdir -p ~/.ssh; echo $src_pub &gt;&gt; ~/.ssh/authorized_keys; chmod 600 ~/.ssh/authorized_keys&rdquo;
expect {
    &ldquo;<em>assword:&rdquo; { send &ldquo;$password\n&rdquo;; exp_continue }
    &ldquo;yes/no</em>&rdquo;   { send &ldquo;yes\n&rdquo;      ; exp_continue }
    eof         { exit                             }
}
EOF
}</p></li>
</ol>

<p>整个 ssh 无密码登录的内容在 ssh-auto-login.sh 中, slaves.txt 文件放的是 Slave 的 IP 地址，一行一个。</p>

<h3 id="3-批量修改-slave-hostname-和-hosts">3. 批量修改 Slave hostname 和 hosts</h3>

<p>主要是修改两个文件：<code>/etc/hostname</code> 和 <code>/etc/hosts</code>。将 Slave 的 IP 和 hostname 信息存到文件中备用，比如
ip_hostname.txt 和 slaves.txt。实际上只要一个文件 ip_hostname.txt 就够了，目的就是为了提供 Slave
主机的信息而已。</p>

<h4 id="hostname">hostname</h4>

<p>为方便起见，集群中每台机器的 <code>/etc/hostname</code> 都不同，并用 Master，Slave1，Slave2 等进行对 hostname
进行命名，即在每台机器上的 <code>/etc/hostname</code> 分别写入 Master，Slave1，Slave2 等。</p>

<p>以 Master 为例，在 Ubuntu 16.04 下，<code>/etc/hostname</code> 默认为空，直接使用命令 <code>echo &quot;Master&quot; &gt;
/etc/hostname</code> 即可。由于 Slave 节点可能很多，我们用脚本来完成。先准备一个包含 Slave IP 与 hostname
的文件，比如，叫做 <code>ip_hostname.txt</code>, 里面内容如下, 每一行是 <code>IP:hostname</code>：</p>

<pre><code>172.109.109.123:Slave1
172.109.109.124:Slave2
</code></pre>

<p>由于已经配置好 SSH 无密码登录，所以直接使用 SSH 远程执行命令即可。</p>

<pre><code>#!/usr/bin/env bash

# ip_hostname.txt:
# ip:hostname
for line in $(cat ip_hostname.txt); do
    ip=${line%%:*}
    hostname=${line##*:}
    ssh &quot;root@$ip&quot; &quot;echo &quot;$hostname&quot; &gt; /etc/hostname&quot;
done
</code></pre>

<h4 id="hosts">hosts</h4>

<p>hosts 比较简单，在 Master 上修改完 <code>/etc/hosts</code>，随后直接复制到其他 Slave 节点。将 ip_hostname.txt
里面的内容附加到 /etc/hosts 尾部，再加上一个 Master 节点的 IP 与 hostname 即可。</p>

<pre><code>#!/usr/bin/env bash

# ip_hostname.txt:
# ip:hostname
for line in $(cat ip_hostname.txt); do
    ip=${line%%:*}
    hostname=${line##*:}
    echo &quot;$ip    $hostname&quot; &gt;&gt; /etc/hosts
done

MASTER=&quot;MASTER IP&quot;
HOSTANME=&quot;Master&quot;
echo  &quot;$MASTER    $HOSTANME&quot; &gt;&gt; /etc/hosts

echo &quot;/etc/hosts has been upadted!&quot;
</code></pre>

<h3 id="4-复制-master-节点上-usr-local-hadoop-等目录到-slave-节点">4. 复制 Master 节点上 /usr/local/hadoop 等目录到 Slave 节点</h3>

<p>我们打算将 Hadoop，Spark 安装在 <code>/usr/local</code> 目录下，也就是 <code>/usr/local/hadoop</code>
<code>/usr/local/spark</code> 。上面的工作完成后，就可以将 Master 节点下面这些目录复制到各个 Slave 节点。使用 rsync
工具来同步目录。</p>

<p>slaves.txt 里面的内容为各 Slave 的 hostname :</p>

<pre><code>Slave1
Slave2


#!/usr/bin/env bash

DIR='/usr/local/hadoop /usr/local/spark /usr/local/hbase'

for slave in $(cat slaves.txt); do
    rsync -avz $HOME/.bashrc   &quot;root@$slave&quot;:$HOME/.bashrc
    rsync -avz $HOME/bin       &quot;root@$slave&quot;:$HOME
    rsync -avz /etc/hosts      &quot;root@$slave&quot;:/etc

    for dir in $DIR; do
        rsync -avz $dir &quot;root@$slave&quot;:/usr/local
    done
done
</code></pre>

<h3 id="5-同步-hadoop-spark-的配置目录">5. 同步 hadoop/spark 的配置目录</h3>

<p>同步完 Hadoop 和 Spark 完整的目录后，我们还需要对 Hadoop 进行一些配置，比如要进行完全分布式的配置，修改 hdfs-site.xml
等等文件。配置完成后，对这些配置目录也进行同步，比如 Hadoop 下面的 etc ，Spark 与 HBase 下面的 conf 目录。具体配置哪些文件,
修改哪些内容可参看上面的厦门大学安装教程。</p>

<pre><code>#!/usr/bin/env bash

DIR='/usr/local/hadoop/etc /usr/local/spark/conf /usr/local/hbase/conf'

for slave in $(cat slaves.txt); do
    rsync -avz $HOME/.bashrc   &quot;root@$slave&quot;:$HOME/.bashrc
    rsync -avz $HOME/bin       &quot;root@$slave&quot;:$HOME
    rsync -avz /etc/hosts      &quot;root@$slave&quot;:/etc

    for dir in $DIR; do
        rsync -avz $dir &quot;root@$slave&quot;:/usr/local
    done
done
</code></pre>

<p>到这里就差不多了。一两台机器完全可以手动安装，稍微多点的话，写个脚本也还是十分有用的。本文涉及的安装文件已经放在了 GitHub：cluster-auto-
installer .</p>

        </div>

        


        

<div class="post-archive">
    <h2>See Also</h2>
    <ul class="listing">
        
        <li><a href="/posts/007hadoop%E9%9B%86%E7%BE%A4%E9%85%8D%E7%BD%AEhadoop%E9%9B%86%E7%BE%A4%E7%9A%84%E5%90%AF%E5%8A%A8%E5%92%8C%E6%B5%8B%E8%AF%95ssh%E5%85%8D%E7%99%BB%E9%99%86%E9%85%8D%E7%BD%AEstartallshhdfs%E5%B8%B8%E7%94%A8%E7%9A%84shell/">007Hadoop集群配置Hadoop集群的启动和测试SSH免登陆配置startallshhdfs常用的shell</a></li>
        
        <li><a href="/posts/009shell%E8%84%9A%E6%9C%AC%E4%B8%8B%E6%9D%A1%E4%BB%B6%E6%B5%8B%E8%AF%95eqne/">009Shell脚本下条件测试eqne</a></li>
        
        <li><a href="/posts/00pythonmanagepyshell%E5%92%8Cpython%E7%9A%84%E5%88%86%E6%9E%90/">00Pythonmanagepyshell和Python的分析</a></li>
        
        <li><a href="/posts/010zookeeper%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5zookeeper%E7%9A%84%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BAzookeeper%E7%9A%84shell%E5%91%BD%E4%BB%A4/">010Zookeeper的基本概念Zookeeper的集群搭建Zookeeper的shell命令</a></li>
        
        <li><a href="/posts/018dockerfileshell/">018DockerfileSHELL</a></li>
        
    </ul>
</div>


        <div class="post-meta meta-tags">
            
            <ul class="clearfix">
                
                <li><a href='https://zaina.newban.cn/tags/shell'>shell</a></li>
                
            </ul>
            
        </div>
    </article>
    
    

    
    
</div>

                    <footer id="footer">
    <div>
        &copy; 2020 <a href="https://zaina.newban.cn">开发者问答集锦 By </a>
        
    </div>
    <br />
    <div>
        <div class="github-badge">
            <a href="https://gohugo.io/" target="_black" rel="nofollow"><span class="badge-subject">Powered by</span><span class="badge-value bg-blue">Hugo</span></a>
        </div>
        <div class="github-badge">
            <a href="https://www.flysnow.org/" target="_black"><span class="badge-subject">Design by</span><span class="badge-value bg-brightgreen">飞雪无情</span></a>
        </div>
        <div class="github-badge">
            <a href="https://github.com/flysnow-org/maupassant-hugo" target="_black"><span class="badge-subject">Theme</span><span class="badge-value bg-yellowgreen">Maupassant</span></a>
        </div>
    </div>
</footer>


    
    <script type="text/javascript">
        window.MathJax = {
            tex2jax: {
                inlineMath: [['$', '$']],
                processEscapes: true
                }
            };
    </script>
    <script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML' async></script>

<a id="rocket" href="#top"></a>
<script type="text/javascript" src='/js/totop.js?v=0.0.0' async=""></script>



    <script type="text/javascript" src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script>




                </div>

                <div id="secondary">
    <section class="widget">
        <form id="search" action='https://zaina.newban.cn/search/' method="get" accept-charset="utf-8" target="_blank" _lpchecked="1">
      
      <input type="text" name="q" maxlength="20" placeholder="Search">
      <input type="hidden" name="sitesearch" value="https://zaina.newban.cn">
      <button type="submit" class="submit icon-search"></button>
</form>
    </section>
    
    <section class="widget">
        <h3 class="widget-title">最近文章</h3>
<ul class="widget-list">
    
    <li>
        <a href="https://zaina.newban.cn/posts/001rubyruby%E4%B8%AD%E5%85%A8%E5%B1%80%E5%8F%98%E9%87%8F%E5%AE%9E%E4%BE%8B%E5%8F%98%E9%87%8F%E5%B1%80%E9%83%A8%E5%8F%98%E9%87%8F%E7%B1%BB%E5%8F%98%E9%87%8Fsymbol%E5%AF%B9%E6%AF%94/" title="001rubyRuby中全局变量实例变量局部变量类变量Symbol对比">001rubyRuby中全局变量实例变量局部变量类变量Symbol对比</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/007hadoop%E9%9B%86%E7%BE%A4%E9%85%8D%E7%BD%AEhadoop%E9%9B%86%E7%BE%A4%E7%9A%84%E5%90%AF%E5%8A%A8%E5%92%8C%E6%B5%8B%E8%AF%95ssh%E5%85%8D%E7%99%BB%E9%99%86%E9%85%8D%E7%BD%AEstartallshhdfs%E5%B8%B8%E7%94%A8%E7%9A%84shell/" title="007Hadoop集群配置Hadoop集群的启动和测试SSH免登陆配置startallshhdfs常用的shell">007Hadoop集群配置Hadoop集群的启动和测试SSH免登陆配置startallshhdfs常用的shell</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/009shell%E8%84%9A%E6%9C%AC%E4%B8%8B%E6%9D%A1%E4%BB%B6%E6%B5%8B%E8%AF%95eqne/" title="009Shell脚本下条件测试eqne">009Shell脚本下条件测试eqne</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/00pythonmanagepyshell%E5%92%8Cpython%E7%9A%84%E5%88%86%E6%9E%90/" title="00Pythonmanagepyshell和Python的分析">00Pythonmanagepyshell和Python的分析</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/010zookeeper%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5zookeeper%E7%9A%84%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BAzookeeper%E7%9A%84shell%E5%91%BD%E4%BB%A4/" title="010Zookeeper的基本概念Zookeeper的集群搭建Zookeeper的shell命令">010Zookeeper的基本概念Zookeeper的集群搭建Zookeeper的shell命令</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/018dockerfileshell/" title="018DockerfileSHELL">018DockerfileSHELL</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/01shell%E5%85%A5%E9%97%A801bashshell%E7%89%B9%E6%80%A7/" title="01Shell入门01bashShell特性">01Shell入门01bashShell特性</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/01shell%E5%8F%98%E9%87%8F/" title="01Shell变量">01Shell变量</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/01shell%E5%9F%BA%E7%A1%80%E6%A6%82%E8%BF%B0%E8%84%9A%E6%9C%AC%E6%89%A7%E8%A1%8C%E6%96%B9%E5%BC%8Fbash%E5%9F%BA%E6%9C%AC%E5%8A%9F%E8%83%BD/" title="01Shell基础概述脚本执行方式Bash基本功能">01Shell基础概述脚本执行方式Bash基本功能</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/01shell%E7%BC%96%E7%A8%8Bhelloworld/" title="01shell编程helloworld">01shell编程helloworld</a>
    </li>
    
</ul>
    </section>

    

    <section class="widget">
        <h3 class="widget-title"><a href="/categories">分类</a></h3>
<ul class="widget-list">
    
</ul>
    </section>

    <section class="widget">
        <h3 class="widget-title"><a href="/tags">标签</a></h3>
<div class="tagcloud">
    
    <a href="https://zaina.newban.cn/tags/ruby/">ruby</a>
    
    <a href="https://zaina.newban.cn/tags/shell/">shell</a>
    
</div>
    </section>

    

    <section class="widget">
        <h3 class="widget-title">其它</h3>
        <ul class="widget-list">
            <li><a href="https://zaina.newban.cn/index.xml">文章 RSS</a></li>
        </ul>
    </section>
</div>
            </div>
        </div>
    </div>
</body>

</html>