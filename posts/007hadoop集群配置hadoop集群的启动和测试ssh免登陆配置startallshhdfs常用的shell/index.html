<!doctype html>
<html lang="en-us">
<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">


    <title>007Hadoop集群配置Hadoop集群的启动和测试SSH免登陆配置startallshhdfs常用的shell | 开发者问答集锦</title>
    <meta property="og:title" content="007Hadoop集群配置Hadoop集群的启动和测试SSH免登陆配置startallshhdfs常用的shell - 开发者问答集锦">
    <meta property="og:type" content="article">
        
    <meta property="article:published_time" content='2020-09-02T00:00:00&#43;08:00'>
        
        
    <meta property="article:modified_time" content='2020-09-02T00:00:00&#43;08:00'>
        
    <meta name="Keywords" content="">
    <meta name="description" content="007Hadoop集群配置Hadoop集群的启动和测试SSH免登陆配置startallshhdfs常用的shell">
        
    <meta name="author" content="">
    <meta property="og:url" content="https://zaina.newban.cn/posts/007hadoop%E9%9B%86%E7%BE%A4%E9%85%8D%E7%BD%AEhadoop%E9%9B%86%E7%BE%A4%E7%9A%84%E5%90%AF%E5%8A%A8%E5%92%8C%E6%B5%8B%E8%AF%95ssh%E5%85%8D%E7%99%BB%E9%99%86%E9%85%8D%E7%BD%AEstartallshhdfs%E5%B8%B8%E7%94%A8%E7%9A%84shell/">
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">

    <link rel="stylesheet" href='/css/normalize.css'>
    <link rel="stylesheet" href='/css/style.css'>
    <script type="text/javascript" src="//cdn.bootcdn.net/ajax/libs/jquery/3.4.1/jquery.min.js"></script>

    
    
    
    
    
    
</head>


<body>
    <header id="header" class="clearfix">
    <div class="container">
        <div class="col-group">
            <div class="site-name ">
                
                    <a id="logo" href="https://zaina.newban.cn">
                        开发者问答集锦
                    </a>
                
                
            </div>
            <div>
                <nav id="nav-menu" class="clearfix">
                    <a class="" href="https://zaina.newban.cn">首页</a>
                    
                </nav>
            </div>
        </div>
    </div>
</header>

    <div id="body">
        <div class="container">
            <div class="col-group">

                <div class="col-8" id="main">
                    
<div class="res-cons">
    
    <article class="post">
        <header>
            <h1 class="post-title">007Hadoop集群配置Hadoop集群的启动和测试SSH免登陆配置startallshhdfs常用的shell</h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        
        <div class="post-meta">
            <span id="busuanzi_container_page_pv">|<span id="busuanzi_value_page_pv"></span><span>
                    阅读</span></span>
        </div>
        
        
        <div class="post-content">
            

<p>Hadoop集群配置<br />
<a href="https://img.it610.com/image/info8/a722175c1db34047907e1ef40dd1c0c4.png"><img src="https://img.it610.com/image/info8/a722175c1db34047907e1ef40dd1c0c4.png" alt="007 Hadoop集群配置 Hadoop集群的启动和测试 SSH免登陆配置（ start-all.sh）
hdfs常用的shell_第1张图片" /></a><br />
三种模式 本地 伪分布式 全分布式<br />
伪分布式 看官网配置 比较简单？<a href="https://hadoop.apache.org/docs/current/hadoop-project-">https://hadoop.apache.org/docs/current/hadoop-project-</a>
dist/hadoop-common/SingleCluster.html#Standalone_Operation</p>

<p>全分布式<br />
Fully-Distributed Mode<br />
<a href="http://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-">http://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-</a>
common/ClusterSetup.html<br />
<a href="https://img.it610.com/image/info8/bdd9e08298d54a2c98aca34daef2f041.jpg"><img src="https://img.it610.com/image/info8/bdd9e08298d54a2c98aca34daef2f041.jpg" alt="007 Hadoop集群配置 Hadoop集群的启动和测试 SSH免登陆配置（ start-all.sh）
hdfs常用的shell_第2张图片" /></a><br />
先安装Java<br />
再安装与Java版本相匹配的Hadoop版本</p>

<p>hadoop全分布式环境搭建<br />
规划：<br />
<a href="https://img.it610.com/image/info8/2e61f89d5e7b4fd4b34486755aa43ff9.jpg"><img src="https://img.it610.com/image/info8/2e61f89d5e7b4fd4b34486755aa43ff9.jpg" alt="007 Hadoop集群配置 Hadoop集群的启动和测试 SSH免登陆配置（ start-all.sh）
hdfs常用的shell_第3张图片" /></a><br />
<a href="https://img.it610.com/image/info8/5a56d53181c249d385aef762db4c9d0f.jpg"><img src="https://img.it610.com/image/info8/5a56d53181c249d385aef762db4c9d0f.jpg" alt="007 Hadoop集群配置 Hadoop集群的启动和测试 SSH免登陆配置（ start-all.sh）
hdfs常用的shell_第4张图片" /></a><br />
<a href="https://img.it610.com/image/info8/1c18bf32e21c4319bac2fd8eb4ee1122.jpg"><img src="https://img.it610.com/image/info8/1c18bf32e21c4319bac2fd8eb4ee1122.jpg" alt="007 Hadoop集群配置 Hadoop集群的启动和测试 SSH免登陆配置（ start-all.sh）
hdfs常用的shell_第5张图片" /></a><br />
<a href="https://img.it610.com/image/info8/c913f66f7f61491290d38ad5194c2c40.jpg"><img src="https://img.it610.com/image/info8/c913f66f7f61491290d38ad5194c2c40.jpg" alt="007 Hadoop集群配置 Hadoop集群的启动和测试 SSH免登陆配置（ start-all.sh）
hdfs常用的shell_第6张图片" /></a><br />
通过前面的学习<br />
Java的jdk和单机版hadoop已经安装<br />
ssh先不安装<br />
然后进行<br />
还是规划<br />
<a href="https://img.it610.com/image/info8/66970a7ae6264a7aa7074edb25ef127e.jpg"><img src="https://img.it610.com/image/info8/66970a7ae6264a7aa7074edb25ef127e.jpg" alt="007 Hadoop集群配置 Hadoop集群的启动和测试 SSH免登陆配置（ start-all.sh）
hdfs常用的shell_第7张图片" /></a><br />
<a href="https://img.it610.com/image/info8/9ba930153e1344ecb4057e0545e45bb5.jpg"><img src="https://img.it610.com/image/info8/9ba930153e1344ecb4057e0545e45bb5.jpg" alt="007 Hadoop集群配置 Hadoop集群的启动和测试 SSH免登陆配置（ start-all.sh）
hdfs常用的shell_第8张图片" /></a><br />
即<br />
<a href="https://img.it610.com/image/info8/077201ac4be5424bab502dd72a4dc286.jpg"><img src="https://img.it610.com/image/info8/077201ac4be5424bab502dd72a4dc286.jpg" alt="007 Hadoop集群配置 Hadoop集群的启动和测试 SSH免登陆配置（ start-all.sh）
hdfs常用的shell_第9张图片" /></a><br />
我的是192.168.37.111</p>

<hr />

<p>开始配置hadoop<br />
1.先进入目录然后配置 cd $HADOOP_HOME</p>

<pre><code>vi ./etc/hadoop/hadoop-env.sh
</code></pre>

<p>这个以前配过了<br />
<a href="https://img.it610.com/image/info8/92de39b2e83a4e72bb78b4afad6441e6.jpg"><img src="https://img.it610.com/image/info8/92de39b2e83a4e72bb78b4afad6441e6.jpg" alt="007 Hadoop集群配置 Hadoop集群的启动和测试 SSH免登陆配置（ start-all.sh）
hdfs常用的shell_第10张图片" /></a></p>

<p>2.hadoop的核心配置文件</p>

<pre><code>vi ./etc/hadoop/core-site.xml 
</code></pre>

<p>官网上是2.9.2版本 131072 我们这里先使用4096</p>

<p>进入后有一个空的configuration 写在这里面 配三个东西</p>

<p><a href="https://img.it610.com/image/info8/1e036bf1ce7a4f6f836f0f1e6301e72e.jpg"><img src="https://img.it610.com/image/info8/1e036bf1ce7a4f6f836f0f1e6301e72e.jpg" alt="007 Hadoop集群配置 Hadoop集群的启动和测试 SSH免登陆配置（ start-all.sh）
hdfs常用的shell_第11张图片" /></a></p>

<pre><code>fs.defaultFS
hdfs://hadoop01:9000



io.file.buffer.size
4096



hadoop.tmp.dir
/home/bigdata/tmp
</code></pre>

<p>3.配置hdfs模块相关信息</p>

<pre><code>vi ./etc/hadoop/hdfs-site.xml





dfs.replication
3



dfs.block.size
134217728



dfs.namenode.name.dir
/home/hadoopdata/dfs/name



dfs.datanode.dir
/home/hadoopdata/dfs/data



fs.checkpoint.dir
/home/hadoopdata/checkpoint/dfs/cname



dfs.http.address
hadoop01:50070



dfs.secondary.http.address
hadoop01:50090



dfs.webhdfs.enabled
false



dfs.permissions
false
</code></pre>

<ol>
<li></li>
</ol>

<p>需要先将文件改个名 再去配置内容</p>

<p>mv ./etc/hadoop/mapred-site.xml.template ./etc/hadoop/mapred-site.xml<br />
<a href="https://img.it610.com/image/info8/20a2bac1e779439aa7344ecea84656d4.jpg"><img src="https://img.it610.com/image/info8/20a2bac1e779439aa7344ecea84656d4.jpg" alt="在这里插入图片描述" /></a><br />
现在完成规划<br />
01后添加NameNode DataNode resourcemanager nodemanager<br />
02 03添加DataNode nodemanager<br />
<a href="https://img.it610.com/image/info8/0ec17b43da5341e59380f788d48a0993.jpg"><img src="https://img.it610.com/image/info8/0ec17b43da5341e59380f788d48a0993.jpg" alt="007 Hadoop集群配置 Hadoop集群的启动和测试 SSH免登陆配置（ start-all.sh）
hdfs常用的shell_第12张图片" /></a></p>

<pre><code>mapreduce.framework.name
yarn
true



mapreduce.jobhistory.address
hadoop01:10020



mapreduce.jobhistory.webapp.address
hadoop01:19888
</code></pre>

<ol>
<li><p>vi ./etc/hadoop/yarn-site.xml</p>

<p>yarn.resourcemanager.hostname
hadoop01</p>

<p>yarn.nodemanager.aux-services
mapreduce_shuffle</p>

<p>yarn.resourcemanager.address
hadoop01:8032</p>

<p>yarn.resourcemanager.scheduler.address
hadoop01:8030</p>

<p>yarn.resourcemanager.resource-tracker.address
hadoop01:8031</p>

<p>yarn:resourcemanager.admin.address
hadoop01:8033</p>

<p>yarn:resourcemanager.webapp.address
hadoop01:8088</p></li>
</ol>

<p>前面那几个都写到配置文件的configuration里面</p>

<ol>
<li><p>vi ./etc/hadoop/slaves</p></li>
</ol>

<p>打开后 删除里面的localhost<br />
然后写入</p>

<pre><code>hadoop01
hadoop02
hadoop03
</code></pre>

<hr />

<p>这样六个配置文件就算弄完了<br />
<a href="https://img.it610.com/image/info8/934a7a14cbc946f2b1fe43ae9bc31171.jpg"><img src="https://img.it610.com/image/info8/934a7a14cbc946f2b1fe43ae9bc31171.jpg" alt="007 Hadoop集群配置 Hadoop集群的启动和测试 SSH免登陆配置（ start-all.sh）
hdfs常用的shell_第13张图片" /></a><br />
<a href="https://img.it610.com/image/info8/d29bd27aac304ca6aa21e1bb0ed55cf6.jpg"><img src="https://img.it610.com/image/info8/d29bd27aac304ca6aa21e1bb0ed55cf6.jpg" alt="007 Hadoop集群配置 Hadoop集群的启动和测试 SSH免登陆配置（ start-all.sh）
hdfs常用的shell_第14张图片" /></a></p>

<hr />

<p>下一步</p>

<h2 id="远程分发到别的服务器上面">远程分发到别的服务器上面</h2>

<p>首先 先把 <strong>hadoop02 03</strong> 的hadoop文件删掉</p>

<p>所以<br />
使用</p>

<pre><code>rm -rf /usr/local/hadoop-2.7.1/
</code></pre>

<p>删除完成后检查一下是否还有<br />
结果02 03都没了hadoop了<br />
<a href="https://img.it610.com/image/info8/e157a9be70bc4710b18e17b269688d21.jpg"><img src="https://img.it610.com/image/info8/e157a9be70bc4710b18e17b269688d21.jpg" alt="007 Hadoop集群配置 Hadoop集群的启动和测试 SSH免登陆配置（ start-all.sh）
hdfs常用的shell_第15张图片" /></a><br />
此时这两个which hadoop是没了的<br />
<img src="https://img.it610.com/image/info8/42ee7aa4591d4c5a993f0e0459cfbf96.jpg" alt="在这里插入图片描述" /><br />
然后可以分发了</p>

<pre><code>scp -r ../hadoop-2.7.1/ hadoop02:/usr/local/
</code></pre>

<p>如果出现找不到hadoop02的问题 需要配置hosts<br />
将02 03 写上<br />
<a href="https://img.it610.com/image/info8/18949c8ff9d8489cb760b655412f832f.jpg"><img src="https://img.it610.com/image/info8/18949c8ff9d8489cb760b655412f832f.jpg" alt="007 Hadoop集群配置 Hadoop集群的启动和测试 SSH免登陆配置（ start-all.sh）
hdfs常用的shell_第16张图片" /></a><br />
<img src="https://img.it610.com/image/info8/89cefbfceb4f4d279563c30b3b59188d.jpg" alt="在这里插入图片描述" /><br />
这里我们之前是弄了的 只是说明一下</p>

<p>可能会让你输入yes 输入就行<br />
然后输入hadoop02的密码root<br />
然后就开始了<br />
可能比较慢<br />
相同的方法搞到03上去<br />
<a href="https://img.it610.com/image/info8/ad3b0ff9dc2642c98633916cbbc7349b.jpg"><img src="https://img.it610.com/image/info8/ad3b0ff9dc2642c98633916cbbc7349b.jpg" alt="007 Hadoop集群配置 Hadoop集群的启动和测试 SSH免登陆配置（ start-all.sh）
hdfs常用的shell_第17张图片" /></a></p>

<p>哎 这里视频说 你要嫌慢 可以删除 01里面的hadoop的学习文档 再传输<br />
（如果已经传输了 可是执行rm的操作 删除学习文档后重新传输）<br />
其实差不了几秒 我就没弄<br />
<a href="https://img.it610.com/image/info8/c790bd601cbc4f5794c1e116356a2b72.jpg"><img src="https://img.it610.com/image/info8/c790bd601cbc4f5794c1e116356a2b72.jpg" alt="007 Hadoop集群配置 Hadoop集群的启动和测试 SSH免登陆配置（ start-all.sh）
hdfs常用的shell_第18张图片" /></a></p>

<p>结束<br />
上面的操作即这两句话<br />
<a href="https://img.it610.com/image/info8/244519d005cc4ef485a1b749c40b8a10.jpg"><img src="https://img.it610.com/image/info8/244519d005cc4ef485a1b749c40b8a10.jpg" alt="在这里插入图片描述" /></a></p>

<hr />

<h2 id="然后">然后</h2>

<p>我们就可以启动我们的hadoop集群了</p>

<p>不过还有好多工作要做<br />
1.启动之前格式化 只需要一次即可<br />
在namenode服务器上 即hadoop01<br />
<a href="https://img.it610.com/image/info8/2061217b2c4f4683aa04c3aab703017b.jpg"><img src="https://img.it610.com/image/info8/2061217b2c4f4683aa04c3aab703017b.jpg" alt="007 Hadoop集群配置 Hadoop集群的启动和测试 SSH免登陆配置（ start-all.sh）
hdfs常用的shell_第19张图片" /></a><br />
<a href="https://img.it610.com/image/info8/1493455777754dc09ac9782388ec0596.jpg"><img src="https://img.it610.com/image/info8/1493455777754dc09ac9782388ec0596.jpg" alt="007 Hadoop集群配置 Hadoop集群的启动和测试 SSH免登陆配置（ start-all.sh）
hdfs常用的shell_第20张图片" /></a><br />
格式化之前<br />
<a href="https://img.it610.com/image/info8/47735ce62a954c6e98e39d744c7a7551.jpg"><img src="https://img.it610.com/image/info8/47735ce62a954c6e98e39d744c7a7551.jpg" alt="007 Hadoop集群配置 Hadoop集群的启动和测试 SSH免登陆配置（ start-all.sh）
hdfs常用的shell_第21张图片" /></a><br />
使用<code>hadoop namenode -format</code>语句格式化（在01上使用）<br />
<a href="https://img.it610.com/image/info8/4e8e5f8518fd4978aa744083bf886ca6.jpg"><img src="https://img.it610.com/image/info8/4e8e5f8518fd4978aa744083bf886ca6.jpg" alt="007 Hadoop集群配置 Hadoop集群的启动和测试 SSH免登陆配置（ start-all.sh）
hdfs常用的shell_第22张图片" /></a><br />
看到这一句时表示格式化成功<br />
格式化之后 home目录出现hadoopdata文件目录<br />
<a href="https://img.it610.com/image/info8/678c9b3eda304ebda5e1acd01f6b5191.jpg"><img src="https://img.it610.com/image/info8/678c9b3eda304ebda5e1acd01f6b5191.jpg" alt="007 Hadoop集群配置 Hadoop集群的启动和测试 SSH免登陆配置（ start-all.sh）
hdfs常用的shell_第23张图片" /></a><br />
然后一层一层的往下看<br />
最下面就是我们的元数据<br />
<a href="https://img.it610.com/image/info8/0735eb860f434f6ca7dac4a6cf443cd0.jpg"><img src="https://img.it610.com/image/info8/0735eb860f434f6ca7dac4a6cf443cd0.jpg" alt="007 Hadoop集群配置 Hadoop集群的启动和测试 SSH免登陆配置（ start-all.sh）
hdfs常用的shell_第24张图片" /></a></p>

<hr />

<p>格式化之后就可以正常的启动服务了<br />
这里一共有三种启动方式<br />
1.全启动<br />
2.模块启动<br />
3单个进程启动<br />
<a href="https://img.it610.com/image/info8/6ed7caf735cf44229ae87dd5da3b2f29.jpg"><img src="https://img.it610.com/image/info8/6ed7caf735cf44229ae87dd5da3b2f29.jpg" alt="007 Hadoop集群配置 Hadoop集群的启动和测试 SSH免登陆配置（ start-all.sh）
hdfs常用的shell_第25张图片" /></a></p>

<p>注意此时啊<br />
02 03 的/home/下面是没有hadoop的相关目录的<br />
只有01有 因为只有01有元数据<br />
当真正写数据的时候 02 03才会创建相应目录</p>

<h2 id="我们使用">我们使用</h2>

<p>./sbin/start-dfs.sh 启动试试</p>

<p>过程中需要输入yes<br />
密码<br />
输好几次<br />
所以很繁琐 在我们配置ssh免密登录之后就可以不用这么麻烦了<br />
<a href="https://img.it610.com/image/info8/4ce3d269f292456ab4525986973554d9.jpg"><img src="https://img.it610.com/image/info8/4ce3d269f292456ab4525986973554d9.jpg" alt="007 Hadoop集群配置 Hadoop集群的启动和测试 SSH免登陆配置（ start-all.sh）
hdfs常用的shell_第26张图片" /></a><br />
我们看到它停在02这个地方<br />
所以我们到02看看<br />
使用jps命令<br />
<a href="https://img.it610.com/image/info8/aa33753581e644c0b7f75985c01a97bc.jpg"><img src="https://img.it610.com/image/info8/aa33753581e644c0b7f75985c01a97bc.jpg" alt="007 Hadoop集群配置 Hadoop集群的启动和测试 SSH免登陆配置（ start-all.sh）
hdfs常用的shell_第27张图片" /></a><br />
判断是否启动成功使用jps 查看java进程的例子<br />
这里啊 我启动了两编 视频中一遍就成功了<br />
我第一遍01和03的jps都没有DataNode<br />
又运行了一遍启动命令才可以<br />
结果如下</p>

<p>三个的DataNode都启动了<br />
01的SecondaryNameNode也启动了<br />
01<br />
<a href="https://img.it610.com/image/info8/0ebac903145e4f128fbdeb74bc553d96.jpg"><img src="https://img.it610.com/image/info8/0ebac903145e4f128fbdeb74bc553d96.jpg" alt="007 Hadoop集群配置 Hadoop集群的启动和测试 SSH免登陆配置（ start-all.sh）
hdfs常用的shell_第28张图片" /></a><br />
02<br />
<a href="https://img.it610.com/image/info8/e61940d4ca2e481a8938b2af6a9a2869.jpg"><img src="https://img.it610.com/image/info8/e61940d4ca2e481a8938b2af6a9a2869.jpg" alt="007 Hadoop集群配置 Hadoop集群的启动和测试 SSH免登陆配置（ start-all.sh）
hdfs常用的shell_第29张图片" /></a><br />
03<br />
<a href="https://img.it610.com/image/info8/9c625efc26c34e58826b179b336f2c61.jpg"><img src="https://img.it610.com/image/info8/9c625efc26c34e58826b179b336f2c61.jpg" alt="007 Hadoop集群配置 Hadoop集群的启动和测试 SSH免登陆配置（ start-all.sh）
hdfs常用的shell_第30张图片" /></a></p>

<h2 id="测试">测试</h2>

<p>1.如上jps命令查看 (查看进程是否安装规划启动起来)<br />
2.访问192.168.37.111:50070（查看对应模块的web ui监控是否正常）<br />
3.上传和下载文件（测试hsfs）<br />
然后跑一个MapReduce的作业</p>

<p><a href="https://img.it610.com/image/info8/b8e7587f3e2a4621935572b7c29e5845.jpg"><img src="https://img.it610.com/image/info8/b8e7587f3e2a4621935572b7c29e5845.jpg" alt="007 Hadoop集群配置 Hadoop集群的启动和测试 SSH免登陆配置（ start-all.sh）
hdfs常用的shell_第31张图片" /></a><br />
上传测试<br />
先使用hdfs dfs -ls / （查看根目录是否有文件 结果是没有）<br />
<a href="https://img.it610.com/image/info8/f85139f932fa451e8b46cca4753cced1.jpg"><img src="https://img.it610.com/image/info8/f85139f932fa451e8b46cca4753cced1.jpg" alt="007 Hadoop集群配置 Hadoop集群的启动和测试 SSH免登陆配置（ start-all.sh）
hdfs常用的shell_第32张图片" /></a><br />
然后看一下当前目录下有啥 ll 看到有个Readme txt 就它了 把它传上去<br />
使用<br />
hdfs dfs -put ./README.txt /<br />
上传至根目录<br />
然后再次查看<br />
结果显示有了那个文件<br />
上传成功</p>

<hr />

<p>然后我们看一下其中内容</p>

<h2 id="注意-hdfs没有相对目录-不能打点-只能使用绝对路径">注意 hdfs没有相对目录 不能打点. 只能使用绝对路径</h2>

<p>使用hdfs dfs -cat /README.txt<br />
结果如下 内容就读出来了<br />
<a href="https://img.it610.com/image/info8/d753f779440e4d78b8b77e7422319792.jpg"><img src="https://img.it610.com/image/info8/d753f779440e4d78b8b77e7422319792.jpg" alt="007 Hadoop集群配置 Hadoop集群的启动和测试 SSH免登陆配置（ start-all.sh）
hdfs常用的shell_第33张图片" /></a></p>

<p>至此 hdfs模块的集群就算是搞完了</p>

<hr />

<h2 id="接下来我们看-yarn模块">接下来我们看 yarn模块</h2>

<p>还是那三步<br />
<a href="https://img.it610.com/image/info8/eeeb428a5a494a738a7ae0b755ecd7f8.jpg"><img src="https://img.it610.com/image/info8/eeeb428a5a494a738a7ae0b755ecd7f8.jpg" alt="007 Hadoop集群配置 Hadoop集群的启动和测试 SSH免登陆配置（ start-all.sh）
hdfs常用的shell_第34张图片" /></a><br />
start-yarn.sh</p>

<h2 id="启动起来">启动起来</h2>

<p>然后是输入三遍密码</p>

<h2 id="然后使用jps看一下-看看是否nodemanager启动了">然后使用jps看一下 看看是否NodeManager启动了</h2>

<p>其中 01 多启动了 ResourceManager<br />
<a href="https://img.it610.com/image/info8/259ed1622aa94f8f8ba95099cce3e111.jpg"><img src="https://img.it610.com/image/info8/259ed1622aa94f8f8ba95099cce3e111.jpg" alt="007 Hadoop集群配置 Hadoop集群的启动和测试 SSH免登陆配置（ start-all.sh）
hdfs常用的shell_第35张图片" /></a><br />
<a href="https://img.it610.com/image/info8/6febcc1b8e0a4aee8b1df5c788b5a4cc.jpg"><img src="https://img.it610.com/image/info8/6febcc1b8e0a4aee8b1df5c788b5a4cc.jpg" alt="007 Hadoop集群配置 Hadoop集群的启动和测试 SSH免登陆配置（ start-all.sh）
hdfs常用的shell_第36张图片" /></a><br />
<a href="https://img.it610.com/image/info8/f5d26a81fa6b4d81ac9b45d16664fd03.jpg"><img src="https://img.it610.com/image/info8/f5d26a81fa6b4d81ac9b45d16664fd03.jpg" alt="007 Hadoop集群配置 Hadoop集群的启动和测试 SSH免登陆配置（ start-all.sh）
hdfs常用的shell_第37张图片" /></a></p>

<hr />

<p>成功启动了三个的NodeManager</p>

<p>这个符合规划</p>

<ul>
<li><p>./sbin/start-dfs.sh启动hdfs模块的DataManager和SecondaryManager</p></li>

<li><p>start-yarn.sh 启动yarn模块的 NodeManager 和 ResourceManager</p></li>
</ul>

<hr />

<p>测试第二步<br />
192.168.37.111:8088<br />
也成功了<br />
<a href="https://img.it610.com/image/info8/9d042161047e444a9e8657b158eaa083.jpg"><img src="https://img.it610.com/image/info8/9d042161047e444a9e8657b158eaa083.jpg" alt="007 Hadoop集群配置 Hadoop集群的启动和测试 SSH免登陆配置（ start-all.sh）
hdfs常用的shell_第38张图片" /></a><br />
<a href="https://img.it610.com/image/info8/4dfdeb1b670748ffab325b4dad8619e6.jpg"><img src="https://img.it610.com/image/info8/4dfdeb1b670748ffab325b4dad8619e6.jpg" alt="007 Hadoop集群配置 Hadoop集群的启动和测试 SSH免登陆配置（ start-all.sh）
hdfs常用的shell_第39张图片" /></a><br />
3.测试第三步 跑一个MapReduce作业<br />
使用默认的jar来跑<br />
我们来测试一个文件单词出现次数<br />
此时使用的目录<br />
即输入文件的目录<br />
如果说是集群在跑作业的时候<br />
我们的输入数据一定是hdfs文件系统下的数据<br />
我们刚刚上传了一个文件就用这个吧readme的</p>

<pre><code>yarn jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar wordcount /README.txt /out/00 
</code></pre>

<p>wordcount这个单词不能写错<br />
然后写输入目录<br />
输出目录<br />
回车<br />
<a href="https://img.it610.com/image/info8/a508e7ff92aa44b0af0b89ad07c80527.jpg"><img src="https://img.it610.com/image/info8/a508e7ff92aa44b0af0b89ad07c80527.jpg" alt="007 Hadoop集群配置 Hadoop集群的启动和测试 SSH免登陆配置（ start-all.sh）
hdfs常用的shell_第40张图片" /></a><br />
这样算是跑完了 然后就是结果<br />
先看web端<br />
<a href="https://img.it610.com/image/info8/17301c7ed932468dab462f6b4455458b.jpg"><img src="https://img.it610.com/image/info8/17301c7ed932468dab462f6b4455458b.jpg" alt="007 Hadoop集群配置 Hadoop集群的启动和测试 SSH免登陆配置（ start-all.sh）
hdfs常用的shell_第41张图片" /></a><br />
然后继续看<br />
hdfs dfs -ls /out<br />
看看这下面是否有文件<br />
<a href="https://img.it610.com/image/info8/d93d9f05bd0244e1a1237d75d21c635a.jpg"><img src="https://img.it610.com/image/info8/d93d9f05bd0244e1a1237d75d21c635a.jpg" alt="007 Hadoop集群配置 Hadoop集群的启动和测试 SSH免登陆配置（ start-all.sh）
hdfs常用的shell_第42张图片" /></a><br />
有的<br />
然后继续看00的信息<br />
<a href="https://img.it610.com/image/info8/f10f5d87c9dc4e6b8172b75615f279cf.jpg"><img src="https://img.it610.com/image/info8/f10f5d87c9dc4e6b8172b75615f279cf.jpg" alt="在这里插入图片描述" /></a><br />
注意里面有两个 part那个是内容<br />
使用-cat查看<br />
<a href="https://img.it610.com/image/info8/a13d802b997946fc93661be1b19c5b1f.jpg"><img src="https://img.it610.com/image/info8/a13d802b997946fc93661be1b19c5b1f.jpg" alt="007 Hadoop集群配置 Hadoop集群的启动和测试 SSH免登陆配置（ start-all.sh）
hdfs常用的shell_第43张图片" /></a></p>

<hr />

<p>现在我们的启动和测试完成了<br />
但是<br />
每次启动都需要输好多密码 麻烦<br />
所以我们需要配置SSH</p>

<h2 id="ssh免登陆设置">SSH免登陆设置</h2>

<p>官网上说要先下载<br />
不用的 Linux上都有<br />
我们which ssd就可以看到<br />
<a href="https://img.it610.com/image/info8/96dd2594e5b54b2fa0de2e48aac0f7a9.jpg"><img src="https://img.it610.com/image/info8/96dd2594e5b54b2fa0de2e48aac0f7a9.jpg" alt="在这里插入图片描述" /></a><br />
现在 我们来做一些配置<br />
第一步 ：输入</p>

<h2 id="ssh-keygen-t-rsa"><code>ssh-keygen -t rsa</code></h2>

<p>然后回车回车回车 目的就是生成几个文件 （貌似是 什么 …公钥私钥的信息 登陆过服务器的主机名）<br />
<a href="https://img.it610.com/image/info8/3846f8b8e74049c3844f9f9bee494d10.jpg"><img src="https://img.it610.com/image/info8/3846f8b8e74049c3844f9f9bee494d10.jpg" alt="007 Hadoop集群配置 Hadoop集群的启动和测试 SSH免登陆配置（ start-all.sh）
hdfs常用的shell_第44张图片" /></a><br />
我们看一下<br />
hadoop01家目录下面的ssh多了几个文件的<br />
<a href="https://img.it610.com/image/info8/bcaa96dbaea44a0884698654907d0a7d.jpg"><img src="https://img.it610.com/image/info8/bcaa96dbaea44a0884698654907d0a7d.jpg" alt="007 Hadoop集群配置 Hadoop集群的启动和测试 SSH免登陆配置（ start-all.sh）
hdfs常用的shell_第45张图片" /></a><br />
以02作对比 02是没有任何内容的<br />
<a href="https://img.it610.com/image/info8/f4da09aa487047ccaeee4ab3e91898f8.jpg"><img src="https://img.it610.com/image/info8/f4da09aa487047ccaeee4ab3e91898f8.jpg" alt="007 Hadoop集群配置 Hadoop集群的启动和测试 SSH免登陆配置（ start-all.sh）
hdfs常用的shell_第46张图片" /></a><br />
第二步：<br />
然后开始设置ssh<br />
有三种方式<br />
<a href="https://img.it610.com/image/info8/87cc15fff4284d9faa06f1bb3d7c7431.jpg"><img src="https://img.it610.com/image/info8/87cc15fff4284d9faa06f1bb3d7c7431.jpg" alt="007 Hadoop集群配置 Hadoop集群的启动和测试 SSH免登陆配置（ start-all.sh）
hdfs常用的shell_第47张图片" /></a><br />
我们这里使用最后一种 比较简单一些</p>

<p>首先我们先试试哈 这是配置之前的效果<br />
ssh hadoop01 然后输密码<br />
<img src="https://img.it610.com/image/info8/47d44f1367324f80abdf7c0b99c9d6c7.jpg" alt="在这里插入图片描述" /><br />
然后我们照着方法配置一下<br />
ssh-copy-id hadoop01 输密码 退出<br />
<a href="https://img.it610.com/image/info8/ffd9774846704c57a0ba468b6365ed76.jpg"><img src="https://img.it610.com/image/info8/ffd9774846704c57a0ba468b6365ed76.jpg" alt="007 Hadoop集群配置 Hadoop集群的启动和测试 SSH免登陆配置（ start-all.sh）
hdfs常用的shell_第48张图片" /></a><br />
看ssh文件 果然 多了一个keys文件<br />
我们再次登录<br />
ok 不需要输密码了<br />
<a href="https://img.it610.com/image/info8/3fa870e390b24f7cab85e749f6ab46a6.jpg"><img src="https://img.it610.com/image/info8/3fa870e390b24f7cab85e749f6ab46a6.jpg" alt="007 Hadoop集群配置 Hadoop集群的启动和测试 SSH免登陆配置（ start-all.sh）
hdfs常用的shell_第49张图片" /></a><br />
同样的方法配置hadoop02 03 （在01下进行 其实都可以 目的就为了生成那个文件）<br />
ssh-cppy-id hadoop02 输密码 退出 查看02的ssh文件 登录 不需要密码了</p>

<p>ssh-cppy-id hadoop03 输密码 退出 查看03的ssh文件 登录 不需要密码了</p>

<p>这样就可以了</p>

<p>我们来停止所有服务<br />
原来是需要输入密码 现在应该不输入密码了</p>

<pre><code>stop-all.sh
</code></pre>

<p><a href="https://img.it610.com/image/info8/c2cf5b28b95749758aa6bba0b4f25618.jpg"><img src="https://img.it610.com/image/info8/c2cf5b28b95749758aa6bba0b4f25618.jpg" alt="007 Hadoop集群配置 Hadoop集群的启动和测试 SSH免登陆配置（ start-all.sh）
hdfs常用的shell_第50张图片" /></a><br />
然后再启动</p>

<pre><code>start-all.sh
</code></pre>

<h2 id="不用输密码启动成功">不用输密码启动成功</h2>

<p>start-all.sh</p>

<p><a href="https://img.it610.com/image/info8/1b1f1d1803eb48f9afaafeb1a78cd906.jpg"><img src="https://img.it610.com/image/info8/1b1f1d1803eb48f9afaafeb1a78cd906.jpg" alt="007 Hadoop集群配置 Hadoop集群的启动和测试 SSH免登陆配置（ start-all.sh）
hdfs常用的shell_第51张图片" /></a><br />
使用jps查看也是正确的<br />
01<br />
<a href="https://img.it610.com/image/info8/0420c669af3d45a0842eb0135074f83a.jpg"><img src="https://img.it610.com/image/info8/0420c669af3d45a0842eb0135074f83a.jpg" alt="007 Hadoop集群配置 Hadoop集群的启动和测试 SSH免登陆配置（ start-all.sh）
hdfs常用的shell_第52张图片" /></a><br />
02<br />
<img src="https://img.it610.com/image/info8/38008514ed8541378692c6879d9b580d.jpg" alt="在这里插入图片描述" /><br />
03<br />
<img src="https://img.it610.com/image/info8/a3e211fd9d8f44c481c4af82d0a223da.jpg" alt="在这里插入图片描述" /><br />
然后看web<br />
50070<br />
<a href="https://img.it610.com/image/info8/d42d0fadebe346bdb5fd0d985c17b806.jpg"><img src="https://img.it610.com/image/info8/d42d0fadebe346bdb5fd0d985c17b806.jpg" alt="007 Hadoop集群配置 Hadoop集群的启动和测试 SSH免登陆配置（ start-all.sh）
hdfs常用的shell_第53张图片" /></a><br />
8088<br />
<a href="https://img.it610.com/image/info8/8664c14aec234784b5de2ccf951b50db.jpg"><img src="https://img.it610.com/image/info8/8664c14aec234784b5de2ccf951b50db.jpg" alt="007 Hadoop集群配置 Hadoop集群的启动和测试 SSH免登陆配置（ start-all.sh）
hdfs常用的shell_第54张图片" /></a></p>

<hr />

<h2 id="hdfs常用的shell">hdfs常用的shell</h2>

<p><a href="https://img.it610.com/image/info8/f95f615ee77b40b995b48ec5a121bf0b.jpg"><img src="https://img.it610.com/image/info8/f95f615ee77b40b995b48ec5a121bf0b.jpg" alt="007 Hadoop集群配置 Hadoop集群的启动和测试 SSH免登陆配置（ start-all.sh）
hdfs常用的shell_第55张图片" /></a><br />
<a href="https://img.it610.com/image/info8/6c3944de5c88475799d5b5963a63cb11.jpg"><img src="https://img.it610.com/image/info8/6c3944de5c88475799d5b5963a63cb11.jpg" alt="007 Hadoop集群配置 Hadoop集群的启动和测试 SSH免登陆配置（ start-all.sh）
hdfs常用的shell_第56张图片" /></a><br />
这个是输入</p>

<pre><code>hdfs dfs -
</code></pre>

<p>hdfs dfs -<br />
出来了这么多 我们可供使用的<br />
Usage: hadoop fs [generic options]<br />
[-appendToFile … ]追加文件到某个 localsrc指的是LInux本地的 dst指的是hdfs文件系统的<br />
[-cat [-ignoreCrc] …]读取文件内容<br />
[-checksum …]<br />
[-chgrp [-R] GROUP PATH…]改变组 -R递归<br />
[-chmod [-R]  PATH…]改权限<br />
[-chown [-R] [OWNER][:[GROUP]] PATH…]改拥有者<br />
[-copyFromLocal [-f] [-p] [-l] … ]把来自本地的文件copy到hdfs系统<br />
[-copyToLocal [-p] [-ignoreCrc] [-crc] … ]这个反着 copy到本地<br />
[-count [-q] [-h] …]<br />
[-cp [-f] [-p | -p[topax]] … ]<br />
[-createSnapshot []]<br />
[-deleteSnapshot ]<br />
[-df [-h] [ …]]<br />
[-du [-s] [-h] …]<br />
[-expunge]<br />
[-find … …]<br />
[-get [-p] [-ignoreCrc] [-crc] … ]下载·<br />
[-getfacl [-R] ]<br />
[-getfattr [-R] {-n name | -d} [-e en] ]<br />
[-getmerge [-nl] ]<br />
[-help [cmd …]]<br />
[-ls [-d] [-h] [-R] [ …]]<br />
[-mkdir [-p] …]<br />
[-moveFromLocal … ]<br />
[-moveToLocal ]<br />
[-mv … ]<br />
[-put [-f] [-p] [-l] … ]<br />
[-renameSnapshot ]<br />
[-rm [-f] [-r|-R] [-skipTrash] …]<br />
[-rmdir [–ignore-fail-on-non-empty]</p>

<p>…]<br />
[-setfacl [-R] [{-b|-k} {-m|-x } ]|[–set  ]]<br />
[-setfattr {-n name [-v value] | -x name} ]<br />
[-setrep [-R] [-w] …]<br />
[-stat [format] …]<br />
[-tail [-f] ]<br />
[-test -[defsz] ]<br />
[-text [-ignoreCrc] …]<br />
[-touchz …]<br />
[-truncate [-w] …]<br />
[-usage [cmd …]]</p>

<p><a href="https://img.it610.com/image/info8/84c8ad74e99045a1a600730a13b5b041.jpg"><img src="https://img.it610.com/image/info8/84c8ad74e99045a1a600730a13b5b041.jpg" alt="007 Hadoop集群配置 Hadoop集群的启动和测试 SSH免登陆配置（ start-all.sh）
hdfs常用的shell_第57张图片" /></a><br />
hdfs中的shell命令<br />
通常都是这样<br />
hdfs dfs - /<br />
杠 加命令 斜杠 加 绝对目录<br />
或者hadoop fs - /</p>

<h2 id="例子">例子</h2>

<p>查看 -ls<br />
<a href="https://img.it610.com/image/info8/30d2c418229448868c79319cdd75d63c.jpg"><img src="https://img.it610.com/image/info8/30d2c418229448868c79319cdd75d63c.jpg" alt="在这里插入图片描述" /></a><br />
hdfs dfs -ls /<br />
查看hdfs根目录的文件<br />
或者hadoop fs -ls /也行（不过这是老版本了）<br />
<a href="https://img.it610.com/image/info8/54aa8998eff54a70857f4ec32c597c83.jpg"><img src="https://img.it610.com/image/info8/54aa8998eff54a70857f4ec32c597c83.jpg" alt="007 Hadoop集群配置 Hadoop集群的启动和测试 SSH免登陆配置（ start-all.sh）
hdfs常用的shell_第58张图片" /></a><br />
也可以使用-ls -R大写 递归查看目录<br />
<img src="https://img.it610.com/image/info8/7396c5207f7846a8a4dbe97e4161811f.jpg" alt="在这里插入图片描述" /><br />
创建目录<br />
hdfs dfs -mkdir /test<br />
<a href="https://img.it610.com/image/info8/b04fb5332379492d8a4c500a27446db5.jpg"><img src="https://img.it610.com/image/info8/b04fb5332379492d8a4c500a27446db5.jpg" alt="007 Hadoop集群配置 Hadoop集群的启动和测试 SSH免登陆配置（ start-all.sh）
hdfs常用的shell_第59张图片" /></a><br />
递归创建目录<br />
递归创建 -p<br />
hdfs dfs -mkdir -p /test/01/02<br />
然后查看 hdfs dfs -ls -R /test/<br />
<a href="https://img.it610.com/image/info8/4d143549499d469fa76a9f923d5dd950.jpg"><img src="https://img.it610.com/image/info8/4d143549499d469fa76a9f923d5dd950.jpg" alt="007 Hadoop集群配置 Hadoop集群的启动和测试 SSH免登陆配置（ start-all.sh）
hdfs常用的shell_第60张图片" /></a><br />
创建文件 （是空的！！！）<br />
hdfs dfs -touchz /test/te.txt<br />
<a href="https://img.it610.com/image/info8/6caf02d9c3234a949d534ce4cb733b9a.jpg"><img src="https://img.it610.com/image/info8/6caf02d9c3234a949d534ce4cb733b9a.jpg" alt="007 Hadoop集群配置 Hadoop集群的启动和测试 SSH免登陆配置（ start-all.sh）
hdfs常用的shell_第61张图片" /></a><br />
注意 由于不能修改 所以只能追加</p>

<p>然后复制-cp<br />
hdfs dfs -lsr /test/01<br />
<img src="https://img.it610.com/image/info8/0e56656a8b404aa3a966cb0fac89e23e.jpg" alt="在这里插入图片描述" /><br />
<a href="https://img.it610.com/image/info8/a005ba68546b40ecbfdb66fd8be373ee.jpg"><img src="https://img.it610.com/image/info8/a005ba68546b40ecbfdb66fd8be373ee.jpg" alt="007 Hadoop集群配置 Hadoop集群的启动和测试 SSH免登陆配置（ start-all.sh）
hdfs常用的shell_第62张图片" /></a><br />
移动-mv<br />
hdfs dfs -mv /test/01/te.txt /test/01/02<br />
<a href="https://img.it610.com/image/info8/f60526cc07b3461da3bf2dbc63227bf5.jpg"><img src="https://img.it610.com/image/info8/f60526cc07b3461da3bf2dbc63227bf5.jpg" alt="007 Hadoop集群配置 Hadoop集群的启动和测试 SSH免登陆配置（ start-all.sh）
hdfs常用的shell_第63张图片" /></a><br />
-mv还可以在移动过程中改名<br />
<a href="https://img.it610.com/image/info8/0db14af19fa04b5cafdd601226c52c1a.jpg"><img src="https://img.it610.com/image/info8/0db14af19fa04b5cafdd601226c52c1a.jpg" alt="007 Hadoop集群配置 Hadoop集群的启动和测试 SSH免登陆配置（ start-all.sh）
hdfs常用的shell_第64张图片" /></a><br />
上传文件<br />
将本地的上传到hdfs中<br />
先进入到home的shell目录下 看看有啥 我们传一个if.sh吧<br />
<a href="https://img.it610.com/image/info8/d02e053f6e564576b14af3c0815a2483.jpg"><img src="https://img.it610.com/image/info8/d02e053f6e564576b14af3c0815a2483.jpg" alt="007 Hadoop集群配置 Hadoop集群的启动和测试 SSH免登陆配置（ start-all.sh）
hdfs常用的shell_第65张图片" /></a><br />
然后hdfs dfs -put ./if.sh /test<br />
<a href="https://img.it610.com/image/info8/a65e339b16dd40c89bf5dd03519afdf3.jpg"><img src="https://img.it610.com/image/info8/a65e339b16dd40c89bf5dd03519afdf3.jpg" alt="007 Hadoop集群配置 Hadoop集群的启动和测试 SSH免登陆配置（ start-all.sh）
hdfs常用的shell_第66张图片" /></a><br />
除了-put<br />
还有一个-copyFromLocal可以实现文件复制上传<br />
<a href="https://img.it610.com/image/info8/55cbfc44fb404e01ab851ccc0d044e85.jpg"><img src="https://img.it610.com/image/info8/55cbfc44fb404e01ab851ccc0d044e85.jpg" alt="007 Hadoop集群配置 Hadoop集群的启动和测试 SSH免登陆配置（ start-all.sh）
hdfs常用的shell_第67张图片" /></a><br />
hdfs dfs -get /test/if.sh /home/if 顺便还可以改名<br />
然后我们实现文件下载-get<a href="https://img.it610.com/image/info8/ea8a33dcf6c74cfc9e509aa06c734133.jpg"><img src="https://img.it610.com/image/info8/ea8a33dcf6c74cfc9e509aa06c734133.jpg" alt="007 Hadoop集群配置 Hadoop集群的启动和测试 SSH免登陆配置（ start-all.sh）
hdfs常用的shell_第68张图片" /></a><br />
下载成功<br />
同样的 下载命令还有<br />
-copyToLocal<br />
hdfs dfs -copyToLocal /test/for.sh /home/for<br />
下载成功<br />
<a href="https://img.it610.com/image/info8/f279b9ff3cdc446ea6a6e59406e25508.jpg"><img src="https://img.it610.com/image/info8/f279b9ff3cdc446ea6a6e59406e25508.jpg" alt="007 Hadoop集群配置 Hadoop集群的启动和测试 SSH免登陆配置（ start-all.sh）
hdfs常用的shell_第69张图片" /></a></p>

<p>hdfs查看真正的文件内容</p>

<h4 id="text">-text</h4>

<p><a href="https://img.it610.com/image/info8/3fa9c8294a8e426289735dcc49e9f04d.jpg"><img src="https://img.it610.com/image/info8/3fa9c8294a8e426289735dcc49e9f04d.jpg" alt="007 Hadoop集群配置 Hadoop集群的启动和测试 SSH免登陆配置（ start-all.sh）
hdfs常用的shell_第70张图片" /></a><br />
hdfs dfs -text /test/if.sh</p>

<h4 id="tail">-tail</h4>

<p>这个也能查看文件内容<br />
也可以进行监控功能<br />
<a href="https://img.it610.com/image/info8/8b8304efb97b499bb4cce414f72794b4.jpg"><img src="https://img.it610.com/image/info8/8b8304efb97b499bb4cce414f72794b4.jpg" alt="007 Hadoop集群配置 Hadoop集群的启动和测试 SSH免登陆配置（ start-all.sh）
hdfs常用的shell_第71张图片" /></a></p>

<h2 id="du">-du</h2>

<p>查看目录大小</p>

<p><a href="https://img.it610.com/image/info8/4fc7712cf9ba445997257b61e386fda2.jpg"><img src="https://img.it610.com/image/info8/4fc7712cf9ba445997257b61e386fda2.jpg" alt="007 Hadoop集群配置 Hadoop集群的启动和测试 SSH免登陆配置（ start-all.sh）
hdfs常用的shell_第72张图片" /></a></p>

<h2 id="du-s">-du -s</h2>

<p>加s是总和的意思<br />
<a href="https://img.it610.com/image/info8/22c366ebbd144d3ea9b1285314e13370.jpg"><img src="https://img.it610.com/image/info8/22c366ebbd144d3ea9b1285314e13370.jpg" alt="007 Hadoop集群配置 Hadoop集群的启动和测试 SSH免登陆配置（ start-all.sh）
hdfs常用的shell_第73张图片" /></a></p>

        </div>

        


        

<div class="post-archive">
    <h2>See Also</h2>
    <ul class="listing">
        
        <li><a href="/posts/009shell%E8%84%9A%E6%9C%AC%E4%B8%8B%E6%9D%A1%E4%BB%B6%E6%B5%8B%E8%AF%95eqne/">009Shell脚本下条件测试eqne</a></li>
        
        <li><a href="/posts/00pythonmanagepyshell%E5%92%8Cpython%E7%9A%84%E5%88%86%E6%9E%90/">00Pythonmanagepyshell和Python的分析</a></li>
        
        <li><a href="/posts/010zookeeper%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5zookeeper%E7%9A%84%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BAzookeeper%E7%9A%84shell%E5%91%BD%E4%BB%A4/">010Zookeeper的基本概念Zookeeper的集群搭建Zookeeper的shell命令</a></li>
        
        <li><a href="/posts/018dockerfileshell/">018DockerfileSHELL</a></li>
        
        <li><a href="/posts/01shell%E5%85%A5%E9%97%A801bashshell%E7%89%B9%E6%80%A7/">01Shell入门01bashShell特性</a></li>
        
    </ul>
</div>


        <div class="post-meta meta-tags">
            
            <ul class="clearfix">
                
                <li><a href='https://zaina.newban.cn/tags/shell'>shell</a></li>
                
            </ul>
            
        </div>
    </article>
    
    

    
    
</div>

                    <footer id="footer">
    <div>
        &copy; 2020 <a href="https://zaina.newban.cn">开发者问答集锦 By </a>
        
    </div>
    <br />
    <div>
        <div class="github-badge">
            <a href="https://gohugo.io/" target="_black" rel="nofollow"><span class="badge-subject">Powered by</span><span class="badge-value bg-blue">Hugo</span></a>
        </div>
        <div class="github-badge">
            <a href="https://www.flysnow.org/" target="_black"><span class="badge-subject">Design by</span><span class="badge-value bg-brightgreen">飞雪无情</span></a>
        </div>
        <div class="github-badge">
            <a href="https://github.com/flysnow-org/maupassant-hugo" target="_black"><span class="badge-subject">Theme</span><span class="badge-value bg-yellowgreen">Maupassant</span></a>
        </div>
    </div>
</footer>


    
    <script type="text/javascript">
        window.MathJax = {
            tex2jax: {
                inlineMath: [['$', '$']],
                processEscapes: true
                }
            };
    </script>
    <script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML' async></script>

<a id="rocket" href="#top"></a>
<script type="text/javascript" src='/js/totop.js?v=0.0.0' async=""></script>



    <script type="text/javascript" src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script>




                </div>

                <div id="secondary">
    <section class="widget">
        <form id="search" action='https://zaina.newban.cn/search/' method="get" accept-charset="utf-8" target="_blank" _lpchecked="1">
      
      <input type="text" name="q" maxlength="20" placeholder="Search">
      <input type="hidden" name="sitesearch" value="https://zaina.newban.cn">
      <button type="submit" class="submit icon-search"></button>
</form>
    </section>
    
    <section class="widget">
        <h3 class="widget-title">最近文章</h3>
<ul class="widget-list">
    
    <li>
        <a href="https://zaina.newban.cn/posts/001rubyruby%E4%B8%AD%E5%85%A8%E5%B1%80%E5%8F%98%E9%87%8F%E5%AE%9E%E4%BE%8B%E5%8F%98%E9%87%8F%E5%B1%80%E9%83%A8%E5%8F%98%E9%87%8F%E7%B1%BB%E5%8F%98%E9%87%8Fsymbol%E5%AF%B9%E6%AF%94/" title="001rubyRuby中全局变量实例变量局部变量类变量Symbol对比">001rubyRuby中全局变量实例变量局部变量类变量Symbol对比</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/007hadoop%E9%9B%86%E7%BE%A4%E9%85%8D%E7%BD%AEhadoop%E9%9B%86%E7%BE%A4%E7%9A%84%E5%90%AF%E5%8A%A8%E5%92%8C%E6%B5%8B%E8%AF%95ssh%E5%85%8D%E7%99%BB%E9%99%86%E9%85%8D%E7%BD%AEstartallshhdfs%E5%B8%B8%E7%94%A8%E7%9A%84shell/" title="007Hadoop集群配置Hadoop集群的启动和测试SSH免登陆配置startallshhdfs常用的shell">007Hadoop集群配置Hadoop集群的启动和测试SSH免登陆配置startallshhdfs常用的shell</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/009shell%E8%84%9A%E6%9C%AC%E4%B8%8B%E6%9D%A1%E4%BB%B6%E6%B5%8B%E8%AF%95eqne/" title="009Shell脚本下条件测试eqne">009Shell脚本下条件测试eqne</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/00pythonmanagepyshell%E5%92%8Cpython%E7%9A%84%E5%88%86%E6%9E%90/" title="00Pythonmanagepyshell和Python的分析">00Pythonmanagepyshell和Python的分析</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/010zookeeper%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5zookeeper%E7%9A%84%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BAzookeeper%E7%9A%84shell%E5%91%BD%E4%BB%A4/" title="010Zookeeper的基本概念Zookeeper的集群搭建Zookeeper的shell命令">010Zookeeper的基本概念Zookeeper的集群搭建Zookeeper的shell命令</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/018dockerfileshell/" title="018DockerfileSHELL">018DockerfileSHELL</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/01shell%E5%85%A5%E9%97%A801bashshell%E7%89%B9%E6%80%A7/" title="01Shell入门01bashShell特性">01Shell入门01bashShell特性</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/01shell%E5%8F%98%E9%87%8F/" title="01Shell变量">01Shell变量</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/01shell%E5%9F%BA%E7%A1%80%E6%A6%82%E8%BF%B0%E8%84%9A%E6%9C%AC%E6%89%A7%E8%A1%8C%E6%96%B9%E5%BC%8Fbash%E5%9F%BA%E6%9C%AC%E5%8A%9F%E8%83%BD/" title="01Shell基础概述脚本执行方式Bash基本功能">01Shell基础概述脚本执行方式Bash基本功能</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/01shell%E7%BC%96%E7%A8%8Bhelloworld/" title="01shell编程helloworld">01shell编程helloworld</a>
    </li>
    
</ul>
    </section>

    

    <section class="widget">
        <h3 class="widget-title"><a href="/categories">分类</a></h3>
<ul class="widget-list">
    
</ul>
    </section>

    <section class="widget">
        <h3 class="widget-title"><a href="/tags">标签</a></h3>
<div class="tagcloud">
    
    <a href="https://zaina.newban.cn/tags/ruby/">ruby</a>
    
    <a href="https://zaina.newban.cn/tags/shell/">shell</a>
    
</div>
    </section>

    

    <section class="widget">
        <h3 class="widget-title">其它</h3>
        <ul class="widget-list">
            <li><a href="https://zaina.newban.cn/index.xml">文章 RSS</a></li>
        </ul>
    </section>
</div>
            </div>
        </div>
    </div>
</body>

</html>