<!doctype html>
<html lang="en-us">
<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">


    <title>9kafkashell脚本用法详解 | 开发者问答集锦</title>
    <meta property="og:title" content="9kafkashell脚本用法详解 - 开发者问答集锦">
    <meta property="og:type" content="article">
        
    <meta property="article:published_time" content='2020-09-02T00:00:00&#43;08:00'>
        
        
    <meta property="article:modified_time" content='2020-09-02T00:00:00&#43;08:00'>
        
    <meta name="Keywords" content="">
    <meta name="description" content="9kafkashell脚本用法详解">
        
    <meta name="author" content="">
    <meta property="og:url" content="https://zaina.newban.cn/posts/9kafkashell%E8%84%9A%E6%9C%AC%E7%94%A8%E6%B3%95%E8%AF%A6%E8%A7%A3/">
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">

    <link rel="stylesheet" href='/css/normalize.css'>
    <link rel="stylesheet" href='/css/style.css'>
    <script type="text/javascript" src="//cdn.bootcdn.net/ajax/libs/jquery/3.4.1/jquery.min.js"></script>

    
    
    
    
    
    
</head>


<body>
    <header id="header" class="clearfix">
    <div class="container">
        <div class="col-group">
            <div class="site-name ">
                
                    <a id="logo" href="https://zaina.newban.cn">
                        开发者问答集锦
                    </a>
                
                
            </div>
            <div>
                <nav id="nav-menu" class="clearfix">
                    <a class="" href="https://zaina.newban.cn">首页</a>
                    
                </nav>
            </div>
        </div>
    </div>
</header>

    <div id="body">
        <div class="container">
            <div class="col-group">

                <div class="col-8" id="main">
                    
<div class="res-cons">
    
    <article class="post">
        <header>
            <h1 class="post-title">9kafkashell脚本用法详解</h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        
        <div class="post-meta">
            <span id="busuanzi_container_page_pv">|<span id="busuanzi_value_page_pv"></span><span>
                    阅读</span></span>
        </div>
        
        
        <div class="post-content">
            <p>kafka安装目录下的bin目录包含了很多运维可操作的shell脚本，列举如下：</p>

<table>
<thead>
<tr>
<th>脚本名称</th>
<th>用途描述</th>
</tr>
</thead>

<tbody>
<tr>
<td>connect-distributed.sh</td>
<td>连接kafka集群模式</td>
</tr>

<tr>
<td>connect-standalone.sh</td>
<td>连接kafka单机模式</td>
</tr>

<tr>
<td>kafka-acls.sh</td>
<td>todo</td>
</tr>

<tr>
<td>kafka-broker-api-versions.sh</td>
<td>todo</td>
</tr>

<tr>
<td>kafka-configs.sh</td>
<td>配置管理脚本</td>
</tr>

<tr>
<td>kafka-console-consumer.sh</td>
<td>kafka消费者控制台</td>
</tr>

<tr>
<td>kafka-console-producer.sh</td>
<td>kafka生产者控制台</td>
</tr>

<tr>
<td>kafka-consumer-groups.sh</td>
<td>kafka消费者组相关信息</td>
</tr>

<tr>
<td>kafka-consumer-perf-test.sh</td>
<td>kafka消费者性能测试脚本</td>
</tr>

<tr>
<td>kafka-delegation-tokens.sh</td>
<td>todo</td>
</tr>

<tr>
<td>kafka-delete-records.sh</td>
<td>删除低水位的日志文件</td>
</tr>

<tr>
<td>kafka-log-dirs.sh</td>
<td>kafka消息日志目录信息</td>
</tr>

<tr>
<td>kafka-mirror-maker.sh</td>
<td>不同数据中心kafka集群复制工具</td>
</tr>

<tr>
<td>kafka-preferred-replica-election.sh</td>
<td>触发preferred replica选举</td>
</tr>

<tr>
<td>kafka-producer-perf-test.sh</td>
<td>kafka生产者性能测试脚本</td>
</tr>

<tr>
<td>kafka-reassign-partitions.sh</td>
<td>分区重分配脚本</td>
</tr>

<tr>
<td>kafka-replay-log-producer.sh</td>
<td>todo</td>
</tr>

<tr>
<td>kafka-replica-verification.sh</td>
<td>复制进度验证脚本</td>
</tr>

<tr>
<td>kafka-run-class.sh</td>
<td>todo</td>
</tr>

<tr>
<td>kafka-server-start.sh</td>
<td>启动kafka服务</td>
</tr>

<tr>
<td>kafka-server-stop.sh</td>
<td>停止kafka服务</td>
</tr>

<tr>
<td>kafka-simple-consumer-shell.sh</td>
<td>deprecated，推荐使用kafka-console-consumer.sh</td>
</tr>

<tr>
<td>kafka-streams-application-reset.sh</td>
<td>todo</td>
</tr>

<tr>
<td>kafka-topics.sh</td>
<td>topic管理脚本</td>
</tr>

<tr>
<td>kafka-verifiable-consumer.sh</td>
<td>可检验的kafka消费者</td>
</tr>

<tr>
<td>kafka-verifiable-producer.sh</td>
<td>可检验的kafka生产者</td>
</tr>

<tr>
<td>trogdor.sh</td>
<td>todo</td>
</tr>

<tr>
<td>zookeeper-security-migration.sh</td>
<td>todo</td>
</tr>

<tr>
<td>zookeeper-server-start.sh</td>
<td>启动zk服务</td>
</tr>

<tr>
<td>zookeeper-server-stop.sh</td>
<td>停止zk服务</td>
</tr>

<tr>
<td>zookeeper-shell.sh</td>
<td>zk客户端</td>
</tr>
</tbody>
</table>

<p>接下来详细说明每个脚本的使用方法。</p>

<ul>
<li><strong>connect-distributed.sh &amp;connect-standalone.sh</strong></li>
</ul>

<p>Kafka
Connect是在0.9以后加入的功能，主要是用来将其他系统的数据导入到Kafka,然后再将Kafka中的数据导出到另外的系统。可以用来做实时数据同步的ETL，数据实时分析处理等。<br />
主要有2种模式：Standalone（单机模式）和Distribute（分布式模式）。<br />
单机主要用来开发，测试，分布式的用于生产环境。<br />
用法比较复杂，建议参考：Kafka Connect教程详解 <a href="https://3gods.com/bigdata/Kafka-Connect-">https://3gods.com/bigdata/Kafka-Connect-</a>
Details.html</p>

<ul>
<li><strong>kafka-broker-api-versions.sh</strong></li>
</ul>

<p>用法：bin/kafka-broker-api-versions.sh –bootstrap-server
10.0.55.229:9092,10.0.55.229:9093,10.0.55.229:9094</p>

<ul>
<li><strong>kafka-configs.sh</strong></li>
</ul>

<p>配置管理脚本，这个脚本主要分两类用法：describe和alter。<br />
describe相关用法：<br />
查看每个topic的配置：bin/kafka-configs.sh –zookeeper localhost:2181 –describe –entity-
type topics<br />
部分结果如下：</p>

<pre><code>Configs for topic 'afei' are 
Configs for topic 'TOPIC-TEST-AFEI' are retention.ms=600000 
Configs for topic '__consumer_offsets' are segment.bytes=104857600,cleanup.policy=compact,compression.type=producer
</code></pre>

<p>查看broker的配置：bin/kafka-configs.sh –bootstrap-server localhost:9092 –describe
–entity-type brokers –entity-name 0</p>

<blockquote>
<p>说明：0是broker.id，因为entity-type为brokers，所以entity-name表示broker.id。</p>
</blockquote>

<p>alter相关用法：<br />
给指定topic增加配置：bin/kafka-configs.sh –zookeeper localhost:2181 –alter –entity-
type topics –entity-name TOPIC-TEST-AFEI <strong>–add-config</strong> retention.ms=600000<br />
给指定topic删除配置：bin/kafka-configs.sh –zookeeper localhost:2181 –alter –entity-
type topics –entity-name TOPIC-TEST-AFEI <strong>–delete-config</strong> max.message.bytes</p>

<blockquote>
<p>通过该脚本可以管理的属性，可以通过执行<code>bin/kafka-configs.sh</code>得到的输出中<code>--add-config</code>的desc可以得到。</p>
</blockquote>

<ul>
<li><strong>kafka-broker-api-versions.sh</strong></li>
</ul>

<p>用法：bin/kafka-broker-api-versions.sh –bootstrap-server localhost:9092</p>

<ul>
<li><strong>kafka-console-consumer.sh</strong></li>
</ul>

<p>用法：bin/kafka-console-consumer.sh –bootstrap-server localhost:9092 –topic afei
[–group groupName] [–partition 目标分区]</p>

<p>这个命令后面还可带很多参数：<br />
<code>--key-deserializer</code>：指定key的反序列化方式，默认是
org.apache.kafka.common.serialization.StringDeserializer<br />
<code>--value-deserializer</code>：指定value的反序列化方式，默认是
org.apache.kafka.common.serialization.StringDeserializer<br />
<code>--from-beginning</code>：从最早的消息开始消费，默认是从最新消息开始消费。<br />
<code>--offset</code>： 从指定的消息位置开始消费，如果设置了这个参数，还需要带上<code>--partition</code>。否则会提示：The partition is
required when offset is specified.<br />
<code>--timeout-
ms</code>：当消费者在这个参数指定时间间隔内没有收到消息就会推出，并抛出异常：kafka.consumer.ConsumerTimeoutException。<br />
<code>--whitelist</code>：接收的topic白名单集合，和<code>--topic</code>二者取其一。例如：<code>--whitelist
&quot;afei.*&quot;</code>（以afei开头的topic），<code>--whitelist
&quot;afei&quot;</code>（指定afei这个topic），<code>&quot;afei|fly&quot;</code>（指定afei或者fly这两个topic）。另外一个参数<code>--blacklist</code>用法类似。</p>

<ul>
<li><strong>kafka-console-producer.sh</strong></li>
</ul>

<p>用法：bin/kafka-console-producer.sh –broker-list localhost:9092 –topic afei<br />
，如果连接集群，那么broker-list参数格式为：HOST1:PORT1,HOST2:PORT2,HOST3:PORT3</p>

<p>这个命令后面还可带很多参数：<br />
<code>--key-serializer</code>：指定key的序列化方式，默认是
org.apache.kafka.common.serialization.StringSerializer<br />
<code>--value-serializer</code>：指定value的序列化方式，默认是
org.apache.kafka.common.serialization.StringSerializer</p>

<ul>
<li><strong>kafka-consumer-groups.sh</strong></li>
</ul>

<p>查看所有消费者组：bin/kafka-consumer-groups.sh –bootstrap-server localhost:9092 –list<br />
查看某个消费者组：bin/kafka-consumer-groups.sh –bootstrap-server localhost:9092 –group
AfeiGroup –describe，输出结果如下：</p>

<pre><code>Note: This will not show information about old Zookeeper-based consumers.

TOPIC           PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG             CONSUMER-ID                                     HOST            CLIENT-ID
afei            0          8               8               0               consumer-1-7a46c647-8221-4aca-b6bf-ed14571fb0f1 /172.18.36.203  consumer-1
afei            4          10              10              0               consumer-1-7a46c647-8221-4aca-b6bf-ed14571fb0f1 /172.18.36.203  consumer-1
afei            1          8               8               0               consumer-1-7a46c647-8221-4aca-b6bf-ed14571fb0f1 /172.18.36.203  consumer-1
afei            3          6               6               0               consumer-1-7a46c647-8221-4aca-b6bf-ed14571fb0f1 /172.18.36.203  consumer-1
afei            2          9               9               0               consumer-1-7a46c647-8221-4aca-b6bf-ed14571fb0f1 /172.18.36.203  consumer-1
</code></pre>

<ul>
<li><strong>kafka-consumer-perf-test.sh</strong></li>
</ul>

<p>perf是performance的缩写，所以这个脚本是kafka消费者性能测试脚本。<br />
用法：bin/kafka-consumer-perf-test.sh –broker-list localhost:9092 –group
testGroup –topic afei –messages 1024<br />
输出结果如下：</p>

<pre><code>start.time, end.time, data.consumed.in.MB, MB.sec, data.consumed.in.nMsg, nMsg.sec, rebalance.time.ms, fetch.time.ms, fetch.MB.sec, fetch.nMsg.sec
2018-07-02 22:49:10:068, 2018-07-02 22:49:12:077, 0.0001, 0.0001, 41, 20.4082, 19, 1990, 0.0001, 20.6030
</code></pre>

<ul>
<li><strong>kafka-delete-records.sh</strong></li>
</ul>

<p>用法：bin/kafka-delete-records.sh –bootstrap-server
10.0.55.229:9092,10.0.55.229:9093,10.0.55.229:9094 –offset-json-file
offset.json，offset.json文件内容：</p>

<pre><code>{
    &quot;partitions&quot;: [{
        &quot;topic&quot;: &quot;afei&quot;,
        &quot;partition&quot;: 3,
        &quot;offset&quot;: 10
    }],
    &quot;version&quot;: 1
}
</code></pre>

<p>执行结果如下，表示删除afei这个topic下分区为3的offset少于10的消息日志（不会删除offset=10的消息日志）：</p>

<pre><code>Executing records delete operation
Records delete operation completed:
partition: afei-3   low_watermark: 10
</code></pre>

<ul>
<li><strong>kafka-log-dirs.sh</strong></li>
</ul>

<p>用法：bin/kafka-log-dirs.sh –bootstrap-server localhost:9092 –describe –topic-
list afei[,topicName2,topicNameN]，如果没有指定<code>--topic-
list</code>，那么会输出所有kafka消息日志目录以及目录下所有topic信息。加上<code>--topic-
list</code>参数后，输出结果如下，由这段结果可知，消息日志所在目录为<code>/data/kafka-logs</code>，并且afei这个topic有3个分区：</p>

<pre><code>{
    &quot;version&quot;: 1,
    &quot;brokers&quot;: [{
        &quot;broker&quot;: 0,
        &quot;logDirs&quot;: [{
            &quot;logDir&quot;: &quot;/data/kafka-logs&quot;,
            &quot;error&quot;: null,
            &quot;partitions&quot;: [{
                &quot;partition&quot;: &quot;afei-1&quot;,
                &quot;size&quot;: 567,
                &quot;offsetLag&quot;: 0,
                &quot;isFuture&quot;: false
            }, {
                &quot;partition&quot;: &quot;afei-2&quot;,
                &quot;size&quot;: 639,
                &quot;offsetLag&quot;: 0,
                &quot;isFuture&quot;: false
            }, {
                &quot;partition&quot;: &quot;afei-0&quot;,
                &quot;size&quot;: 561,
                &quot;offsetLag&quot;: 0,
                &quot;isFuture&quot;: false
            }]
        }]
    }]
}
</code></pre>

<ul>
<li><strong>kafka-preferred-replica-election.sh</strong></li>
</ul>

<p>用法：bin/kafka-preferred-replica-election.sh –zookeeper
10.0.55.208:2181/wallet,10.0.55.209:2181/wallet,10.0.55.210:2181/wallet –path-
to-json-file afei-preferred.json（如果不带–path-to-json-file就是对所有topic进行preferred
replica election），json文件内容如下：：</p>

<pre><code>{
    &quot;partitions&quot;: [{
        &quot;topic&quot;: &quot;afei&quot;,
        &quot;partition&quot;: 0
    },
    {
        &quot;topic&quot;: &quot;afei&quot;,
        &quot;partition&quot;: 1
    },
    {
        &quot;topic&quot;: &quot;afei&quot;,
        &quot;partition&quot;: 2
    }]
}
</code></pre>

<p>场景：在创建一个topic时，kafka尽量将partition均分在所有的brokers上，并且将replicas也均分在不同的broker上。每个partitiion的所有replicas叫做”assigned
replicas”，”assigned replicas”中的第一个replicas叫”preferred
replica”，刚创建的topic一般”preferred replica”是leader。leader
replica负责所有的读写。其他replica只是冷备状态，不接受读写请求。但随着时间推移，broker可能会主动停机甚至客观宕机，会发生leader选举迁移，导致机群的负载不均衡。我们期望对topic的leader进行重新负载均衡，让partition选择”preferred
replica”做为leader。</p>

<p>kafka提供了一个参数<code>auto.leader.rebalance.enable</code>自动做这件事情，且默认为true，原理是一个后台线程检查并触发leader
balance。但是并不建议把这个参数设置为true。因为担心这个自动选举发生在业务高峰期，从而导致影响业务。</p>

<p>验证：<br />
操作比较简单，常见一个3个分区3个副本的topic，然后kill掉一个broker。这时候topic信息如下，我们可以看到broker.id为0的broker上有两个leader：</p>

<pre><code>Topic:afei  PartitionCount:3    ReplicationFactor:3 Configs:
    Topic: afei Partition: 0    Leader: 0   Replicas: 0,1,2 Isr: 0,1,2
    Topic: afei Partition: 1    Leader: 1   Replicas: 1,2,0 Isr: 0,1,2
    Topic: afei Partition: 2    Leader: 0   Replicas: 2,0,1 Isr: 0,1,2
</code></pre>

<p>执行<code>kafka-preferred-replica-election.sh</code>脚本后，topic信息如下，leader均匀分布在3个不同的broker上，</p>

<pre><code>Topic:afei  PartitionCount:3    ReplicationFactor:3 Configs:
    Topic: afei Partition: 0    Leader: 0   Replicas: 0,1,2 Isr: 0,1,2
    Topic: afei Partition: 1    Leader: 1   Replicas: 1,2,0 Isr: 0,1,2
    Topic: afei Partition: 2    Leader: 2   Replicas: 2,0,1 Isr: 0,1,2
</code></pre>

<ul>
<li><strong>kafka-producer-perf-test.sh</strong></li>
</ul>

<p>perf是performance的缩写，所以这个脚本是kafka生产者性能测试脚本。</p>

<ul>
<li><strong>kafka-reassign-partitions.sh</strong></li>
</ul>

<p>场景：将一些topic上的分区从当前所在broker移到其他比如新增的broker上。假设有个名为ORDER-
DETAIL的topic，在broker.id为2的broker上：</p>

<pre><code>Topic:ORDER-DETAIL  PartitionCount:1    ReplicationFactor:1 Configs:
    Topic: ORDER-DETAIL Partition: 0    Leader: 2   Replicas: 2 Isr: 2
</code></pre>

<p>现在想要把它移动到broker.id为1的broker上，执行脚本：bin/kafka-reassign-partitions.sh –zookeeper
10.0.55.208:2181/wallet,10.0.55.209:2181/wallet,10.0.55.210:2181/wallet
–topics-to-move-json-file move.json –broker-list “1” –generate</p>

<p><code>--generate</code>参数表示生成一个分区再分配配置，并不会真正的执行，命令执行结果如下：</p>

<pre><code>Current partition replica assignment
{&quot;version&quot;:1,&quot;partitions&quot;:[{&quot;topic&quot;:&quot;ORDER-DETAIL&quot;,&quot;partition&quot;:0,&quot;replicas&quot;:[2],&quot;log_dirs&quot;:[&quot;any&quot;]}]}

Proposed partition reassignment configuration
{&quot;version&quot;:1,&quot;partitions&quot;:[{&quot;topic&quot;:&quot;ORDER-DETAIL&quot;,&quot;partition&quot;:0,&quot;replicas&quot;:[1],&quot;log_dirs&quot;:[&quot;any&quot;]}]}
</code></pre>

<p>我们只需要把第二段json内容保存到一个新建的final.json文件中（如果知道如何编写这段json内容，那么也可以不执行第一条命令），然后执行命令：bin/kafka-
reassign-partitions.sh –zookeeper
10.0.55.208:2181/wallet,10.0.55.209:2181/wallet,10.0.55.210:2181/wallet
–reassignment-json-file move_final.json
–execute，此次执行的命令带有<code>--execute</code>参数，说明是真正的执行分区重分配。</p>

<p>通过这个命令还可以给某个topic<strong>增加副本</strong>，例如有一个名为ORDER-
DETAIL的topic，有3个分区，但是只有1个副本，为了高可用，需要将副本数增加到2，那么编写replica.json文本内容如下：</p>

<pre><code>{
    &quot;version&quot;: 1,
    &quot;partitions&quot;: [{
        &quot;topic&quot;: &quot;ORDER-DETAIL&quot;,
        &quot;partition&quot;: 0,
        &quot;replicas&quot;: [1, 2]
    },
    {
        &quot;topic&quot;: &quot;ORDER-DETAIL&quot;,
        &quot;partition&quot;: 1,
        &quot;replicas&quot;: [0, 2]
    },
    {
        &quot;topic&quot;: &quot;ORDER-DETAIL&quot;,
        &quot;partition&quot;: 2,
        &quot;replicas&quot;: [1, 0]
    }]
}
</code></pre>

<p>然后执行命令即可：bin/kafka-reassign-partitions.sh –zookeeper
10.0.55.208:2181/wallet,10.0.55.209:2181/wallet,10.0.55.210:2181/wallet
–reassignment-json-file replica.json</p>

<ul>
<li><strong>kafka-replica-verification.sh</strong></li>
</ul>

<p>用法：bin/kafka-replica-verification.sh –broker-list
10.0.55.229:9092,10.0.55.229:9093,10.0.55.229:9094 [–topic-white-list
afei]，参数–topic-white-list指定要检查的目标topic。输出结果如下，如果输出信息为<code>max lag is 0 for
...</code>表示这个topic的复制没有任何延迟：</p>

<pre><code>2018-07-03 15:04:46,889: verification process is started.
2018-07-03 15:05:16,811: max lag is 0 for partition multi-1 at offset 0 among 5 partitions
2018-07-03 15:05:46,812: max lag is 0 for partition multi-1 at offset 0 among 5 partitions
... ...
</code></pre>

<ul>
<li><strong>kafka-server-start.sh</strong></li>
</ul>

<p>用法：bin/kafka-server-start.sh -daemon
config/server.properties，指定配置文件并以守护进程模式启动。</p>

<ul>
<li><strong>kafka-server-stop.sh</strong></li>
</ul>

<p>用法：bin/kafka-server-stop.sh 。说明，这个命令会kill掉当前服务器上所有kafka
broker。但是这个脚本可能执行结果为：<code>No kafka server to stop</code></p>

<p>分析原因：我们先看一下<code>kafka-server-stop.sh</code>脚本内容，这个脚本非常简单，就是得到所有包含 <strong>kafka.Kafka</strong>
的进程ID，但是由于kafka启动依赖比较多的jar，导致kafka进程的<code>ps</code>结果输出内容比较长，而<code>ps</code>输出结果受到<code>PAGE_SIZE</code>（其值通过命令<code>getconf
PAGE_SIZE</code>可以得到）的限制，从而导致<code>ps</code>结果中看不到<code>kafka\.Kafka</code>，所以不能kill掉kafka server：</p>

<pre><code>SIGNAL=${SIGNAL:-TERM}
PIDS=$(ps ax | grep -i 'kafka\.Kafka' | grep java | grep -v grep | awk '{print $1}')

if [ -z &quot;$PIDS&quot; ]; then
  echo &quot;No kafka server to stop&quot;
  exit 1
else
  kill -s $SIGNAL $PIDS
fi
</code></pre>

<p>为了kafka-server-stop.sh脚本可以正常执行，建议修改脚本如下，通过bin脚本所在目录的上级目录来查找进程ID，从而kill相关进程：</p>

<pre><code>cd `dirname $0`
BIN_DIR=`pwd`
cd ..
DEPLOY_DIR=`pwd`
SIGNAL=${SIGNAL:-TERM}

PIDS=$(ps ax | grep -i &quot;${DEPLOY_DIR}&quot; | grep java | grep -v grep | awk '{print $1}')

if [ -z &quot;$PIDS&quot; ]; then
  echo &quot;No kafka server to stop&quot;
  exit 1
else
  kill -s $SIGNAL $PIDS
fi
</code></pre>

<ul>
<li><strong>kafka-simple-consumer-shell.sh</strong></li>
</ul>

<p>deprecated，用法：bin/kafka-simple-consumer-shell.sh –broker-list
10.0.55.229:9092,10.0.55.229:9093,10.0.55.229:9094 –topic afei</p>

<ul>
<li><strong>kafka-topics.sh</strong></li>
</ul>

<p><strong>创建topic:</strong> bin/kafka-topics.sh –zookeeper localhost:2181 –create –topic afei
–partitions 3 –replication-factor 1<br />
<strong>删除topic</strong> : bin/kafka-topics.sh –zookeeper localhost:2181 –delete –topic
test<br />
<strong>修改topic</strong> : bin/kafka-topics.sh –zookeeper localhost:2181 –alter –topic afei
–partitions 5，修改topic时只能增加分区数量。<br />
<strong>查询topic</strong> : bin/kafka-topics.sh –zookeeper localhost:2181 –describe [ –topic
afei ]，查询时如果带上<code>--topic topicName</code>，那么表示只查询该topic的详细信息。这时候还可以带上<code>--unavailable-
partitions</code> 和<code>--under-replicated-partitions</code>任意一个参数。</p>

<ul>
<li><strong>kafka-verifiable-consumer.sh</strong></li>
</ul>

<p>用法：bin/kafka-verifiable-consumer.sh –broker-list
10.0.55.229:9092,10.0.55.229:9093,10.0.55.229:9094 –topic afei –group-id
groupName<br />
这个脚本的作用是接收指定topic的消息消费，并发出消费者事件，例如：offset提交等。</p>

<ul>
<li><strong>kafka-verifiable-producer.sh</strong></li>
</ul>

<p>用法：bin/kafka-verifiable-producer.sh –broker-list
10.0.55.229:9092,10.0.55.229:9093,10.0.55.229:9094 –topic afei [–max-messages
64]，建议使用该脚本时增加参数<code>--max-messages</code>，否则会不停的发送消息。<br />
这个脚本的作用是持续发送消息到指定的topic中，参数<code>--max-
messages</code>限制最大发送消息数。且每条发送的消息都会有响应信息，这就是和<code>kafka-console-producer.sh</code>最大的不同：</p>

<pre><code>[mwopr@jtcrtvdra35 kafka_2.12-1.1.0]$ bin/kafka-verifiable-producer.sh  --broker-list 10.0.55.229:9092,10.0.55.229:9093,10.0.55.229:9094 --topic afei --max-messages 9
{&quot;timestamp&quot;:1530515959900,&quot;name&quot;:&quot;startup_complete&quot;}
{&quot;timestamp&quot;:1530515960310,&quot;name&quot;:&quot;producer_send_success&quot;,&quot;key&quot;:null,&quot;value&quot;:&quot;1&quot;,&quot;offset&quot;:5,&quot;topic&quot;:&quot;afei&quot;,&quot;partition&quot;:0}
{&quot;timestamp&quot;:1530515960315,&quot;name&quot;:&quot;producer_send_success&quot;,&quot;key&quot;:null,&quot;value&quot;:&quot;4&quot;,&quot;offset&quot;:6,&quot;topic&quot;:&quot;afei&quot;,&quot;partition&quot;:0}
{&quot;timestamp&quot;:1530515960315,&quot;name&quot;:&quot;producer_send_success&quot;,&quot;key&quot;:null,&quot;value&quot;:&quot;7&quot;,&quot;offset&quot;:7,&quot;topic&quot;:&quot;afei&quot;,&quot;partition&quot;:0}
{&quot;timestamp&quot;:1530515960316,&quot;name&quot;:&quot;producer_send_success&quot;,&quot;key&quot;:null,&quot;value&quot;:&quot;0&quot;,&quot;offset&quot;:5,&quot;topic&quot;:&quot;afei&quot;,&quot;partition&quot;:1}
{&quot;timestamp&quot;:1530515960316,&quot;name&quot;:&quot;producer_send_success&quot;,&quot;key&quot;:null,&quot;value&quot;:&quot;3&quot;,&quot;offset&quot;:6,&quot;topic&quot;:&quot;afei&quot;,&quot;partition&quot;:1}
{&quot;timestamp&quot;:1530515960316,&quot;name&quot;:&quot;producer_send_success&quot;,&quot;key&quot;:null,&quot;value&quot;:&quot;6&quot;,&quot;offset&quot;:7,&quot;topic&quot;:&quot;afei&quot;,&quot;partition&quot;:1}
{&quot;timestamp&quot;:1530515960316,&quot;name&quot;:&quot;producer_send_success&quot;,&quot;key&quot;:null,&quot;value&quot;:&quot;2&quot;,&quot;offset&quot;:6,&quot;topic&quot;:&quot;afei&quot;,&quot;partition&quot;:2}
{&quot;timestamp&quot;:1530515960316,&quot;name&quot;:&quot;producer_send_success&quot;,&quot;key&quot;:null,&quot;value&quot;:&quot;5&quot;,&quot;offset&quot;:7,&quot;topic&quot;:&quot;afei&quot;,&quot;partition&quot;:2}
{&quot;timestamp&quot;:1530515960316,&quot;name&quot;:&quot;producer_send_success&quot;,&quot;key&quot;:null,&quot;value&quot;:&quot;8&quot;,&quot;offset&quot;:8,&quot;topic&quot;:&quot;afei&quot;,&quot;partition&quot;:2}
{&quot;timestamp&quot;:1530515960333,&quot;name&quot;:&quot;shutdown_complete&quot;}
{&quot;timestamp&quot;:1530515960334,&quot;name&quot;:&quot;tool_data&quot;,&quot;sent&quot;:9,&quot;acked&quot;:9,&quot;target_throughput&quot;:-1,&quot;avg_throughput&quot;:20.689655172413794}
</code></pre>

<blockquote>
<p>afei这个topic有3个分区，使用kafka-verifiable-
producer.sh发送9条消息。根据输出结果可以看出，往每个分区发送了3条消息。另外，我们可以通过设置参数<code>--max-
messages</code>一个比较大的值，可以压测一下搭建的kafka集群环境。</p>
</blockquote>

<ul>
<li><strong>zookeeper-shell.sh</strong></li>
</ul>

<p>用法：bin/zookeeper-shell.sh
localhost:2181[/path]，如果kafka集群的zk配置了chroot路径，那么需要加上/path，例如<code>bin/zookeeper-
shell.sh
localhost:2181/mykafka</code>，登陆zk后，就可以查看kafka写在zk上的节点信息。例如查看有哪些broker，以及broker的详细信息：</p>

<pre><code>ls /brokers/ids
[0]
get /brokers/ids/0
{&quot;listener_security_protocol_map&quot;:{&quot;PLAINTEXT&quot;:&quot;PLAINTEXT&quot;},&quot;endpoints&quot;:[&quot;PLAINTEXT://izwz91rhzhed2c54e6yx87z:9092&quot;],&quot;jmx_port&quot;:-1,&quot;host&quot;:&quot;izwz91rhzhed2c54e6yx87z&quot;,&quot;timestamp&quot;:&quot;1530435834272&quot;,&quot;port&quot;:9092,&quot;version&quot;:4}
cZxid = 0x2d3
ctime = Sun Jul 01 17:03:54 CST 2018
mZxid = 0x2d3
mtime = Sun Jul 01 17:03:54 CST 2018
pZxid = 0x2d3
cversion = 0
dataVersion = 0
aclVersion = 0
ephemeralOwner = 0x1642cb09421006c
dataLength = 216
numChildren = 0
</code></pre>

<ul>
<li>写在最后</li>
</ul>

<p>上面的这些kafka运维脚本，有些是指定参数–zookeeper，有些是指定参数–broker-list，有些是指定参数–bootstrap-server。<br />
这实际上是历史问题。broker-list代表broker地址，而bootstrap-
server代表连接起点，可以从中拉取broker地址信息（前面的[4. kafka生产者&amp;消费者]已经分析过）。bootstrap-
server的命名更高级点。还有通过zookeeper连接的，kafka早起很多信息存方在zk中，后期慢慢弱化了zk的作用，这三个参数代表kafka的三个时代。往好的讲是见证kafka设计的理念变迁，往坏的讲：什么**玩意儿，绕的一笔（来自厮大大的解答），哈。</p>

        </div>

        


        

<div class="post-archive">
    <h2>See Also</h2>
    <ul class="listing">
        
        <li><a href="/posts/007hadoop%E9%9B%86%E7%BE%A4%E9%85%8D%E7%BD%AEhadoop%E9%9B%86%E7%BE%A4%E7%9A%84%E5%90%AF%E5%8A%A8%E5%92%8C%E6%B5%8B%E8%AF%95ssh%E5%85%8D%E7%99%BB%E9%99%86%E9%85%8D%E7%BD%AEstartallshhdfs%E5%B8%B8%E7%94%A8%E7%9A%84shell/">007Hadoop集群配置Hadoop集群的启动和测试SSH免登陆配置startallshhdfs常用的shell</a></li>
        
        <li><a href="/posts/009shell%E8%84%9A%E6%9C%AC%E4%B8%8B%E6%9D%A1%E4%BB%B6%E6%B5%8B%E8%AF%95eqne/">009Shell脚本下条件测试eqne</a></li>
        
        <li><a href="/posts/00pythonmanagepyshell%E5%92%8Cpython%E7%9A%84%E5%88%86%E6%9E%90/">00Pythonmanagepyshell和Python的分析</a></li>
        
        <li><a href="/posts/010zookeeper%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5zookeeper%E7%9A%84%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BAzookeeper%E7%9A%84shell%E5%91%BD%E4%BB%A4/">010Zookeeper的基本概念Zookeeper的集群搭建Zookeeper的shell命令</a></li>
        
        <li><a href="/posts/018dockerfileshell/">018DockerfileSHELL</a></li>
        
    </ul>
</div>


        <div class="post-meta meta-tags">
            
            <ul class="clearfix">
                
                <li><a href='https://zaina.newban.cn/tags/shell'>shell</a></li>
                
            </ul>
            
        </div>
    </article>
    
    

    
    
</div>

                    <footer id="footer">
    <div>
        &copy; 2020 <a href="https://zaina.newban.cn">开发者问答集锦 By </a>
        
    </div>
    <br />
    <div>
        <div class="github-badge">
            <a href="https://gohugo.io/" target="_black" rel="nofollow"><span class="badge-subject">Powered by</span><span class="badge-value bg-blue">Hugo</span></a>
        </div>
        <div class="github-badge">
            <a href="https://www.flysnow.org/" target="_black"><span class="badge-subject">Design by</span><span class="badge-value bg-brightgreen">飞雪无情</span></a>
        </div>
        <div class="github-badge">
            <a href="https://github.com/flysnow-org/maupassant-hugo" target="_black"><span class="badge-subject">Theme</span><span class="badge-value bg-yellowgreen">Maupassant</span></a>
        </div>
    </div>
</footer>


    
    <script type="text/javascript">
        window.MathJax = {
            tex2jax: {
                inlineMath: [['$', '$']],
                processEscapes: true
                }
            };
    </script>
    <script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML' async></script>

<a id="rocket" href="#top"></a>
<script type="text/javascript" src='/js/totop.js?v=0.0.0' async=""></script>



    <script type="text/javascript" src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script>




                </div>

                <div id="secondary">
    <section class="widget">
        <form id="search" action='https://zaina.newban.cn/search/' method="get" accept-charset="utf-8" target="_blank" _lpchecked="1">
      
      <input type="text" name="q" maxlength="20" placeholder="Search">
      <input type="hidden" name="sitesearch" value="https://zaina.newban.cn">
      <button type="submit" class="submit icon-search"></button>
</form>
    </section>
    
    <section class="widget">
        <h3 class="widget-title">最近文章</h3>
<ul class="widget-list">
    
    <li>
        <a href="https://zaina.newban.cn/posts/001rubyruby%E4%B8%AD%E5%85%A8%E5%B1%80%E5%8F%98%E9%87%8F%E5%AE%9E%E4%BE%8B%E5%8F%98%E9%87%8F%E5%B1%80%E9%83%A8%E5%8F%98%E9%87%8F%E7%B1%BB%E5%8F%98%E9%87%8Fsymbol%E5%AF%B9%E6%AF%94/" title="001rubyRuby中全局变量实例变量局部变量类变量Symbol对比">001rubyRuby中全局变量实例变量局部变量类变量Symbol对比</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/007hadoop%E9%9B%86%E7%BE%A4%E9%85%8D%E7%BD%AEhadoop%E9%9B%86%E7%BE%A4%E7%9A%84%E5%90%AF%E5%8A%A8%E5%92%8C%E6%B5%8B%E8%AF%95ssh%E5%85%8D%E7%99%BB%E9%99%86%E9%85%8D%E7%BD%AEstartallshhdfs%E5%B8%B8%E7%94%A8%E7%9A%84shell/" title="007Hadoop集群配置Hadoop集群的启动和测试SSH免登陆配置startallshhdfs常用的shell">007Hadoop集群配置Hadoop集群的启动和测试SSH免登陆配置startallshhdfs常用的shell</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/009shell%E8%84%9A%E6%9C%AC%E4%B8%8B%E6%9D%A1%E4%BB%B6%E6%B5%8B%E8%AF%95eqne/" title="009Shell脚本下条件测试eqne">009Shell脚本下条件测试eqne</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/00pythonmanagepyshell%E5%92%8Cpython%E7%9A%84%E5%88%86%E6%9E%90/" title="00Pythonmanagepyshell和Python的分析">00Pythonmanagepyshell和Python的分析</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/010zookeeper%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5zookeeper%E7%9A%84%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BAzookeeper%E7%9A%84shell%E5%91%BD%E4%BB%A4/" title="010Zookeeper的基本概念Zookeeper的集群搭建Zookeeper的shell命令">010Zookeeper的基本概念Zookeeper的集群搭建Zookeeper的shell命令</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/018dockerfileshell/" title="018DockerfileSHELL">018DockerfileSHELL</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/01shell%E5%85%A5%E9%97%A801bashshell%E7%89%B9%E6%80%A7/" title="01Shell入门01bashShell特性">01Shell入门01bashShell特性</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/01shell%E5%8F%98%E9%87%8F/" title="01Shell变量">01Shell变量</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/01shell%E5%9F%BA%E7%A1%80%E6%A6%82%E8%BF%B0%E8%84%9A%E6%9C%AC%E6%89%A7%E8%A1%8C%E6%96%B9%E5%BC%8Fbash%E5%9F%BA%E6%9C%AC%E5%8A%9F%E8%83%BD/" title="01Shell基础概述脚本执行方式Bash基本功能">01Shell基础概述脚本执行方式Bash基本功能</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/01shell%E7%BC%96%E7%A8%8Bhelloworld/" title="01shell编程helloworld">01shell编程helloworld</a>
    </li>
    
</ul>
    </section>

    

    <section class="widget">
        <h3 class="widget-title"><a href="/categories">分类</a></h3>
<ul class="widget-list">
    
</ul>
    </section>

    <section class="widget">
        <h3 class="widget-title"><a href="/tags">标签</a></h3>
<div class="tagcloud">
    
    <a href="https://zaina.newban.cn/tags/ruby/">ruby</a>
    
    <a href="https://zaina.newban.cn/tags/shell/">shell</a>
    
</div>
    </section>

    

    <section class="widget">
        <h3 class="widget-title">其它</h3>
        <ul class="widget-list">
            <li><a href="https://zaina.newban.cn/index.xml">文章 RSS</a></li>
        </ul>
    </section>
</div>
            </div>
        </div>
    </div>
</body>

</html>