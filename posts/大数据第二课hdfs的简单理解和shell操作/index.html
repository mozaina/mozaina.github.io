<!doctype html>
<html lang="en-us">
<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">


    <title>大数据第二课HDFS的简单理解和shell操作 | 开发者问答集锦</title>
    <meta property="og:title" content="大数据第二课HDFS的简单理解和shell操作 - 开发者问答集锦">
    <meta property="og:type" content="article">
        
    <meta property="article:published_time" content='2020-09-02T00:00:00&#43;08:00'>
        
        
    <meta property="article:modified_time" content='2020-09-02T00:00:00&#43;08:00'>
        
    <meta name="Keywords" content="">
    <meta name="description" content="大数据第二课HDFS的简单理解和shell操作">
        
    <meta name="author" content="">
    <meta property="og:url" content="https://zaina.newban.cn/posts/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%AC%AC%E4%BA%8C%E8%AF%BEhdfs%E7%9A%84%E7%AE%80%E5%8D%95%E7%90%86%E8%A7%A3%E5%92%8Cshell%E6%93%8D%E4%BD%9C/">
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">

    <link rel="stylesheet" href='/css/normalize.css'>
    <link rel="stylesheet" href='/css/style.css'>
    <script type="text/javascript" src="//cdn.bootcdn.net/ajax/libs/jquery/3.4.1/jquery.min.js"></script>

    
    
    
    
    
    
</head>


<body>
    <header id="header" class="clearfix">
    <div class="container">
        <div class="col-group">
            <div class="site-name ">
                
                    <a id="logo" href="https://zaina.newban.cn">
                        开发者问答集锦
                    </a>
                
                
            </div>
            <div>
                <nav id="nav-menu" class="clearfix">
                    <a class="" href="https://zaina.newban.cn">首页</a>
                    
                </nav>
            </div>
        </div>
    </div>
</header>

    <div id="body">
        <div class="container">
            <div class="col-group">

                <div class="col-8" id="main">
                    
<div class="res-cons">
    
    <article class="post">
        <header>
            <h1 class="post-title">大数据第二课HDFS的简单理解和shell操作</h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        
        <div class="post-meta">
            <span id="busuanzi_container_page_pv">|<span id="busuanzi_value_page_pv"></span><span>
                    阅读</span></span>
        </div>
        
        
        <div class="post-content">
            <p>1、HDFS 是做什么的</p>

<p>HDFS（Hadoop Distributed File
System）是Hadoop项目的核心子项目，是分布式计算中数据存储管理的基础，是基于流数据模式访问和处理超大文件的需求而开发的，可以运行于廉价的商用服务器上。它所具有的高容错、高可靠性、高可扩展性、高获得性、高吞吐率等特征为海量数据提供了不怕故障的存储，为超大数据集（Large
Data Set）的应用处理带来了很多便利。</p>

<p>2、HDFS 从何而来</p>

<p>HDFS 源于 Google 在2003年10月份发表的GFS（Google File System） 论文。 它其实就是 GFS 的一个克隆版本</p>

<p>3、为什么选择 HDFS 存储数据</p>

<p>之所以选择 HDFS 存储数据，因为 HDFS 具有以下优点：</p>

<p>1、高容错性</p>

<ul>
<li><p>数据自动保存多个副本。它通过增加副本的形式，提高容错性。</p></li>

<li><p>某一个副本丢失以后，它可以自动恢复，这是由 HDFS 内部机制实现的，我们不必关心。</p></li>
</ul>

<p>2、适合批处理</p>

<ul>
<li><p>它是通过移动计算而不是移动数据。</p></li>

<li><p>它会把数据位置暴露给计算框架。</p></li>
</ul>

<p>3、适合大数据处理</p>

<ul>
<li><p>处理数据达到 GB、TB、甚至PB级别的数据。</p></li>

<li><p>能够处理百万规模以上的文件数量，数量相当之大。</p></li>

<li><p>能够处理10K节点的规模。</p></li>
</ul>

<p>4、流式文件访问</p>

<ul>
<li><p>一次写入，多次读取。文件一旦写入不能修改，只能追加。</p></li>

<li><p>它能保证数据的一致性。</p></li>
</ul>

<p>5、可构建在廉价机器上</p>

<ul>
<li><p>它通过多副本机制，提高可靠性。</p></li>

<li><p>它提供了容错和恢复机制。比如某一个副本丢失，可以通过其它副本来恢复。</p></li>
</ul>

<p>当然 HDFS 也有它的劣势，并不适合所有的场合：</p>

<p>1、低延时数据访问</p>

<ul>
<li><p>比如毫秒级的来存储数据，这是不行的，它做不到。</p></li>

<li><p>它适合高吞吐率的场景，就是在某一时间内写入大量的数据。但是它在低延时的情况下是不行的，比如毫秒级以内读取数据，这样它是很难做到的。</p></li>
</ul>

<p>2、小文件存储</p>

<ul>
<li><p>存储大量小文件(这里的小文件是指小于HDFS系统的Block大小的文件（默认64M）)的话，它会占用 NameNode大量的内存来存储文件、目录和块信息。这样是不可取的，因为NameNode的内存总是有限的。</p></li>

<li><p>小文件存储的寻道时间会超过读取时间，它违反了HDFS的设计目标。</p></li>
</ul>

<p>3、并发写入、文件随机修改</p>

<ul>
<li><p>一个文件只能有一个写，不允许多个线程同时写。</p></li>

<li><p>仅支持数据 append（追加），不支持文件的随机修改。</p></li>
</ul>

<p>4、HDFS 如何存储数据</p>

<p><img src="https://img.it610.com/image/info8/a9c922a6a8e84d2988004a9dcabb6975.jpg" alt="" /></p>

<p>HDFS的架构图</p>

<p>HDFS 采用Master/Slave的架构来存储数据，这种架构主要由四个部分组成，分别为HDFS
Client、NameNode、DataNode和Secondary NameNode。下面我们分别介绍这四个组成部分</p>

<p>1、Client：就是客户端。</p>

<ul>
<li>文件切分。文件上传 HDFS 的时候，Client 将文件切分成 一个一个的Block，然后进行存储。</li>
<li>与 NameNode 交互，获取文件的位置信息。</li>
<li>与 DataNode 交互，读取或者写入数据。</li>
<li>Client 提供一些命令来管理 HDFS，比如启动或者关闭HDFS。</li>
<li>Client 可以通过一些命令来访问 HDFS。</li>
</ul>

<p>2、NameNode：就是 master，它是一个主管、管理者。</p>

<ul>
<li>管理 HDFS 的名称空间</li>
<li>管理数据块（Block）映射信息</li>
<li>配置副本策略</li>
<li>处理客户端读写请求。</li>
</ul>

<p>3、DataNode：就是Slave。NameNode 下达命令，DataNode 执行实际的操作。</p>

<ul>
<li>存储实际的数据块。</li>
<li>执行数据块的读/写操作。</li>
</ul>

<p>4、Secondary NameNode：并非 NameNode 的热备。当NameNode 挂掉的时候，它并不能马上替换 NameNode 并提供服务。</p>

<ul>
<li>辅助 NameNode，分担其工作量。</li>
<li>定期合并 fsimage和fsedits，并推送给NameNode。</li>
<li>在紧急情况下，可辅助恢复 NameNode。</li>
</ul>

<p>5、HDFS 如何读取文件</p>

<p><img src="https://img.it610.com/image/info8/cf461d01de9f4c99a88b66c4f19159f1.jpg" alt="" /></p>

<p>HDFS的文件读取原理，主要包括以下几个步骤：</p>

<ul>
<li>首先调用FileSystem对象的open方法，其实获取的是一个DistributedFileSystem的实例。</li>
<li>DistributedFileSystem通过RPC(远程过程调用)获得文件的第一批block的locations，同一block按照重复数会返回多个locations，这些locations按照hadoop拓扑结构排序，距离客户端近的排在前面。</li>
<li>前两步会返回一个FSDataInputStream对象，该对象会被封装成 DFSInputStream对象，DFSInputStream可以方便的管理datanode和namenode数据流。客户端调用read方法，DFSInputStream就会找出离客户端最近的datanode并连接datanode。</li>
<li>数据从datanode源源不断的流向客户端。</li>
<li>如果第一个block块的数据读完了，就会关闭指向第一个block块的datanode连接，接着读取下一个block块。这些操作对客户端来说是透明的，从客户端的角度来看只是读一个持续不断的流。</li>
<li>如果第一批block都读完了，DFSInputStream就会去namenode拿下一批blocks的location，然后继续读，如果所有的block块都读完，这时就会关闭掉所有的流。</li>
</ul>

<p>6、HDFS 如何写入文件</p>

<p><img src="https://img.it610.com/image/info8/0838516b27a44f90985643b0fc9c754b.jpg" alt="" /></p>

<p>HDFS的文件写入原理，主要包括以下几个步骤：</p>

<ul>
<li>客户端通过调用 DistributedFileSystem 的create方法，创建一个新的文件。</li>
<li>DistributedFileSystem 通过 RPC（远程过程调用）调用 NameNode，去创建一个没有blocks关联的新文件。创建前，NameNode 会做各种校验，比如文件是否存在，客户端有无权限去创建等。如果校验通过，NameNode 就会记录下新文件，否则就会抛出IO异常。</li>
<li>前两步结束后会返回 FSDataOutputStream 的对象，和读文件的时候相似，FSDataOutputStream 被封装成 DFSOutputStream，DFSOutputStream 可以协调 NameNode和 DataNode。客户端开始写数据到DFSOutputStream,DFSOutputStream会把数据切成一个个小packet，然后排成队列 data queue。</li>
<li>DataStreamer 会去处理接受 data queue，它先问询 NameNode 这个新的 block 最适合存储的在哪几个DataNode里，比如重复数是3，那么就找到3个最适合的 DataNode，把它们排成一个 pipeline。DataStreamer 把 packet 按队列输出到管道的第一个 DataNode 中，第一个 DataNode又把 packet 输出到第二个 DataNode 中，以此类推。</li>
<li>DFSOutputStream 还有一个队列叫 ack queue，也是由 packet 组成，等待DataNode的收到响应，当pipeline中的所有DataNode都表示已经收到的时候，这时akc queue才会把对应的packet包移除掉。</li>
<li>客户端完成写数据后，调用close方法关闭写入流。</li>
<li>DataStreamer 把剩余的包都刷到 pipeline 里，然后等待 ack 信息，收到最后一个 ack 后，通知 DataNode 把文件标示为已完成。</li>
</ul>

<p>7、HDFS 副本存放策略</p>

<p>namenode如何选择在哪个datanode
存储副本（replication）？这里需要对可靠性、写入带宽和读取带宽进行权衡。Hadoop对datanode存储副本有自己的副本策略，在其发展过程中一共有两个版本的副本策略，分别如下所示</p>

<p><img src="https://img.it610.com/image/info8/e9487765886846adadb6c1652bfff552.jpg" alt="" /></p>

<p>8、hadoop2.x新特性</p>

<ul>
<li>引入了NameNode Federation，解决了横向内存扩展</li>
<li>引入了Namenode HA，解决了namenode单点故障</li>
<li>引入了YARN，负责资源管理和调度</li>
<li>增加了ResourceManager HA解决了ResourceManager单点故障</li>
</ul>

<p>1、NameNode Federation</p>

<p>架构如下图</p>

<p><img src="https://img.it610.com/image/info8/65581c1c8bed4b1fb72aee6924f5b90f.jpg" alt="" /></p>

<ul>
<li>存在多个NameNode，每个NameNode分管一部分目录</li>
<li>NameNode共用DataNode</li>
</ul>

<p>这样做的好处就是当NN内存受限时，能扩展内存，解决内存扩展问题，而且每个NN独立工作相互不受影响，比如其中一个NN挂掉啦，它不会影响其他NN提供服务，但我们需要注意的是，虽然有多个NN，分管不同的目录，但是对于特定的NN，依然存在单点故障，因为没有它没有热备，解决单点故障使用NameNode
HA</p>

<p>2、NameNode HA</p>

<p>解决方案：</p>

<ul>
<li>基于NFS共享存储解决方案</li>
<li>基于Qurom Journal Manager(QJM)解决方案</li>
</ul>

<p>1、基于NFS方案</p>

<p>Active NN与Standby NN通过NFS实现共享数据，但如果Active NN与NFS之间或Standby
NN与NFS之间，其中一处有网络故障的话，那就会造成数据同步问题</p>

<p>2、基于QJM方案</p>

<p>架构如下图</p>

<p><img src="https://img.it610.com/image/info8/aeb4f34af2ae47298eb7e4a4485b3673.jpg" alt="" /></p>

<p>Active NN、Standby NN有主备之分，NN Active是主的，NN Standby备用的</p>

<p>集群启动之后，一个namenode是active状态，来处理client与datanode之间的请求，并把相应的日志文件写到本地中或JN中；</p>

<p>Active NN与Standby NN之间是通过一组JN共享数据（JN一般为奇数个，ZK一般也为奇数个），Active
NN会把日志文件、镜像文件写到JN中去，只要JN中有一半写成功，那就表明Active NN向JN中写成功啦，Standby
NN就开始从JN中读取数据，来实现与Active NN数据同步，这种方式支持容错，因为Standby
NN在启动的时候，会加载镜像文件（fsimage）并周期性的从JN中获取日志文件来保持与Active NN同步</p>

<p>为了实现Standby NN在Active NN挂掉之后，能迅速的再提供服务，需要DN不仅需要向Active NN汇报，同时还要向Standby
NN汇报，这样就使得Standby NN能保存数据块在DN上的位置信息，因为在NameNode在启动过程中最费时工作，就是处理所有DN上的数据块的信息</p>

<p>为了实现Active
NN高热备，增加了FailoverController和ZK，FailoverController通过Heartbeat的方式与ZK通信，通过ZK来选举，一旦Active
NN挂掉，就选取另一个FailoverController作为active状态，然后FailoverController通过rpc，让standby
NN转变为Active NN</p>

<p>FailoverController一方面监控NN的状态信息，一方面还向ZK定时发送心跳，使自己被选举。当自己被选为主（Active）的时候，就会通过rpc使相应NN转变Active状态</p>

<p>3、结合HDFS2的新特性，在实际生成环境中部署图</p>

<p><img src="https://img.it610.com/image/info8/d8dfe396e1b0446ebdc6896aafae3536.jpg" alt="" /></p>

<p>这里有12个DN,有4个NN，NN-1与NN-2是主备关系，它们管理/share目录；NN-3与NN-4是主备关系，它们管理/user目录</p>

<p>HDFS设计的主要目的是对海量数据进行存储，也就是说在其上能够存储很大量文件（可以存储TB级的文件）。HDFS将这些文件分割之后，存储在不同的DataNode上，
HDFS 提供了两种访问接口：Shell接口和Java API
接口，对HDFS里面的文件进行操作，具体每个Block放在哪台DataNode上面，对于开发者来说是透明的。</p>

<p>下面将介绍通过Shell接口对HDFS进行操作，HDFS处理文件的命令和Linux命令基本相同，这里区分大小写</p>

<p>目录</p>

<p>1、shell操作单个HDFS集群</p>

<p>2、shell操作多个HDFS集群</p>

<p>3、hadoop管理员其他常见shel操作</p>

<p>1、shell 操作单个HDFS集群</p>

<p>下面列举出几个常用场景下的命令</p>

<ul>
<li>创建文件夹</li>
</ul>

<p>HDFS上的文件目录结构类似Linux，根目录使用&rdquo;/&ldquo;表示。</p>

<p>下面的命令将在/middle(已存在)目录下建立目录weibo</p>

<p>[hadoop@ljc hadoop]$ hadoop fs -mkdir /middle/weibo</p>

<p>效果如下：</p>

<p><a href="https://img.it610.com/image/info8/1ec3b96895d849ae9b85a8e1dd68a2e5.jpg"><img src="https://img.it610.com/image/info8/1ec3b96895d849ae9b85a8e1dd68a2e5.jpg" alt="" /></a></p>

<ul>
<li>上传文件weibo.txt到weibo目录下</li>
</ul>

<p>[hadoop@ljc ~]$ hadoop fs -put weibo.txt /middle/weibo/</p>

<p>效果如下：</p>

<p><a href="https://img.it610.com/image/info8/a919de3242944e4a8aafe87d6deebab5.jpg"><img src="https://img.it610.com/image/info8/a919de3242944e4a8aafe87d6deebab5.jpg" alt="大数据第二课：HDFS的简单理解和shell操作_第1张图片" /></a></p>

<p>还可以使用 -copyFromLocal参数。</p>

<p>[hadoop@ljc ~]$ hadoop fs -copyFromLocal weibo.txt /middle/weibo/</p>

<ul>
<li>查看weibo.txt文件内容。</li>
</ul>

<p>[hadoop@ljc ~]$ hadoop fs -text /middle/weibo/weibo.txt</p>

<p>效果如下：</p>

<p><a href="https://img.it610.com/image/info8/4f2cc5c693e54864991226f7a228f321.png"><img src="https://img.it610.com/image/info8/4f2cc5c693e54864991226f7a228f321.png" alt="" /></a></p>

<p>还可以用 -cat、-tail 参数查看文件的内容。但是对于压缩的结果文件只能用 -text 参数来查看，否则是乱码。</p>

<p>[hadoop@ljc ~]$ hadoop fs -cat /middle/weibo/weibo.txt</p>

<p>[hadoop@ljc ~]$ hadoop fs -tail /middle/weibo/weibo.txt</p>

<ul>
<li>通过终端向&rdquo;/middle/weibo/weibo.txt&rdquo;中输入内容</li>
</ul>

<p>[hadoop@ljc ~]$ hadoop fs -appendToFile - /middle/weibo/weibo.txt</p>

<p>如下所示：</p>

<p><a href="https://img.it610.com/image/info8/6419c363798b4a9e955667ad46bb2b77.jpg"><img src="https://img.it610.com/image/info8/6419c363798b4a9e955667ad46bb2b77.jpg" alt="大数据第二课：HDFS的简单理解和shell操作_第2张图片" /></a></p>

<p>退出终端输入，按Ctrl + C</p>

<ul>
<li>把&rdquo;/middle/weibo/weibo.txt&rdquo;复制到&rdquo;/middle&rdquo;</li>
</ul>

<p>[hadoop@ljc ~]$ hadoop fs -cp /middle/weibo/weibo.txt /middle</p>

<p>效果如下：</p>

<p><a href="https://img.it610.com/image/info8/d765df1302a54bab8b2eb79bf91757b1.jpg"><img src="https://img.it610.com/image/info8/d765df1302a54bab8b2eb79bf91757b1.jpg" alt="" /></a></p>

<ul>
<li>把weibo.txt文件复制到本地。</li>
</ul>

<p>[hadoop@ljc ~]$ hadoop fs -get /middle/weibo/weibo.txt</p>

<p>效果如下：</p>

<p><a href="https://img.it610.com/image/info8/f0cb5e08b57649528d3c20fc9c3eb0ee.png"><img src="https://img.it610.com/image/info8/f0cb5e08b57649528d3c20fc9c3eb0ee.png" alt="大数据第二课：HDFS的简单理解和shell操作_第3张图片" /></a></p>

<p>还可以用 -copyToLocal 参数。</p>

<p>[hadoop@ljc ~]$ hadoop fs -copyToLocal /middle/weibo/weibo.txt</p>

<ul>
<li>删除weibo.txt文件。</li>
</ul>

<p>[hadoop@ljc ~]$ hadoop fs -rm /middle/weibo/weibo.txt</p>

<p>效果如下：</p>

<p><a href="https://img.it610.com/image/info8/e0e6dc27192048c2bc811970f2feadc0.jpg"><img src="https://img.it610.com/image/info8/e0e6dc27192048c2bc811970f2feadc0.jpg" alt="" /></a></p>

<ul>
<li>删除/middle/weibo文件夹。</li>
</ul>

<p>[hadoop@ljc ~]$ hadoop fs -rm -r /middle/weibo</p>

<p>效果如下：</p>

<p><a href="https://img.it610.com/image/info8/a6241fc9b33f423aa7dc74a0f9a3c8cd.jpg"><img src="https://img.it610.com/image/info8/a6241fc9b33f423aa7dc74a0f9a3c8cd.jpg" alt="" /></a></p>

<ul>
<li>显示 /middle 目录下的文件。</li>
</ul>

<p>[hadoop@ljc ~]$ hadoop fs -ls /middle</p>

<p>效果如下：</p>

<p><a href="https://img.it610.com/image/info8/11a45984165840a588db820a344c0f18.jpg"><img src="https://img.it610.com/image/info8/11a45984165840a588db820a344c0f18.jpg" alt="" /></a></p>

<p>2、shell 操作多个 HDFS 集群</p>

<p>上面我们介绍的是访问单个HDFS集群，但是多个Hadoop集群需要复制数据该怎么办呢？幸运的是，Hadoop
有一个有用的distcp分布式复制程序，该程序是由
MapReduce作业来实现的，它是通过集群中并行运行的map来完成集群之间大量数据的复制。下面我们将介绍 distcp在不同场景下该如何使用</p>

<ul>
<li>两个集群运行相同版本的Hadoop</li>
</ul>

<p>确保两个集群版本相同，这里以hadoop1、hadoop2集群为例，如下所示</p>

<p><a href="https://img.it610.com/image/info8/9b46abded1a74da089bc44c9eb083980.jpg"><img src="https://img.it610.com/image/info8/9b46abded1a74da089bc44c9eb083980.jpg" alt="大数据第二课：HDFS的简单理解和shell操作_第4张图片" /></a></p>

<p><a href="https://img.it610.com/image/info8/5573c22f566b4915bb031ae567d75555.jpg"><img src="https://img.it610.com/image/info8/5573c22f566b4915bb031ae567d75555.jpg" alt="大数据第二课：HDFS的简单理解和shell操作_第5张图片" /></a></p>

<p>1)、两个 HDFS 集群之间传输数据，默认情况下 distcp 会跳过目标路径下已经存在的文件</p>

<p>[hadoop@hadoop1 ~]$ hadoop distcp /weather hdfs://hadoop2:9000/middle</p>

<p>效果如下：</p>

<p><img src="https://img.it610.com/image/info8/a2b2987d69bd45f6a4caa0fb5f0cc8df.png" alt="" /></p>

<p>这条指令是在hadoop1中执行，意思是把/weather目录及其内容复制到hadoop2集群的/middle目录下，所以hadoop2集群最后的目录结构为/middle/weather</p>

<p>如下所示</p>

<p><a href="https://img.it610.com/image/info8/172231baec4e4804810639cad14c62cf.png"><img src="https://img.it610.com/image/info8/172231baec4e4804810639cad14c62cf.png" alt="" /></a></p>

<p>如果/middle 不存在，则新建一个。也可以指定多个源路径，并把所有路径都复制到目标路径下。</p>

<p>这里的目标路径（hadoop2）必须是绝对路径，源路径（hadoop1）可以是绝对路径，也可以是相对路径，因为我是在hadoop1中执行的，且默认是HDFS协议</p>

<p>在执行这条指令时可能会报错</p>

<p>如下所示</p>

<p><a href="https://img.it610.com/image/info8/29e31b5003b2484280ad66a036a288f5.jpg"><img src="https://img.it610.com/image/info8/29e31b5003b2484280ad66a036a288f5.jpg" alt="大数据第二课：HDFS的简单理解和shell操作_第6张图片" /></a></p>

<p>这是因为没有把hadoop2(hadoop2对应IP：192.168.233.130)追加到/etc/hosts文件中，如下所示</p>

<p><a href="https://img.it610.com/image/info8/5db261af9e534bf4a889cfff13c760ae.jpg"><img src="https://img.it610.com/image/info8/5db261af9e534bf4a889cfff13c760ae.jpg" alt="大数据第二课：HDFS的简单理解和shell操作_第7张图片" /></a></p>

<p>如果指令在hadoop2中执行，可以这样写，如下</p>

<p>[hadoop@hadoop2 ~]$ hadoop distcp hdfs://hadoop1:9000/weather /middle</p>

<p>效果如下：</p>

<p><img src="https://img.it610.com/image/info8/7eac59772e2f4abda449ebd0c87fdf54.png" alt="" /></p>

<p>这时，源路径就必须写绝对路径，目录路径可以是绝对路径，也可以是相对路径，因为我是在hadoop2中执行的，且默认是HDFS协议，如果报错，请参考上面</p>

<p>2)、两个 HDFS 集群之间传输数据，覆盖现有的文件使用overwrite</p>

<p>[hadoop@hadoop1 ~]$ hadoop distcp -overwrite /weather
hdfs://hadoop2:9000/middle/weather</p>

<p>如下所示</p>

<p><img src="https://img.it610.com/image/info8/0200df749a484a81a64174ee80d0df08.jpg" alt="" /></p>

<p>注意，在overwrite时，只是将/weather中的内容覆盖到&rdquo;hdfs://hadoop2:9000/middle/weather&rdquo;中，不包含/weather目录本身，所以在overwrite时，目录路径加上了/weather</p>

<p>3)、两个 HDFS 集群之间传输数据，更新有改动过的文件使用update。</p>

<p>[hadoop@hadoop1 ~]$ hadoop distcp -update /weather
hdfs://hadoop2:9000/middle/weather</p>

<p>效果如下：</p>

<p><img src="https://img.it610.com/image/info8/483250c3f8d44c419387f655fe9d61b9.jpg" alt="" /></p>

<p>注意，在update时，只是将/weather中的内容覆盖到&rdquo;hdfs://hadoop2:9000/middle/weather&rdquo;中，不包含/weather目录本身，所以在update时，目录路径加上了/weather</p>

<ul>
<li>两个集群运行不同版本的Hadoop</li>
</ul>

<p>不同版本Hadoop集群的RPC是不兼容的，使用distcp复制数据并使用hdfs协议，会导致复制作业失败。想要弥补这种情况，可以在下面两种方式选择一种；下面以hadoop1、hadoop3两个集群为例，版本如下</p>

<p><a href="https://img.it610.com/image/info8/2bae7c3a8d634ac6aa6847a5b8fae7ee.jpg"><img src="https://img.it610.com/image/info8/2bae7c3a8d634ac6aa6847a5b8fae7ee.jpg" alt="大数据第二课：HDFS的简单理解和shell操作_第8张图片" /></a></p>

<p><a href="https://img.it610.com/image/info8/103b2cab98dd4c81b3c05b0d81c5e182.jpg"><img src="https://img.it610.com/image/info8/103b2cab98dd4c81b3c05b0d81c5e182.jpg" alt="大数据第二课：HDFS的简单理解和shell操作_第9张图片" /></a></p>

<p>1)、基于hftp实现两个HDFS集群之间传输数据</p>

<p>[hadoop@hadoop3 ~]$ hadoop distcp hftp://hadoop1:50070/weather /middle</p>

<p>如下所示</p>

<p><img src="https://img.it610.com/image/info8/6083d6a931cd45aa81964eeb41227d5c.png" alt="" /></p>

<p>有三点需要说明：</p>

<p>1、这个命令必须运行在目标集群上，进而实现hdfs RPC版本的兼容</p>

<p>2、hftp地址由dfs.http.address属性决定的，其端口默认值为50070</p>

<p>3、该命令是将hftp://hadoop1:9000/weather中内容传输到/middle目录中，不包含/middle目录本身</p>

<p>2)、基于webhdfs实现两个HDFS集群之间传输数据</p>

<p>如果使用新出的webhdfs协议（替代 hftp）后，对源集群和目标集群均可以使用 HTTP协议进行通信，且不会造成任何不兼容的问题</p>

<p>[hadoop@hadoop3 ~]$ hadoop distcp webhdfs://hadoop1:50070/weather
webhdfs://hadoop3:50070/middle</p>

<p>如下所示</p>

<p><img src="https://img.it610.com/image/info8/9c79fecc11bd4a58843c7587162fb8bd.jpg" alt="" /></p>

<p>3、Hadoop管理员其他常见shell操作</p>

<p>掌握了 shell 如何访问 HDFS，作为 Hadoop 管理员，还需要掌握如下常见命令</p>

<ul>
<li>查看正在运行的Job。</li>
</ul>

<p>[hadoop@hadoop1 ~]$ hadoop job –list</p>

<p>如下所示</p>

<p><img src="https://img.it610.com/image/info8/c5b78437140c4278a36fd3af4a5e22ff.png" alt="" /></p>

<ul>
<li>关闭正在运行的Job</li>
</ul>

<p>[hadoop@hadoop1 ~]$ hadoop job -kill job_1432108212572_0001</p>

<p>如下所示</p>

<p><img src="https://img.it610.com/image/info8/bd4858ac76c5452cadc6a4396a39cb88.png" alt="" /></p>

<ul>
<li>检查 HDFS 块状态，查看是否损坏。</li>
</ul>

<p>[hadoop@hadoop1 ~]$ hadoop fsck /</p>

<ul>
<li>检查 HDFS 块状态，并删除损坏的块。</li>
</ul>

<p>[hadoop@hadoop1 ~]$ hadoop fsck / -delete</p>

<ul>
<li>检查 HDFS 状态，包括 DataNode 信息。</li>
</ul>

<p>[hadoop@hadoop1 ~]$ hadoop dfsadmin -report</p>

<ul>
<li>Hadoop 进入安全模式。</li>
</ul>

<p>[hadoop@hadoop1 ~]$ hadoop dfsadmin -safemode enter</p>

<p>如下所示</p>

<p><a href="https://img.it610.com/image/info8/f252c4cb79c7459c93cadd54095465c7.png"><img src="https://img.it610.com/image/info8/f252c4cb79c7459c93cadd54095465c7.png" alt="" /></a></p>

<ul>
<li>Hadoop 离开安全模式。</li>
</ul>

<p>[hadoop@hadoop1 ~]$ hadoop dfsadmin -safemode leave</p>

<p>如下所示</p>

<p><a href="https://img.it610.com/image/info8/fbdaf5a7378a4f58a4d9defe2618a02e.png"><img src="https://img.it610.com/image/info8/fbdaf5a7378a4f58a4d9defe2618a02e.png" alt="" /></a></p>

<ul>
<li>平衡集群中的文件</li>
</ul>

<p>[hadoop@hadoop1 ~]$ /usr/java/hadoop/sbin/start-balancer.sh</p>

<p>start-balancer.sh命令位于hadoop安装路径下的/sbin下</p>

<p>如下所示</p>

<p><a href="https://img.it610.com/image/info8/b588a8a335d04addb974fb2f68e36561.jpg"><img src="https://img.it610.com/image/info8/b588a8a335d04addb974fb2f68e36561.jpg" alt="" /></a></p>

        </div>

        


        

<div class="post-archive">
    <h2>See Also</h2>
    <ul class="listing">
        
        <li><a href="/posts/007hadoop%E9%9B%86%E7%BE%A4%E9%85%8D%E7%BD%AEhadoop%E9%9B%86%E7%BE%A4%E7%9A%84%E5%90%AF%E5%8A%A8%E5%92%8C%E6%B5%8B%E8%AF%95ssh%E5%85%8D%E7%99%BB%E9%99%86%E9%85%8D%E7%BD%AEstartallshhdfs%E5%B8%B8%E7%94%A8%E7%9A%84shell/">007Hadoop集群配置Hadoop集群的启动和测试SSH免登陆配置startallshhdfs常用的shell</a></li>
        
        <li><a href="/posts/009shell%E8%84%9A%E6%9C%AC%E4%B8%8B%E6%9D%A1%E4%BB%B6%E6%B5%8B%E8%AF%95eqne/">009Shell脚本下条件测试eqne</a></li>
        
        <li><a href="/posts/00pythonmanagepyshell%E5%92%8Cpython%E7%9A%84%E5%88%86%E6%9E%90/">00Pythonmanagepyshell和Python的分析</a></li>
        
        <li><a href="/posts/010zookeeper%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5zookeeper%E7%9A%84%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BAzookeeper%E7%9A%84shell%E5%91%BD%E4%BB%A4/">010Zookeeper的基本概念Zookeeper的集群搭建Zookeeper的shell命令</a></li>
        
        <li><a href="/posts/018dockerfileshell/">018DockerfileSHELL</a></li>
        
    </ul>
</div>


        <div class="post-meta meta-tags">
            
            <ul class="clearfix">
                
                <li><a href='https://zaina.newban.cn/tags/shell'>shell</a></li>
                
            </ul>
            
        </div>
    </article>
    
    

    
    
</div>

                    <footer id="footer">
    <div>
        &copy; 2020 <a href="https://zaina.newban.cn">开发者问答集锦 By </a>
        
    </div>
    <br />
    <div>
        <div class="github-badge">
            <a href="https://gohugo.io/" target="_black" rel="nofollow"><span class="badge-subject">Powered by</span><span class="badge-value bg-blue">Hugo</span></a>
        </div>
        <div class="github-badge">
            <a href="https://www.flysnow.org/" target="_black"><span class="badge-subject">Design by</span><span class="badge-value bg-brightgreen">飞雪无情</span></a>
        </div>
        <div class="github-badge">
            <a href="https://github.com/flysnow-org/maupassant-hugo" target="_black"><span class="badge-subject">Theme</span><span class="badge-value bg-yellowgreen">Maupassant</span></a>
        </div>
    </div>
</footer>


    
    <script type="text/javascript">
        window.MathJax = {
            tex2jax: {
                inlineMath: [['$', '$']],
                processEscapes: true
                }
            };
    </script>
    <script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML' async></script>

<a id="rocket" href="#top"></a>
<script type="text/javascript" src='/js/totop.js?v=0.0.0' async=""></script>



    <script type="text/javascript" src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script>




                </div>

                <div id="secondary">
    <section class="widget">
        <form id="search" action='https://zaina.newban.cn/search/' method="get" accept-charset="utf-8" target="_blank" _lpchecked="1">
      
      <input type="text" name="q" maxlength="20" placeholder="Search">
      <input type="hidden" name="sitesearch" value="https://zaina.newban.cn">
      <button type="submit" class="submit icon-search"></button>
</form>
    </section>
    
    <section class="widget">
        <h3 class="widget-title">最近文章</h3>
<ul class="widget-list">
    
    <li>
        <a href="https://zaina.newban.cn/posts/001rubyruby%E4%B8%AD%E5%85%A8%E5%B1%80%E5%8F%98%E9%87%8F%E5%AE%9E%E4%BE%8B%E5%8F%98%E9%87%8F%E5%B1%80%E9%83%A8%E5%8F%98%E9%87%8F%E7%B1%BB%E5%8F%98%E9%87%8Fsymbol%E5%AF%B9%E6%AF%94/" title="001rubyRuby中全局变量实例变量局部变量类变量Symbol对比">001rubyRuby中全局变量实例变量局部变量类变量Symbol对比</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/007hadoop%E9%9B%86%E7%BE%A4%E9%85%8D%E7%BD%AEhadoop%E9%9B%86%E7%BE%A4%E7%9A%84%E5%90%AF%E5%8A%A8%E5%92%8C%E6%B5%8B%E8%AF%95ssh%E5%85%8D%E7%99%BB%E9%99%86%E9%85%8D%E7%BD%AEstartallshhdfs%E5%B8%B8%E7%94%A8%E7%9A%84shell/" title="007Hadoop集群配置Hadoop集群的启动和测试SSH免登陆配置startallshhdfs常用的shell">007Hadoop集群配置Hadoop集群的启动和测试SSH免登陆配置startallshhdfs常用的shell</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/009shell%E8%84%9A%E6%9C%AC%E4%B8%8B%E6%9D%A1%E4%BB%B6%E6%B5%8B%E8%AF%95eqne/" title="009Shell脚本下条件测试eqne">009Shell脚本下条件测试eqne</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/00pythonmanagepyshell%E5%92%8Cpython%E7%9A%84%E5%88%86%E6%9E%90/" title="00Pythonmanagepyshell和Python的分析">00Pythonmanagepyshell和Python的分析</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/010zookeeper%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5zookeeper%E7%9A%84%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BAzookeeper%E7%9A%84shell%E5%91%BD%E4%BB%A4/" title="010Zookeeper的基本概念Zookeeper的集群搭建Zookeeper的shell命令">010Zookeeper的基本概念Zookeeper的集群搭建Zookeeper的shell命令</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/018dockerfileshell/" title="018DockerfileSHELL">018DockerfileSHELL</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/01shell%E5%85%A5%E9%97%A801bashshell%E7%89%B9%E6%80%A7/" title="01Shell入门01bashShell特性">01Shell入门01bashShell特性</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/01shell%E5%8F%98%E9%87%8F/" title="01Shell变量">01Shell变量</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/01shell%E5%9F%BA%E7%A1%80%E6%A6%82%E8%BF%B0%E8%84%9A%E6%9C%AC%E6%89%A7%E8%A1%8C%E6%96%B9%E5%BC%8Fbash%E5%9F%BA%E6%9C%AC%E5%8A%9F%E8%83%BD/" title="01Shell基础概述脚本执行方式Bash基本功能">01Shell基础概述脚本执行方式Bash基本功能</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/01shell%E7%BC%96%E7%A8%8Bhelloworld/" title="01shell编程helloworld">01shell编程helloworld</a>
    </li>
    
</ul>
    </section>

    

    <section class="widget">
        <h3 class="widget-title"><a href="/categories">分类</a></h3>
<ul class="widget-list">
    
</ul>
    </section>

    <section class="widget">
        <h3 class="widget-title"><a href="/tags">标签</a></h3>
<div class="tagcloud">
    
    <a href="https://zaina.newban.cn/tags/ruby/">ruby</a>
    
    <a href="https://zaina.newban.cn/tags/shell/">shell</a>
    
</div>
    </section>

    

    <section class="widget">
        <h3 class="widget-title">其它</h3>
        <ul class="widget-list">
            <li><a href="https://zaina.newban.cn/index.xml">文章 RSS</a></li>
        </ul>
    </section>
</div>
            </div>
        </div>
    </div>
</body>

</html>