<!doctype html>
<html lang="en-us">
<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">


    <title>Hive的Shell里hive执行操作时出现FAILEDExecutionErrorreturncode1fromorgapachehadoophiveqlexec | 开发者问答集锦</title>
    <meta property="og:title" content="Hive的Shell里hive执行操作时出现FAILEDExecutionErrorreturncode1fromorgapachehadoophiveqlexec - 开发者问答集锦">
    <meta property="og:type" content="article">
        
    <meta property="article:published_time" content='2020-09-02T00:00:00&#43;08:00'>
        
        
    <meta property="article:modified_time" content='2020-09-02T00:00:00&#43;08:00'>
        
    <meta name="Keywords" content="">
    <meta name="description" content="Hive的Shell里hive执行操作时出现FAILEDExecutionErrorreturncode1fromorgapachehadoophiveqlexec">
        
    <meta name="author" content="">
    <meta property="og:url" content="https://zaina.newban.cn/posts/hive%E7%9A%84shell%E9%87%8Chive%E6%89%A7%E8%A1%8C%E6%93%8D%E4%BD%9C%E6%97%B6%E5%87%BA%E7%8E%B0failedexecutionerrorreturncode1fromorgapachehadoophiveqlexec/">
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">

    <link rel="stylesheet" href='/css/normalize.css'>
    <link rel="stylesheet" href='/css/style.css'>
    <script type="text/javascript" src="//cdn.bootcdn.net/ajax/libs/jquery/3.4.1/jquery.min.js"></script>

    
    
    
    
    
    
</head>


<body>
    <header id="header" class="clearfix">
    <div class="container">
        <div class="col-group">
            <div class="site-name ">
                
                    <a id="logo" href="https://zaina.newban.cn">
                        开发者问答集锦
                    </a>
                
                
            </div>
            <div>
                <nav id="nav-menu" class="clearfix">
                    <a class="" href="https://zaina.newban.cn">首页</a>
                    
                </nav>
            </div>
        </div>
    </div>
</header>

    <div id="body">
        <div class="container">
            <div class="col-group">

                <div class="col-8" id="main">
                    
<div class="res-cons">
    
    <article class="post">
        <header>
            <h1 class="post-title">Hive的Shell里hive执行操作时出现FAILEDExecutionErrorreturncode1fromorgapachehadoophiveqlexec</h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        
        <div class="post-meta">
            <span id="busuanzi_container_page_pv">|<span id="busuanzi_value_page_pv"></span><span>
                    阅读</span></span>
        </div>
        
        
        <div class="post-content">
            

<p>不多说，直接上干货！</p>

<p>这个问题，得非 你的hive和hbase是不是同样都是CDH版本，还是一个是apache版本，一个是CDH版本。</p>

<p><strong>问题详情</strong></p>

<p><a href="https://img.it610.com/image/info8/19cd2d7dcfcc425f965f4668e7dfa4d1.jpg"><img src="https://img.it610.com/image/info8/19cd2d7dcfcc425f965f4668e7dfa4d1.jpg" alt="Hive的Shell里hive&gt; 执行操作时，出现FAILED: Execution Error, return code 1 from
org.apache.hadoop.hive.ql.exec...._第1张图片" /></a></p>

<pre><code>[kfk@bigdata-pro01 apache-hive-1.0.0-bin]$ bin/hive

Logging initialized using configuration in file:/opt/modules/apache-hive-1.0.0-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/modules/hadoop-2.6.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/modules/apache-hive-1.0.0-bin/lib/hive-jdbc-1.0.0-standalone.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
hive&gt; create external table weblogs(id string,datatime string,userid string,searchname string,retorder string,cliorder string,cliurl string)  STORED BY  'org.apache.hadoop.hive.hbase.HBaseStorageHandler' WITH SERDEPROPERTIES(&quot;hbase.columns.mapping&quot; = &quot;:key,info:datatime,info:userid,info:searchname,info:retorder,info:cliorder,info:cliurl&quot;) TBLPROPERTIES(&quot;hbase.table.name&quot; = &quot;weblogs&quot;);
**FAILED: Execution Error,** **return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. MetaException(message:MetaException(message:HBase table weblogs doesn't exist while the table is declared as an external table.)**
    at org.apache.hadoop.hive.hbase.HBaseStorageHandler.preCreateTable(HBaseStorageHandler.java:202)
    at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:608)
    at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:601)
    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
    at java.lang.reflect.Method.invoke(Method.java:606)
    at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:90)
    at com.sun.proxy.$Proxy7.createTable(Unknown Source)
    at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:671)
    at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3973)
    at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:295)
    at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:160)
    at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:85)
    at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1604)
    at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1364)
    at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1177)
    at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1004)
    at org.apache.hadoop.hive.ql.Driver.run(Driver.java:994)
    at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:201)
    at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:153)
    at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:364)
    at org.apache.hadoop.hive.cli.CliDriver.executeDriver(CliDriver.java:712)
    at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:631)
    at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:570)
    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
    at java.lang.reflect.Method.invoke(Method.java:606)
    at org.apache.hadoop.util.RunJar.run(RunJar.java:221)
    at org.apache.hadoop.util.RunJar.main(RunJar.java:136)
)
</code></pre>

<p><a href="https://img.it610.com/image/info8/dc0758a4ff754f00992fa394505a48dd.jpg"><img src="https://img.it610.com/image/info8/dc0758a4ff754f00992fa394505a48dd.jpg" alt="Hive的Shell里hive&gt; 执行操作时，出现FAILED: Execution Error, return code 1 from
org.apache.hadoop.hive.ql.exec...._第2张图片" /></a></p>

<p>说明没创建成功。</p>

<p>** Hive和HBase同是CDH版本的** <strong>解决办法</strong></p>

<p><strong><a href="https://img.it610.com/image/info8/836c6b09c08145b696ad8c6ccfaa7024.jpg"><img src="https://img.it610.com/image/info8/836c6b09c08145b696ad8c6ccfaa7024.jpg" alt="Hive的Shell里hive&gt; 执行操作时，出现FAILED: Execution Error, return code 1 from
org.apache.hadoop.hive.ql.exec...._第3张图片" /></a></strong></p>

<p>首先通过用下面的命令，重新启动hive<br />
./hive -hiveconf hive.root.logger=DEBUG,console 进行debug<br />
查看到错误原因</p>

<p><a href="https://img.it610.com/image/info8/ad023566168442dcb61e7f1935ba7449.jpg"><img src="https://img.it610.com/image/info8/ad023566168442dcb61e7f1935ba7449.jpg" alt="Hive的Shell里hive&gt; 执行操作时，出现FAILED: Execution Error, return code 1 from
org.apache.hadoop.hive.ql.exec...._第4张图片" /></a></p>

<p><a href="https://img.it610.com/image/info8/800f3c05b95049d0a35197e8914e2651.jpg"><img src="https://img.it610.com/image/info8/800f3c05b95049d0a35197e8914e2651.jpg" alt="Hive的Shell里hive&gt; 执行操作时，出现FAILED: Execution Error, return code 1 from
org.apache.hadoop.hive.ql.exec...._第5张图片" /></a></p>

<p>调遣hbase包错误，配置文件不能加载。</p>

<p>将hbase目录下jar包拷贝到hadoop/lib下，（注意了我这里为了保险起见3个节点都做了这一步）</p>

<p><a href="https://img.it610.com/image/info8/2e97242d86a144fda5537a29e4f52c9d.jpg"><img src="https://img.it610.com/image/info8/2e97242d86a144fda5537a29e4f52c9d.jpg" alt="Hive的Shell里hive&gt; 执行操作时，出现FAILED: Execution Error, return code 1 from
org.apache.hadoop.hive.ql.exec...._第6张图片" /></a></p>

<pre><code>[kfk@bigdata-pro01 lib]$ cp  hbase-client-0.98.6-cdh5.3.0.jar /opt/modules/hadoop-2.6.0/lib
[kfk@bigdata-pro01 lib]$ cp hbase-common-0.98.6-cdh5.3.0.jar /opt/modules/hadoop-2.6.0/lib
[kfk@bigdata-pro01 lib]$ cp hbase-common-0.98.6-cdh5.3.0-tests.jar /opt/modules/hadoop-2.6.0/lib
[kfk@bigdata-pro01 lib]$ cp hbase-examples-0.98.6-cdh5.3.0.jar /opt/modules/hadoop-2.6.0/lib
[kfk@bigdata-pro01 lib]$ cp hbase-hadoop2-compat-0.98.6-cdh5.3.0.jar /opt/modules/h
hadoop-2.6.0/          hbase-0.98.6-cdh5.3.0/ hive-0.13.1-cdh5.3.0/  
[kfk@bigdata-pro01 lib]$ cp hbase-hadoop2-compat-0.98.6-cdh5.3.0.jar /opt/modules/hadoop-2.6.0/lib
[kfk@bigdata-pro01 lib]$ cp hbase-hadoop2-compat-0.98.6-cdh5.3.0-tests.jar /opt/modules/hadoop-2.6.0/lib
[kfk@bigdata-pro01 lib]$ cp hbase-hadoop-compat-0.98.6-cdh5.3.0.jar /opt/modules/hadoop-2.6.0/lib
[kfk@bigdata-pro01 lib]$ cp hbase-hadoop-compat-0.98.6-cdh5.3.0-tests.jar /opt/modules/hadoop-2.6.0/lib
[kfk@bigdata-pro01 lib]$ cp hbase-it-0.98.6-cdh5.3.0.jar /opt/modules/hadoop-2.6.0/lib
[kfk@bigdata-pro01 lib]$ cp hbase-it-0.98.6-cdh5.3.0-tests.jar /opt/modules/hadoop-2.6.0/lib
[kfk@bigdata-pro01 lib]$ cp hbase-prefix-tree-0.98.6-cdh5.3.0.jar /opt/modules/hadoop-2.6.0/lib
[kfk@bigdata-pro01 lib]$ cp hbase-protocol-0.98.6-cdh5.3.0.jar /opt/modules/hadoop-2.6.0/lib
[kfk@bigdata-pro01 lib]$ cp hbase-server-0.98.6-cdh5.3.0.jar /opt/modules/hadoop-2.6.0/lib
[kfk@bigdata-pro01 lib]$ cp hbase-server-0.98.6-cdh5.3.0-tests.jar /opt/modules/hadoop-2.6.0/lib
[kfk@bigdata-pro01 lib]$ cp hbase-shell-0.98.6-cdh5.3.0.jar /opt/modules/hadoop-2.6.0/lib
[kfk@bigdata-pro01 lib]$ cp  hbase-testing-util-0.98.6-cdh5.3.0.jar /opt/modules/hadoop-2.6.0/lib
[kfk@bigdata-pro01 lib]$ cp hbase-thrift-0.98.6-cdh5.3.0.jar /opt/modules/hadoop-2.6.0/lib
[kfk@bigdata-pro01 lib]$ pwd
/opt/modules/hbase-0.98.6-cdh5.3.0/lib
[kfk@bigdata-pro01 lib]$ 
</code></pre>

<p><a href="https://img.it610.com/image/info8/80673f99e4034f67bf1f1005f8b601af.jpg"><img src="https://img.it610.com/image/info8/80673f99e4034f67bf1f1005f8b601af.jpg" alt="Hive的Shell里hive&gt; 执行操作时，出现FAILED: Execution Error, return code 1 from
org.apache.hadoop.hive.ql.exec...._第7张图片" /></a></p>

<pre><code>[kfk@bigdata-pro02 lib]$ cp  hbase-client-0.98.6-cdh5.3.0.jar /opt/modules/hadoop-2.6.0/lib
[kfk@bigdata-pro02 lib]$ cp hbase-common-0.98.6-cdh5.3.0.jar /opt/modules/hadoop-2.6.0/lib
[kfk@bigdata-pro02 lib]$ cp hbase-common-0.98.6-cdh5.3.0-tests.jar /opt/modules/hadoop-2.6.0/lib
[kfk@bigdata-pro02 lib]$ cp hbase-examples-0.98.6-cdh5.3.0.jar /opt/modules/hadoop-2.6.0/lib
[kfk@bigdata-pro02 lib]$ cp hbase-hadoop2-compat-0.98.6-cdh5.3.0.jar /opt/modules/hadoop-2.6.0/lib
[kfk@bigdata-pro02 lib]$ cp hbase-hadoop2-compat-0.98.6-cdh5.3.0-tests.jar /opt/modules/hadoop-2.6.0/lib
[kfk@bigdata-pro02 lib]$ cp hbase-hadoop-compat-0.98.6-cdh5.3.0.jar /opt/modules/hadoop-2.6.0/lib
[kfk@bigdata-pro02 lib]$ cp hbase-hadoop-compat-0.98.6-cdh5.3.0-tests.jar /opt/modules/hadoop-2.6.0/lib
[kfk@bigdata-pro02 lib]$ cp hbase-it-0.98.6-cdh5.3.0.jar /opt/modules/hadoop-2.6.0/lib
[kfk@bigdata-pro02 lib]$ cp hbase-it-0.98.6-cdh5.3.0-tests.jar /opt/modules/hadoop-2.6.0/lib
[kfk@bigdata-pro02 lib]$ cp hbase-prefix-tree-0.98.6-cdh5.3.0.jar /opt/modules/hadoop-2.6.0/lib
[kfk@bigdata-pro02 lib]$ cp hbase-protocol-0.98.6-cdh5.3.0.jar /opt/modules/hadoop-2.6.0/lib
[kfk@bigdata-pro02 lib]$ cp hbase-server-0.98.6-cdh5.3.0.jar /opt/modules/hadoop-2.6.0/lib
[kfk@bigdata-pro02 lib]$ cp hbase-server-0.98.6-cdh5.3.0-tests.jar /opt/modules/hadoop-2.6.0/lib
[kfk@bigdata-pro02 lib]$ cp hbase-shell-0.98.6-cdh5.3.0.jar /opt/modules/hadoop-2.6.0/lib
[kfk@bigdata-pro02 lib]$ 
[kfk@bigdata-pro02 lib]$ cp  hbase-testing-util-0.98.6-cdh5.3.0.jar /opt/modules/hadoop-2.6.0/lib
[kfk@bigdata-pro02 lib]$ cp hbase-thrift-0.98.6-cdh5.3.0.jar /opt/modules/hadoop-2.6.0/lib
[kfk@bigdata-pro02 lib]$ cp  hbase-testing-util-0.98.6-cdh5.3.0.jar /opt/modules/hadoop-2.6.0/lib
[kfk@bigdata-pro02 lib]$ pwd
/opt/modules/hbase-0.98.6-cdh5.3.0/lib
[kfk@bigdata-pro02 lib]$ 
</code></pre>

<p><a href="https://img.it610.com/image/info8/874763d8fbc541249e9fdd1f15c76280.jpg"><img src="https://img.it610.com/image/info8/874763d8fbc541249e9fdd1f15c76280.jpg" alt="Hive的Shell里hive&gt; 执行操作时，出现FAILED: Execution Error, return code 1 from
org.apache.hadoop.hive.ql.exec...._第8张图片" /></a></p>

<pre><code>[kfk@bigdata-pro03 ~]$ cd /opt/modules/hbase-0.98.6-cdh5.3.0/lib/
[kfk@bigdata-pro03 lib]$ cp  hbase-client-0.98.6-cdh5.3.0.jar /opt/modules/hadoop-2.6.0/lib
[kfk@bigdata-pro03 lib]$ cp hbase-common-0.98.6-cdh5.3.0.jar /opt/modules/hadoop-2.6.0/lib
[kfk@bigdata-pro03 lib]$ cp hbase-common-0.98.6-cdh5.3.0-tests.jar /opt/modules/hadoop-2.6.0/lib
[kfk@bigdata-pro03 lib]$ cp hbase-examples-0.98.6-cdh5.3.0.jar /opt/modules/hadoop-2.6.0/lib
[kfk@bigdata-pro03 lib]$ cp hbase-hadoop2-compat-0.98.6-cdh5.3.0.jar /opt/modules/hadoop-2.6.0/lib
[kfk@bigdata-pro03 lib]$ cp hbase-hadoop2-compat-0.98.6-cdh5.3.0-tests.jar /opt/modules/hadoop-2.6.0/lib
[kfk@bigdata-pro03 lib]$ cp hbase-hadoop-compat-0.98.6-cdh5.3.0.jar /opt/modules/hadoop-2.6.0/lib
[kfk@bigdata-pro03 lib]$ cp hbase-hadoop-compat-0.98.6-cdh5.3.0-tests.jar /opt/modules/hadoop-2.6.0/lib
[kfk@bigdata-pro03 lib]$ cp hbase-it-0.98.6-cdh5.3.0.jar /opt/modules/hadoop-2.6.0/lib
[kfk@bigdata-pro03 lib]$ cp hbase-it-0.98.6-cdh5.3.0-tests.jar /opt/modules/hadoop-2.6.0/lib
[kfk@bigdata-pro03 lib]$ cp hbase-prefix-tree-0.98.6-cdh5.3.0.jar /opt/modules/hadoop-2.6.0/lib
[kfk@bigdata-pro03 lib]$ cp hbase-protocol-0.98.6-cdh5.3.0.jar /opt/modules/hadoop-2.6.0/lib
[kfk@bigdata-pro03 lib]$ cp hbase-server-0.98.6-cdh5.3.0.jar /opt/modules/hadoop-2.6.0/lib
[kfk@bigdata-pro03 lib]$ cp hbase-server-0.98.6-cdh5.3.0-tests.jar /opt/modules/hadoop-2.6.0/lib
[kfk@bigdata-pro03 lib]$ cp hbase-shell-0.98.6-cdh5.3.0.jar /opt/modules/hadoop-2.6.0/lib
[kfk@bigdata-pro03 lib]$ pwd
/opt/modules/hbase-0.98.6-cdh5.3.0/lib
[kfk@bigdata-pro03 lib]$ 
</code></pre>

<p>然后，修改hive的配置文件，使hbase的lib包生效</p>

<p><a href="https://img.it610.com/image/info8/d44f7cfe69314e8aa29515894b05511b.jpg"><img src="https://img.it610.com/image/info8/d44f7cfe69314e8aa29515894b05511b.jpg" alt="Hive的Shell里hive&gt; 执行操作时，出现FAILED: Execution Error, return code 1 from
org.apache.hadoop.hive.ql.exec...._第9张图片" /></a></p>

<p>重启一下hive，再次建表</p>

<p><a href="https://img.it610.com/image/info8/44b82ff00e0c4e55be9195fe1b8f525d.jpg"><img src="https://img.it610.com/image/info8/44b82ff00e0c4e55be9195fe1b8f525d.jpg" alt="Hive的Shell里hive&gt; 执行操作时，出现FAILED: Execution Error, return code 1 from
org.apache.hadoop.hive.ql.exec...._第10张图片" /></a></p>

<pre><code>[kfk@bigdata-pro01 hive-0.13.1-cdh5.3.0]$ bin/hive

Logging initialized using configuration in file:/opt/modules/hive-0.13.1-cdh5.3.0/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/modules/hadoop-2.6.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/modules/hbase-0.98.6-cdh5.3.0/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
hive (default)&gt; create external table weblogs(
              &gt; id string,
              &gt; datatime string,
              &gt; userid string,
              &gt; searchname string,
              &gt; retorder string,
              &gt; cliorder string,
              &gt; cliurl string
              &gt; )
              &gt; STORED BY  'org.apache.hadoop.hive.hbase.HBaseStorageHandler' 
              &gt; WITH SERDEPROPERTIES(&quot;hbase.columns.mapping&quot; = &quot;:key,info:datatime,info:userid,info:searchname,info:retorder,info:cliorder,info:cliurl&quot;) 
              &gt; TBLPROPERTIES(&quot;hbase.table.name&quot; = &quot;weblogs&quot;);
OK
Time taken: 2.084 seconds
hive (default)&gt; 
</code></pre>

<p><strong>Hive和HBase不同是CDH版本 的</strong> <strong>解决办法</strong></p>

<p>（1） 退出，重新进hive</p>

<p>（2） 重启Hbase服务试试</p>

<p>（3）别光检查你的Hive，还看看你的HBase进程啊。</p>

<p>从时间同步，防火墙，MySQL启动没、hive-site.xml配置好了没，以及授权是否正确等方面去排查。</p>

<h1 id="java-lang-runtimeexception-hregionserver-aborted的问题">java.lang.RuntimeException: HRegionServer Aborted的问题</h1>

<h1 id="分布式集群hbase启动后某节点的hregionserver自动消失问题">分布式集群HBase启动后某节点的HRegionServer自动消失问题</h1>

<p>（4） 少包了，是Hive和HBase集成这过程出错了。</p>

<p>官网
<a href="https://cwiki.apache.org/confluence/display/Hive/HBaseIntegration[![Hive的Shell里hive&gt;">https://cwiki.apache.org/confluence/display/Hive/HBaseIntegration[![Hive的Shell里hive&gt;</a>
执行操作时，出现FAILED: Execution Error, return code 1 from
org.apache.hadoop.hive.ql.exec&hellip;._第11张图片](<a href="https://img.it610.com/image/info8/85edf914434c4af8becc412eaad3412c.jpg)](https://img.it610.com/image/info8/85edf914434c4af8becc412eaad3412c.jpg">https://img.it610.com/image/info8/85edf914434c4af8becc412eaad3412c.jpg)](https://img.it610.com/image/info8/85edf914434c4af8becc412eaad3412c.jpg</a>)</p>

<p><a href="https://img.it610.com/image/info8/89287458fad04221b5c98603b455375d.jpg"><img src="https://img.it610.com/image/info8/89287458fad04221b5c98603b455375d.jpg" alt="Hive的Shell里hive&gt; 执行操作时，出现FAILED: Execution Error, return code 1 from
org.apache.hadoop.hive.ql.exec...._第12张图片" /></a></p>

<p><a href="https://img.it610.com/image/info8/bba6367ebb42467b9c0d12b4306e0e1d.jpg"><img src="https://img.it610.com/image/info8/bba6367ebb42467b9c0d12b4306e0e1d.jpg" alt="Hive的Shell里hive&gt; 执行操作时，出现FAILED: Execution Error, return code 1 from
org.apache.hadoop.hive.ql.exec...._第13张图片" /></a></p>

<p>一闪一闪就是软连接有错误，资源找不到，</p>

<p><a href="https://img.it610.com/image/info8/f0045703f98341dc8c7e30ec1e91335f.jpg"><img src="https://img.it610.com/image/info8/f0045703f98341dc8c7e30ec1e91335f.jpg" alt="Hive的Shell里hive&gt; 执行操作时，出现FAILED: Execution Error, return code 1 from
org.apache.hadoop.hive.ql.exec...._第14张图片" /></a></p>

<p><a href="https://img.it610.com/image/info8/b8c10a1772c0477fbae245180831eb83.jpg"><img src="https://img.it610.com/image/info8/b8c10a1772c0477fbae245180831eb83.jpg" alt="Hive的Shell里hive&gt; 执行操作时，出现FAILED: Execution Error, return code 1 from
org.apache.hadoop.hive.ql.exec...._第15张图片" /></a></p>

<pre><code>export HBASE_HOME=/opt/modules/hbase-0.98.6-cdh5.3.0
export HIVE_HOME=/opt/modules/apache-hive-1.0.0-bin



ln -s $HBASE_HOME/lib/hbase-server-0.98.6-cdh5.3.0.jar $HIVE_HOME/lib/hbase-server-0.98.6-cdh5.3.0.jar
ln -s $HBASE_HOME/lib/hbase-client-0.98.6-cdh5.3.0.jar $HIVE_HOME/lib/hbase-client-0.98.6-cdh5.3.0.jar
ln -s $HBASE_HOME/lib/hbase-protocol-0.98.6-cdh5.3.0.jar $HIVE_HOME/lib/hbase-protocol-0.98.6-cdh5.3.0.jar 
ln -s $HBASE_HOME/lib/hbase-it-0.98.6-cdh5.3.0.jar $HIVE_HOME/lib/hbase-it-0.98.6-cdh5.3.0.jar 
ln -s $HBASE_HOME/lib/htrace-core-2.04.jar $HIVE_HOME/lib/htrace-core-2.04.jar
ln -s $HBASE_HOME/lib/hbase-hadoop2-compat-0.98.6-cdh5.3.0.jar $HIVE_HOME/lib/hbase-hadoop2-compat-0.98.6-cdh5.3.0.jar 
ln -s $HBASE_HOME/lib/hbase-hadoop-compat-0.98.6-cdh5.3.0.jar $HIVE_HOME/lib/hbase-hadoop-compat-0.98.6-cdh5.3.0.jar 
ln -s $HBASE_HOME/lib/high-scale-lib-1.1.1.jar $HIVE_HOME/lib/high-scale-lib-1.1.1.jar 
ln -s $HBASE_HOME/lib/hbase-common-0.98.6-cdh5.3.0.jar $HIVE_HOME/lib/hbase-common-0.98.6-cdh5.3.0.jar 
</code></pre>

<p><a href="https://img.it610.com/image/info8/2ce531a3d2aa4a899e078ec8a8175951.jpg"><img src="https://img.it610.com/image/info8/2ce531a3d2aa4a899e078ec8a8175951.jpg" alt="Hive的Shell里hive&gt; 执行操作时，出现FAILED: Execution Error, return code 1 from
org.apache.hadoop.hive.ql.exec...._第16张图片" /></a></p>

<pre><code>[kfk@bigdata-pro01 lib]$ ll
total 82368
-rw-rw-r--  1 kfk kfk  4368200 Jan  7 17:35 accumulo-core-1.6.0.jar
-rw-rw-r--  1 kfk kfk   102069 Jan  7 17:35 accumulo-fate-1.6.0.jar
-rw-rw-r--  1 kfk kfk    57420 Jan  7 17:35 accumulo-start-1.6.0.jar
-rw-rw-r--  1 kfk kfk   117409 Jan  7 17:35 accumulo-trace-1.6.0.jar
-rw-rw-r--  1 kfk kfk    62983 Jan  7 17:35 activation-1.1.jar
-rw-rw-r--  1 kfk kfk  1997485 Jan  7 17:35 ant-1.9.1.jar
-rw-rw-r--  1 kfk kfk    18336 Jan  7 17:35 ant-launcher-1.9.1.jar
-rw-rw-r--  1 kfk kfk   445288 Jan  7 17:35 antlr-2.7.7.jar
-rw-rw-r--  1 kfk kfk   164368 Jan  7 17:35 antlr-runtime-3.4.jar
-rw-rw-r--  1 kfk kfk    32693 Jan  7 17:35 asm-commons-3.1.jar
-rw-rw-r--  1 kfk kfk    21879 Jan  7 17:35 asm-tree-3.1.jar
-rw-rw-r--  1 kfk kfk   400680 Jan  7 17:35 avro-1.7.5.jar
-rw-rw-r--  1 kfk kfk   110600 Jan  7 17:35 bonecp-0.8.0.RELEASE.jar
-rw-rw-r--  1 kfk kfk    89044 Jan  7 17:35 calcite-avatica-0.9.2-incubating.jar
-rw-rw-r--  1 kfk kfk  3156089 Jan  7 17:35 calcite-core-0.9.2-incubating.jar
-rw-rw-r--  1 kfk kfk   188671 Jan  7 17:35 commons-beanutils-1.7.0.jar
-rw-rw-r--  1 kfk kfk   206035 Jan  7 17:35 commons-beanutils-core-1.8.0.jar
-rw-rw-r--  1 kfk kfk    41123 Jan  7 17:35 commons-cli-1.2.jar
-rw-rw-r--  1 kfk kfk    58160 Jan  7 17:35 commons-codec-1.4.jar
-rw-rw-r--  1 kfk kfk   575389 Jan  7 17:35 commons-collections-3.2.1.jar
-rw-rw-r--  1 kfk kfk    30595 Jan  7 17:35 commons-compiler-2.7.6.jar
-rw-rw-r--  1 kfk kfk   241367 Jan  7 17:35 commons-compress-1.4.1.jar
-rw-rw-r--  1 kfk kfk   298829 Jan  7 17:35 commons-configuration-1.6.jar
-rw-rw-r--  1 kfk kfk   160519 Jan  7 17:35 commons-dbcp-1.4.jar
-rw-rw-r--  1 kfk kfk   143602 Jan  7 17:35 commons-digester-1.8.jar
-rw-rw-r--  1 kfk kfk   279781 Jan  7 17:35 commons-httpclient-3.0.1.jar
-rw-rw-r--  1 kfk kfk   185140 Jan  7 17:35 commons-io-2.4.jar
-rw-rw-r--  1 kfk kfk   284220 Jan  7 17:35 commons-lang-2.6.jar
-rw-rw-r--  1 kfk kfk    62050 Jan  7 17:35 commons-logging-1.1.3.jar
-rw-rw-r--  1 kfk kfk   832410 Jan  7 17:35 commons-math-2.1.jar
-rw-rw-r--  1 kfk kfk    96221 Jan  7 17:35 commons-pool-1.5.4.jar
-rw-rw-r--  1 kfk kfk   415578 Jan  7 17:35 commons-vfs2-2.0.jar
-rw-rw-r--  1 kfk kfk    68866 Jan  7 17:35 curator-client-2.6.0.jar
-rw-rw-r--  1 kfk kfk   185245 Jan  7 17:35 curator-framework-2.6.0.jar
-rw-rw-r--  1 kfk kfk   339666 Jan  7 17:35 datanucleus-api-jdo-3.2.6.jar
-rw-rw-r--  1 kfk kfk  1890075 Jan  7 17:35 datanucleus-core-3.2.10.jar
-rw-rw-r--  1 kfk kfk  1809447 Jan  7 17:35 datanucleus-rdbms-3.2.9.jar
-rw-rw-r--  1 kfk kfk  2831358 Jan  7 17:35 derby-10.10.1.1.jar
-rw-rw-r--  1 kfk kfk    18402 Jan  7 17:35 eigenbase-properties-1.1.4.jar
-rw-rw-r--  1 kfk kfk    12452 Jan  7 17:35 geronimo-annotation_1.0_spec-1.1.1.jar
-rw-rw-r--  1 kfk kfk    30548 Jan  7 17:35 geronimo-jaspic_1.0_spec-1.0.jar
-rw-rw-r--  1 kfk kfk    16030 Jan  7 17:35 geronimo-jta_1.1_spec-1.1.1.jar
-rw-rw-r--  1 kfk kfk  6377448 Jan  7 17:35 groovy-all-2.1.6.jar
-rw-rw-r--  1 kfk kfk  1648200 Jan  7 17:35 guava-11.0.2.jar
-rw-rw-r--  1 kfk kfk    76643 Jan  7 17:35 hamcrest-core-1.1.jar
lrwxrwxrwx  1 kfk kfk       71 Jan  7 17:41 hbase-client-0.98.6-cdh5.3.0.jar -&gt; /opt/modules/hbase-0.98.6-cdh5.3.0/lib/hbase-client-0.98.6-cdh5.3.0.jar
lrwxrwxrwx  1 kfk kfk       71 Jan  7 17:41 hbase-common-0.98.6-cdh5.3.0.jar -&gt; /opt/modules/hbase-0.98.6-cdh5.3.0/lib/hbase-common-0.98.6-cdh5.3.0.jar
lrwxrwxrwx  1 kfk kfk       79 Jan  7 17:41 hbase-hadoop2-compat-0.98.6-cdh5.3.0.jar -&gt; /opt/modules/hbase-0.98.6-cdh5.3.0/lib/hbase-hadoop2-compat-0.98.6-cdh5.3.0.jar
lrwxrwxrwx  1 kfk kfk       78 Jan  7 17:41 hbase-hadoop-compat-0.98.6-cdh5.3.0.jar -&gt; /opt/modules/hbase-0.98.6-cdh5.3.0/lib/hbase-hadoop-compat-0.98.6-cdh5.3.0.jar
lrwxrwxrwx  1 kfk kfk       67 Jan  7 17:41 hbase-it-0.98.6-cdh5.3.0.jar -&gt; /opt/modules/hbase-0.98.6-cdh5.3.0/lib/hbase-it-0.98.6-cdh5.3.0.jar
lrwxrwxrwx  1 kfk kfk       73 Jan  7 17:41 hbase-protocol-0.98.6-cdh5.3.0.jar -&gt; /opt/modules/hbase-0.98.6-cdh5.3.0/lib/hbase-protocol-0.98.6-cdh5.3.0.jar
lrwxrwxrwx  1 kfk kfk       71 Jan  7 17:41 hbase-server-0.98.6-cdh5.3.0.jar -&gt; /opt/modules/hbase-0.98.6-cdh5.3.0/lib/hbase-server-0.98.6-cdh5.3.0.jar
lrwxrwxrwx  1 kfk kfk       63 Jan  7 17:41 high-scale-lib-1.1.1.jar -&gt; /opt/modules/hbase-0.98.6-cdh5.3.0/lib/high-scale-lib-1.1.1.jar
-rw-rw-r--  1 kfk kfk   112948 Jan  7 17:35 hive-accumulo-handler-1.0.0.jar
-rw-rw-r--  1 kfk kfk    42337 Jan  7 17:35 hive-ant-1.0.0.jar
-rw-rw-r--  1 kfk kfk   128193 Jan  7 17:35 hive-beeline-1.0.0.jar
-rw-rw-r--  1 kfk kfk    35030 Jan  7 17:35 hive-cli-1.0.0.jar
-rw-rw-r--  1 kfk kfk   234200 Jan  7 17:35 hive-common-1.0.0.jar
-rw-rw-r--  1 kfk kfk   120929 Jan  7 17:35 hive-contrib-1.0.0.jar
-rw-rw-r--  1 kfk kfk 17429823 Jan  7 17:35 hive-exec-1.0.0.jar
-rw-rw-r--  1 kfk kfk   107720 Jan  7 17:35 hive-hbase-handler-1.0.0.jar
-rw-rw-r--  1 kfk kfk    27378 Jan  7 17:35 hive-hwi-1.0.0.jar
-rw-rw-r--  1 kfk kfk    91218 Jan  7 17:35 hive-jdbc-1.0.0.jar
-rw-rw-r--  1 kfk kfk 15002397 Jan  7 17:35 hive-jdbc-1.0.0-standalone.jar
-rw-rw-r--  1 kfk kfk  5125725 Jan  7 17:35 hive-metastore-1.0.0.jar
-rw-rw-r--  1 kfk kfk   813184 Jan  7 17:35 hive-serde-1.0.0.jar
-rw-rw-r--  1 kfk kfk  1866002 Jan  7 17:35 hive-service-1.0.0.jar
-rw-rw-r--  1 kfk kfk    32386 Jan  7 17:35 hive-shims-0.20-1.0.0.jar
-rw-rw-r--  1 kfk kfk    29032 Jan  7 17:35 hive-shims-0.20S-1.0.0.jar
-rw-rw-r--  1 kfk kfk    48341 Jan  7 17:35 hive-shims-0.23-1.0.0.jar
-rw-rw-r--  1 kfk kfk     7467 Jan  7 17:35 hive-shims-1.0.0.jar
-rw-rw-r--  1 kfk kfk    48305 Jan  7 17:35 hive-shims-common-1.0.0.jar
-rw-rw-r--  1 kfk kfk    79215 Jan  7 17:35 hive-shims-common-secure-1.0.0.jar
-rw-rw-r--  1 kfk kfk    14525 Jan  7 17:35 hive-testutils-1.0.0.jar
lrwxrwxrwx  1 kfk kfk       59 Jan  7 17:41 htrace-core-2.04.jar -&gt; /opt/modules/hbase-0.98.6-cdh5.3.0/lib/htrace-core-2.04.jar
-rw-rw-r--  1 kfk kfk   433368 Jan  7 17:35 httpclient-4.2.5.jar
-rw-rw-r--  1 kfk kfk   227708 Jan  7 17:35 httpcore-4.2.5.jar
-rw-rw-r--  1 kfk kfk   611863 Jan  7 17:35 janino-2.7.6.jar
-rw-rw-r--  1 kfk kfk   114415 Jan  7 17:35 jansi-1.11.jar
-rw-rw-r--  1 kfk kfk    60527 Jan  7 17:35 jcommander-1.32.jar
-rw-rw-r--  1 kfk kfk   201124 Jan  7 17:35 jdo-api-3.0.1.jar
-rw-rw-r--  1 kfk kfk  1681148 Jan  7 17:35 jetty-all-7.6.0.v20120127.jar
-rw-rw-r--  1 kfk kfk  1683027 Jan  7 17:35 jetty-all-server-7.6.0.v20120127.jar
-rw-rw-r--  1 kfk kfk    87325 Jan  7 17:35 jline-0.9.94.jar
-rw-rw-r--  1 kfk kfk    12131 Jan  7 17:35 jpam-1.1.jar
-rw-rw-r--  1 kfk kfk    33015 Jan  7 17:35 jsr305-1.3.9.jar
-rw-rw-r--  1 kfk kfk    15071 Jan  7 17:35 jta-1.1.jar
-rw-rw-r--  1 kfk kfk   245039 Jan  7 17:35 junit-4.11.jar
-rw-rw-r--  1 kfk kfk   275186 Jan  7 17:35 libfb303-0.9.0.jar
-rw-rw-r--  1 kfk kfk   347531 Jan  7 17:35 libthrift-0.9.0.jar
-rw-rw-r--  1 kfk kfk   489213 Jan  7 17:35 linq4j-0.4.jar
-rw-rw-r--  1 kfk kfk   481535 Jan  7 17:35 log4j-1.2.16.jar
-rw-rw-r--  1 kfk kfk   447676 Jan  7 17:35 mail-1.4.1.jar
-rw-rw-r--  1 kfk kfk    94421 Jan  7 17:35 maven-scm-api-1.4.jar
-rw-rw-r--  1 kfk kfk    40066 Jan  7 17:35 maven-scm-provider-svn-commons-1.4.jar
-rw-rw-r--  1 kfk kfk    69858 Jan  7 17:35 maven-scm-provider-svnexe-1.4.jar
-rw-rw-r--  1 kfk kfk   827942 Jan  7 17:36 mysql-connector-java-5.1.21.jar
-rw-rw-r--  1 kfk kfk    19827 Jan  7 17:35 opencsv-2.3.jar
-rw-rw-r--  1 kfk kfk    65261 Jan  7 17:35 oro-2.0.8.jar
-rw-rw-r--  1 kfk kfk    29555 Jan  7 17:35 paranamer-2.3.jar
-rw-rw-r--  1 kfk kfk    48528 Jan  7 17:35 pentaho-aggdesigner-algorithm-5.1.3-jhyde.jar
drwxrwxr-x  6 kfk kfk     4096 Jan  7 17:35 php
-rw-rw-r--  1 kfk kfk   250546 Jan  7 17:35 plexus-utils-1.5.6.jar
drwxrwxr-x 10 kfk kfk     4096 Jan  7 17:35 py
-rw-rw-r--  1 kfk kfk    37325 Jan  7 17:35 quidem-0.1.1.jar
-rw-rw-r--  1 kfk kfk    25429 Jan  7 17:35 regexp-1.3.jar
-rw-rw-r--  1 kfk kfk   105112 Jan  7 17:35 servlet-api-2.5.jar
-rw-rw-r--  1 kfk kfk  1251514 Jan  7 17:35 snappy-java-1.0.5.jar
-rw-rw-r--  1 kfk kfk   236660 Jan  7 17:35 ST4-4.0.4.jar
-rw-rw-r--  1 kfk kfk    26514 Jan  7 17:35 stax-api-1.0.1.jar
-rw-rw-r--  1 kfk kfk   148627 Jan  7 17:35 stringtemplate-3.2.1.jar
-rw-rw-r--  1 kfk kfk    93210 Jan  7 17:35 super-csv-2.2.0.jar
-rw-rw-r--  1 kfk kfk    55953 Jan  7 17:35 tempus-fugit-1.1.jar
-rw-rw-r--  1 kfk kfk   392124 Jan  7 17:35 velocity-1.5.jar
-rw-rw-r--  1 kfk kfk    94672 Jan  7 17:35 xz-1.0.jar
-rw-rw-r--  1 kfk kfk   779974 Jan  7 17:35 zookeeper-3.4.5.jar
[kfk@bigdata-pro01 lib]$ 
</code></pre>

<p>（4）如果你遇到更多的Hive问题，见如下，也许能帮助到你</p>

<h1 id="hive常见问题解决干货大全">hive常见问题解决干货大全</h1>

<p>然后，再来执行</p>

<p><a href="https://img.it610.com/image/info8/9880dd5c54334b9d985186ed00759359.jpg"><img src="https://img.it610.com/image/info8/9880dd5c54334b9d985186ed00759359.jpg" alt="Hive的Shell里hive&gt; 执行操作时，出现FAILED: Execution Error, return code 1 from
org.apache.hadoop.hive.ql.exec...._第17张图片" /></a></p>

<pre><code>[kfk@bigdata-pro01 apache-hive-1.0.0-bin]$ bin/hive

Logging initialized using configuration in file:/opt/modules/apache-hive-1.0.0-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/modules/hadoop-2.6.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/modules/apache-hive-1.0.0-bin/lib/hive-jdbc-1.0.0-standalone.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
hive&gt; create external table weblogs(
    &gt; id string,
    &gt; datatime string,
    &gt; userid string,
    &gt; searchname string,
    &gt; retorder string,
    &gt; cliorder string,
    &gt; cliurl string
    &gt; )  
    &gt; STORED BY  'org.apache.hadoop.hive.hbase.HBaseStorageHandler' 
    &gt; WITH SERDEPROPERTIES(&quot;hbase.columns.mapping&quot; = &quot;:key,info:datatime,info:userid,info:searchname,info:retorder,info:cliorder,info:cliurl&quot;) 
    &gt; TBLPROPERTIES(&quot;hbase.table.name&quot; = &quot;weblogs&quot;);
</code></pre>

<p>或者</p>

<p><a href="https://img.it610.com/image/info8/eeafe480d678475c9d7fa60d4e064169.jpg"><img src="https://img.it610.com/image/info8/eeafe480d678475c9d7fa60d4e064169.jpg" alt="" /></a></p>

<pre><code>[kfk@bigdata-pro01 apache-hive-1.0.0-bin]$ bin/hive

Logging initialized using configuration in file:/opt/modules/apache-hive-1.0.0-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/modules/hadoop-2.6.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/modules/apache-hive-1.0.0-bin/lib/hive-jdbc-1.0.0-standalone.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
hive&gt; create external table weblogs(id string,datatime string,userid string,searchname string,retorder string,cliorder string,cliurl string)  STORED BY  'org.apache.hadoop.hive.hbase.HBaseStorageHandler' WITH SERDEPROPERTIES(&quot;hbase.columns.mapping&quot; = &quot;:key,info:datatime,info:userid,info:searchname,info:retorder,info:cliorder,info:cliurl&quot;) TBLPROPERTIES(&quot;hbase.table.name&quot; = &quot;weblogs&quot;);
</code></pre>

<p>以上是创建与HBase集成的Hive的外部表。</p>

<p>你创建这个只是告诉hive 去读Hbase的表。</p>

<p>你Hbase对应的表的结构要和你创建的一样。</p>

<p>你flume采集的数据有没有进入到hbase到呀。</p>

<p><strong>欢迎大家，加入我的微信公众号：大数据躺过的坑 人工智能躺过的坑</strong></p>

<hr />

<p>同时，大家可以关注 <strong>我的个人博客</strong> ：</p>

<p><strong><a href="http://www.cnblogs.com/zlslch/">http://www.cnblogs.com/zlslch/</a></strong> 和 **<a href="http://www.cnblogs.com/lchzls/">http://www.cnblogs.com/lchzls/</a>
<strong><a href="http://www.cnblogs.com/sunnyDream/">http://www.cnblogs.com/sunnyDream/</a></strong>**</p>

<p><strong>详情请见：<a href="http://www.cnblogs.com/zlslch/p/7473861.html">http://www.cnblogs.com/zlslch/p/7473861.html</a></strong></p>

<p>人生苦短，我愿分享。本公众号将秉持活到老学到老学习无休止的交流分享开源精神，汇聚于互联网和个人学习工作的精华干货知识，一切来于互联网，反馈回互联网。<br />
目前研究领域：大数据、机器学习、深度学习、人工智能、数据挖掘、数据分析。 语言涉及：Java、Scala、Python、Shell、Linux等
。同时还涉及平常所使用的手机、电脑和互联网上的使用技巧、问题和实用软件。 只要你一直关注和呆在群里，每天必须有收获</p>

<p>对应本平台的讨论和答疑QQ群：
**大数据和人工智能躺过的坑（总群）（161156071）<img src="https://img.it610.com/image/info8/1bfbd9ea56d7400cae8d8ea20e17e407.jpg" alt="" /><img src="https://img.it610.com/image/info8/1bfbd9ea56d7400cae8d8ea20e17e407.jpg" alt="" /><img src="https://img.it610.com/image/info8/1bfbd9ea56d7400cae8d8ea20e17e407.jpg" alt="" /><img src="https://img.it610.com/image/info8/1bfbd9ea56d7400cae8d8ea20e17e407.jpg" alt="" /><img src="https://img.it610.com/image/info8/1bfbd9ea56d7400cae8d8ea20e17e407.jpg" alt="" />
**</p>

<p><img src="https://img.it610.com/image/info8/33459ab519444b368d3844f6d36fdaa7.jpg" alt="" /></p>

<p><img src="https://img.it610.com/image/info8/3bc27df4e9c749fca7e10007c236d02f.jpg" alt="" /></p>

<p><img src="https://img.it610.com/image/info8/fde2ee2c6f234910832d020060500dae.jpg" alt="" /></p>

<p>转载于:<a href="https://www.cnblogs.com/zlslch/p/8228781.html">https://www.cnblogs.com/zlslch/p/8228781.html</a></p>

        </div>

        


        

<div class="post-archive">
    <h2>See Also</h2>
    <ul class="listing">
        
        <li><a href="/posts/007hadoop%E9%9B%86%E7%BE%A4%E9%85%8D%E7%BD%AEhadoop%E9%9B%86%E7%BE%A4%E7%9A%84%E5%90%AF%E5%8A%A8%E5%92%8C%E6%B5%8B%E8%AF%95ssh%E5%85%8D%E7%99%BB%E9%99%86%E9%85%8D%E7%BD%AEstartallshhdfs%E5%B8%B8%E7%94%A8%E7%9A%84shell/">007Hadoop集群配置Hadoop集群的启动和测试SSH免登陆配置startallshhdfs常用的shell</a></li>
        
        <li><a href="/posts/009shell%E8%84%9A%E6%9C%AC%E4%B8%8B%E6%9D%A1%E4%BB%B6%E6%B5%8B%E8%AF%95eqne/">009Shell脚本下条件测试eqne</a></li>
        
        <li><a href="/posts/00pythonmanagepyshell%E5%92%8Cpython%E7%9A%84%E5%88%86%E6%9E%90/">00Pythonmanagepyshell和Python的分析</a></li>
        
        <li><a href="/posts/010zookeeper%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5zookeeper%E7%9A%84%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BAzookeeper%E7%9A%84shell%E5%91%BD%E4%BB%A4/">010Zookeeper的基本概念Zookeeper的集群搭建Zookeeper的shell命令</a></li>
        
        <li><a href="/posts/018dockerfileshell/">018DockerfileSHELL</a></li>
        
    </ul>
</div>


        <div class="post-meta meta-tags">
            
            <ul class="clearfix">
                
                <li><a href='https://zaina.newban.cn/tags/shell'>shell</a></li>
                
            </ul>
            
        </div>
    </article>
    
    

    
    
</div>

                    <footer id="footer">
    <div>
        &copy; 2020 <a href="https://zaina.newban.cn">开发者问答集锦 By </a>
        
    </div>
    <br />
    <div>
        <div class="github-badge">
            <a href="https://gohugo.io/" target="_black" rel="nofollow"><span class="badge-subject">Powered by</span><span class="badge-value bg-blue">Hugo</span></a>
        </div>
        <div class="github-badge">
            <a href="https://www.flysnow.org/" target="_black"><span class="badge-subject">Design by</span><span class="badge-value bg-brightgreen">飞雪无情</span></a>
        </div>
        <div class="github-badge">
            <a href="https://github.com/flysnow-org/maupassant-hugo" target="_black"><span class="badge-subject">Theme</span><span class="badge-value bg-yellowgreen">Maupassant</span></a>
        </div>
    </div>
</footer>


    
    <script type="text/javascript">
        window.MathJax = {
            tex2jax: {
                inlineMath: [['$', '$']],
                processEscapes: true
                }
            };
    </script>
    <script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML' async></script>

<a id="rocket" href="#top"></a>
<script type="text/javascript" src='/js/totop.js?v=0.0.0' async=""></script>



    <script type="text/javascript" src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script>




                </div>

                <div id="secondary">
    <section class="widget">
        <form id="search" action='https://zaina.newban.cn/search/' method="get" accept-charset="utf-8" target="_blank" _lpchecked="1">
      
      <input type="text" name="q" maxlength="20" placeholder="Search">
      <input type="hidden" name="sitesearch" value="https://zaina.newban.cn">
      <button type="submit" class="submit icon-search"></button>
</form>
    </section>
    
    <section class="widget">
        <h3 class="widget-title">最近文章</h3>
<ul class="widget-list">
    
    <li>
        <a href="https://zaina.newban.cn/posts/001rubyruby%E4%B8%AD%E5%85%A8%E5%B1%80%E5%8F%98%E9%87%8F%E5%AE%9E%E4%BE%8B%E5%8F%98%E9%87%8F%E5%B1%80%E9%83%A8%E5%8F%98%E9%87%8F%E7%B1%BB%E5%8F%98%E9%87%8Fsymbol%E5%AF%B9%E6%AF%94/" title="001rubyRuby中全局变量实例变量局部变量类变量Symbol对比">001rubyRuby中全局变量实例变量局部变量类变量Symbol对比</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/007hadoop%E9%9B%86%E7%BE%A4%E9%85%8D%E7%BD%AEhadoop%E9%9B%86%E7%BE%A4%E7%9A%84%E5%90%AF%E5%8A%A8%E5%92%8C%E6%B5%8B%E8%AF%95ssh%E5%85%8D%E7%99%BB%E9%99%86%E9%85%8D%E7%BD%AEstartallshhdfs%E5%B8%B8%E7%94%A8%E7%9A%84shell/" title="007Hadoop集群配置Hadoop集群的启动和测试SSH免登陆配置startallshhdfs常用的shell">007Hadoop集群配置Hadoop集群的启动和测试SSH免登陆配置startallshhdfs常用的shell</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/009shell%E8%84%9A%E6%9C%AC%E4%B8%8B%E6%9D%A1%E4%BB%B6%E6%B5%8B%E8%AF%95eqne/" title="009Shell脚本下条件测试eqne">009Shell脚本下条件测试eqne</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/00pythonmanagepyshell%E5%92%8Cpython%E7%9A%84%E5%88%86%E6%9E%90/" title="00Pythonmanagepyshell和Python的分析">00Pythonmanagepyshell和Python的分析</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/010zookeeper%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5zookeeper%E7%9A%84%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BAzookeeper%E7%9A%84shell%E5%91%BD%E4%BB%A4/" title="010Zookeeper的基本概念Zookeeper的集群搭建Zookeeper的shell命令">010Zookeeper的基本概念Zookeeper的集群搭建Zookeeper的shell命令</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/018dockerfileshell/" title="018DockerfileSHELL">018DockerfileSHELL</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/01shell%E5%85%A5%E9%97%A801bashshell%E7%89%B9%E6%80%A7/" title="01Shell入门01bashShell特性">01Shell入门01bashShell特性</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/01shell%E5%8F%98%E9%87%8F/" title="01Shell变量">01Shell变量</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/01shell%E5%9F%BA%E7%A1%80%E6%A6%82%E8%BF%B0%E8%84%9A%E6%9C%AC%E6%89%A7%E8%A1%8C%E6%96%B9%E5%BC%8Fbash%E5%9F%BA%E6%9C%AC%E5%8A%9F%E8%83%BD/" title="01Shell基础概述脚本执行方式Bash基本功能">01Shell基础概述脚本执行方式Bash基本功能</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/01shell%E7%BC%96%E7%A8%8Bhelloworld/" title="01shell编程helloworld">01shell编程helloworld</a>
    </li>
    
</ul>
    </section>

    

    <section class="widget">
        <h3 class="widget-title"><a href="/categories">分类</a></h3>
<ul class="widget-list">
    
</ul>
    </section>

    <section class="widget">
        <h3 class="widget-title"><a href="/tags">标签</a></h3>
<div class="tagcloud">
    
    <a href="https://zaina.newban.cn/tags/ruby/">ruby</a>
    
    <a href="https://zaina.newban.cn/tags/shell/">shell</a>
    
</div>
    </section>

    

    <section class="widget">
        <h3 class="widget-title">其它</h3>
        <ul class="widget-list">
            <li><a href="https://zaina.newban.cn/index.xml">文章 RSS</a></li>
        </ul>
    </section>
</div>
            </div>
        </div>
    </div>
</body>

</html>