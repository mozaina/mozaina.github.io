<!doctype html>
<html lang="en-us">
<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">


    <title>启动SparkShell在SparkShell中编写WordCount程序在IDEA中编写WordCount的Maven程序sparksubmit使用spark的jar来做单词统计 | 开发者问答集锦</title>
    <meta property="og:title" content="启动SparkShell在SparkShell中编写WordCount程序在IDEA中编写WordCount的Maven程序sparksubmit使用spark的jar来做单词统计 - 开发者问答集锦">
    <meta property="og:type" content="article">
        
    <meta property="article:published_time" content='2020-09-02T00:00:00&#43;08:00'>
        
        
    <meta property="article:modified_time" content='2020-09-02T00:00:00&#43;08:00'>
        
    <meta name="Keywords" content="">
    <meta name="description" content="启动SparkShell在SparkShell中编写WordCount程序在IDEA中编写WordCount的Maven程序sparksubmit使用spark的jar来做单词统计">
        
    <meta name="author" content="">
    <meta property="og:url" content="https://zaina.newban.cn/posts/%E5%90%AF%E5%8A%A8sparkshell%E5%9C%A8sparkshell%E4%B8%AD%E7%BC%96%E5%86%99wordcount%E7%A8%8B%E5%BA%8F%E5%9C%A8idea%E4%B8%AD%E7%BC%96%E5%86%99wordcount%E7%9A%84maven%E7%A8%8B%E5%BA%8Fsparksubmit%E4%BD%BF%E7%94%A8spark%E7%9A%84jar%E6%9D%A5%E5%81%9A%E5%8D%95%E8%AF%8D%E7%BB%9F%E8%AE%A1/">
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">

    <link rel="stylesheet" href='/css/normalize.css'>
    <link rel="stylesheet" href='/css/style.css'>
    <script type="text/javascript" src="//cdn.bootcdn.net/ajax/libs/jquery/3.4.1/jquery.min.js"></script>

    
    
    
    
    
    
</head>


<body>
    <header id="header" class="clearfix">
    <div class="container">
        <div class="col-group">
            <div class="site-name ">
                
                    <a id="logo" href="https://zaina.newban.cn">
                        开发者问答集锦
                    </a>
                
                
            </div>
            <div>
                <nav id="nav-menu" class="clearfix">
                    <a class="" href="https://zaina.newban.cn">首页</a>
                    
                </nav>
            </div>
        </div>
    </div>
</header>

    <div id="body">
        <div class="container">
            <div class="col-group">

                <div class="col-8" id="main">
                    
<div class="res-cons">
    
    <article class="post">
        <header>
            <h1 class="post-title">启动SparkShell在SparkShell中编写WordCount程序在IDEA中编写WordCount的Maven程序sparksubmit使用spark的jar来做单词统计</h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        
        <div class="post-meta">
            <span id="busuanzi_container_page_pv">|<span id="busuanzi_value_page_pv"></span><span>
                    阅读</span></span>
        </div>
        
        
        <div class="post-content">
            

<h1 id="1-启动spark-shell">1.启动Spark Shell</h1>

<p>spark-
shell是Spark自带的交互式Shell程序，方便用户进行交互式编程，用户可以在该命令行下用scala编写spark程序。要注意的是要启动Spark-
Shell需要先启动Spark-
ha集群，Spark集群安装和部署参考：<a href="http://blog.csdn.net/tototuzuoquan/article/details/74481570">http://blog.csdn.net/tototuzuoquan/article/details/74481570</a></p>

<h3 id="1-2-1-启动spark-shell">1.2.1、启动spark shell</h3>

<p>启动方式一：</p>

<pre><code>[root@hadoop1 spark-2.1.1-bin-hadoop2.7]# cd $SPARK_HOME 
[root@hadoop1 spark-2.1.1-bin-hadoop2.7]# pwd
/home/tuzq/software/spark-2.1.1-bin-hadoop2.7
[root@hadoop1 spark-2.1.1-bin-hadoop2.7]# bin/spark-shell --master spark://hadoop1:7077,hadoop2:7077
</code></pre>

<p>通过使用–master指定master的地址，连接的是启动着的那个master</p>

<p>同样，还可以指定执行的内存数和总的核心数</p>

<pre><code>[root@hadoop1 spark-2.1.1-bin-hadoop2.7]# cd $SPARK_HOME
[root@hadoop1 spark-2.1.1-bin-hadoop2.7]# bin/spark-shell --master spark://hadoop1:7077,hadoop2:7077 --executor-memory 2g --total-executor-cores 2
</code></pre>

<p><strong>参数说明：</strong><br />
–master spark://hadoop:7077 指定Master的地址<br />
–executor-memory 2g 指定每个worker可用内存为2G<br />
–total-executor-cores 2 指定整个集群使用的cup核数为2个</p>

<p>注意：<br />
如果启动spark shell时没有指定master地址，但是也可以正常启动spark shell和执行spark
shell中的程序，其实是启动了spark的local模式，该模式仅在本机启动一个进程，没有与集群建立联系。</p>

<p>Spark Shell中已经默认将SparkContext类初始化为对象sc。用户代码如果需要用到，则直接应用sc即可</p>

<h3 id="1-2-2-在spark-shell中编写wordcount程序">1.2.2、在spark shell中编写WordCount程序</h3>

<p><strong>1.</strong> 首先启动hdfs<br />
<strong>2.</strong> 向hdfs上传一个文件到hdfs（hdfs://mycluster/wordcount/input/2.txt）<br />
效果图下：<br />
<a href="https://img.it610.com/image/info8/5e4157faa1b54ea0929602a424f55113.png"><img src="https://img.it610.com/image/info8/5e4157faa1b54ea0929602a424f55113.png" alt="启动Spark Shell,在Spark Shell中编写WordCount程序，在IDEA中编写WordCount的Maven程序，spark-
submit使用spark的jar来做单词统计_第1张图片" /></a></p>

<p>如果通过带有协议的方式访问hadoop集群上的文件可以通过下面的方式：</p>

<pre><code>[root@hadoop2 hadoop-2.8.0]# hdfs dfs -ls hdfs://mycluster/
Found 2 items
drwx-wx-wx   - root supergroup          0 2017-07-06 11:11 hdfs://mycluster/tmp
drwxr-xr-x   - root supergroup          0 2017-07-06 11:16 hdfs://mycluster/wordcount
[root@hadoop2 hadoop-2.8.0]# hdfs dfs -ls hdfs://mycluster/wordcount/input
Found 9 items
-rw-r--r--   3 root supergroup        604 2017-07-06 11:16 hdfs://mycluster/wordcount/input/1.txt
-rw-r--r--   3 root supergroup        604 2017-07-06 11:16 hdfs://mycluster/wordcount/input/2.txt
-rw-r--r--   3 root supergroup        604 2017-07-06 11:16 hdfs://mycluster/wordcount/input/3.txt
-rw-r--r--   3 root supergroup        604 2017-07-06 11:16 hdfs://mycluster/wordcount/input/4.txt
-rw-r--r--   3 root supergroup        604 2017-07-06 11:16 hdfs://mycluster/wordcount/input/5.txt
-rw-r--r--   3 root supergroup   27209520 2017-07-06 11:16 hdfs://mycluster/wordcount/input/a.txt
-rw-r--r--   3 root supergroup   27209520 2017-07-06 11:16 hdfs://mycluster/wordcount/input/aaa.txt
-rw-r--r--   3 root supergroup   27787264 2017-07-06 11:16 hdfs://mycluster/wordcount/input/b.txt
-rw-r--r--   3 root supergroup   26738688 2017-07-06 11:16 hdfs://mycluster/wordcount/input/c.txt
[root@hadoop2 hadoop-2.8.0]# hdfs dfs -ls hdfs://mycluster/wordcount/input/2.txt
-rw-r--r--   3 root supergroup        604 2017-07-06 11:16 hdfs://mycluster/wordcount/input/2.txt
[root@hadoop2 hadoop-2.8.0]# hdfs dfs -cat hdfs://mycluster/wordcount/input/2.txt
Collecting and analysis base data for big data analysis;Maintenance Hadoop platform 
Development Hadoop framework 
Cooperate with data scientist, verify and implement data models to realize automatic and accurate fraud detection, in order to improve the risk management level of E-commerce/payment platforms 
Analyze information acquired and compare solutions and weight them against the actual needs, provide root cause analysis affecting key business problems 
Play an active role in company's anti-fraud platform strategy 
Support related data analysis work, and provide valuable business reports[root@hadoop2 hadoop-2.8.0]#
</code></pre>

<p><strong>3.</strong> 在spark shell中用scala语言编写spark程序</p>

<pre><code>scala&gt; sc.textFile(&quot;hdfs://mycluster/wordcount/input/2.txt&quot;).flatMap(_.split(&quot; &quot;)).map((_,1)).reduceByKey(_+_).saveAsTextFile(&quot;hdfs://mycluster/wordcount/output&quot;)
</code></pre>

<p><strong>1.</strong> 使用hdfs命令查看结果</p>

<pre><code>[root@hadoop2 hadoop-2.8.0]# hdfs dfs -ls hdfs://mycluster/wordcount/output
Found 3 items
-rw-r--r--   3 root supergroup          0 2017-07-06 11:48 hdfs://mycluster/wordcount/output/_SUCCESS
-rw-r--r--   3 root supergroup        400 2017-07-06 11:48 hdfs://mycluster/wordcount/output/part-00000
-rw-r--r--   3 root supergroup        346 2017-07-06 11:48 hdfs://mycluster/wordcount/output/part-00001
[root@hadoop2 hadoop-2.8.0]# hdfs dfs -cat hdfs://mycluster/wordcount/output/part-00000
(role,1)
(Play,1)
(fraud,1)
(level,1)
(business,2)
(improve,1)
(platforms,1)
(order,1)
(big,1)
(with,1)
(scientist,,1)
(active,1)
(valuable,1)
(data,5)
(information,1)
(Cooperate,1)
(Collecting,1)
(framework,1)
(E-commerce/payment,1)
(acquired,1)
(root,1)
(accurate,1)
(solutions,1)
(analysis;Maintenance,1)
(problems,1)
(them,1)
(Analyze,1)
(models,1)
(analysis,3)
(realize,1)
(actual,1)
(weight,1)
[root@hadoop2 hadoop-2.8.0]#
</code></pre>

<p>说明：<br />
sc是SparkContext对象，该对象是提交spark程序的入口<br />
sc.textFile(“hdfs://mycluster/wordcount/input/2.txt”)是从hdfs中读取数据<br />
flatMap(<em>.split(” “))先map在压平<br />
map((</em>,1))将单词和1构成元组<br />
reduceByKey( <em>+</em> )按照key进行reduce，并将value累加<br />
saveAsTextFile(“hdfs://mycluster/wordcount/output”)将结果写入到hdfs中</p>

<p><strong>将wordCound的结果排序，并显示的代码：</strong></p>

<pre><code>scala&gt; sc.textFile(&quot;hdfs://mycluster/wordcount/input/2.txt&quot;).flatMap(_.split(&quot; &quot;)).map((_,1)).reduceByKey(_+_).sortBy(_._2,false).collect
res2: Array[(String, Int)] = Array((and,6), (data,5), (analysis,3), (business,2), (to,2), (platform,2), (in,2), (provide,2), (the,2), (Hadoop,2), (compare,1), (risk,1), (anti-fraud,1), (key,1), (related,1), (base,1), (Support,1), (against,1), (automatic,1), (company's,1), (needs,,1), (implement,1), (affecting,1), (strategy,1), (of,1), (reports,1), (management,1), (detection,,1), (for,1), (work,,1), (cause,1), (an,1), (verify,1), (Development,1), (role,1), (Play,1), (fraud,1), (level,1), (improve,1), (platforms,1), (order,1), (big,1), (with,1), (scientist,,1), (active,1), (valuable,1), (information,1), (Cooperate,1), (Collecting,1), (framework,1), (E-commerce/payment,1), (acquired,1), (root,1), (accurate,1), (solutions,1), (analysis;Maintenance,1), (problems,1), (them,1), (Analyze,1), (m...
scala&gt;
</code></pre>

<h1 id="2-idea中创建spark的maven工程">2、idea中创建spark的maven工程</h1>

<p>spark
shell仅在测试和验证我们的程序时使用的较多，在生产环境中，通常会在IDE中编制程序，然后打成jar包，然后提交到集群，最常用的是创建一个Maven项目，利用Maven来管理jar包的依赖。</p>

<p><strong>创建Maven工程：</strong><br />
<a href="https://img.it610.com/image/info8/f84fc3ebf3514ed995c42b63515e8fe3.jpg"><img src="https://img.it610.com/image/info8/f84fc3ebf3514ed995c42b63515e8fe3.jpg" alt="启动Spark Shell,在Spark Shell中编写WordCount程序，在IDEA中编写WordCount的Maven程序，spark-
submit使用spark的jar来做单词统计_第2张图片" /></a><br />
<a href="https://img.it610.com/image/info8/2ad1abc0c7ab494a94c09808048bd9ea.jpg"><img src="https://img.it610.com/image/info8/2ad1abc0c7ab494a94c09808048bd9ea.jpg" alt="启动Spark Shell,在Spark Shell中编写WordCount程序，在IDEA中编写WordCount的Maven程序，spark-
submit使用spark的jar来做单词统计_第3张图片" /></a><br />
<a href="https://img.it610.com/image/info8/3bd83f8854e74bc39f586ac43e1b0b09.jpg"><img src="https://img.it610.com/image/info8/3bd83f8854e74bc39f586ac43e1b0b09.jpg" alt="启动Spark Shell,在Spark Shell中编写WordCount程序，在IDEA中编写WordCount的Maven程序，spark-
submit使用spark的jar来做单词统计_第4张图片" /></a><br />
<a href="https://img.it610.com/image/info8/089d33d3877e47caa7232a93c9e6fd5c.jpg"><img src="https://img.it610.com/image/info8/089d33d3877e47caa7232a93c9e6fd5c.jpg" alt="启动Spark Shell,在Spark Shell中编写WordCount程序，在IDEA中编写WordCount的Maven程序，spark-
submit使用spark的jar来做单词统计_第5张图片" /></a><br />
<strong>要注意的是，在创建好项目之后，一定要重新制定好Maven仓库所在的位置，不然可能会导致重新下载jar包：</strong><br />
<a href="https://img.it610.com/image/info8/d3e8693f3daa440fa9bd4bfc1c4b9947.jpg"><img src="https://img.it610.com/image/info8/d3e8693f3daa440fa9bd4bfc1c4b9947.jpg" alt="启动Spark Shell,在Spark Shell中编写WordCount程序，在IDEA中编写WordCount的Maven程序，spark-
submit使用spark的jar来做单词统计_第6张图片" /></a></p>

<p><strong>创建好maven项目后，点击Enable Auto-Import</strong><br />
<a href="https://img.it610.com/image/info8/bb5c32101c66416995716c495e5c8833.jpg"><img src="https://img.it610.com/image/info8/bb5c32101c66416995716c495e5c8833.jpg" alt="启动Spark Shell,在Spark Shell中编写WordCount程序，在IDEA中编写WordCount的Maven程序，spark-
submit使用spark的jar来做单词统计_第7张图片" /></a><br />
<strong>配置Maven的pom.xml</strong></p>

<pre><code>&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot;
         xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
         xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;
    &lt;modelVersion&gt;4.0.0modelVersion&gt;

    &lt;groupId&gt;cn.toto.sparkgroupId&gt;
    &lt;artifactId&gt;wordCountartifactId&gt;
    &lt;version&gt;1.0-SNAPSHOTversion&gt;

    &lt;properties&gt;
        &lt;maven.compiler.source&gt;1.7maven.compiler.source&gt;
        &lt;maven.compiler.target&gt;1.7maven.compiler.target&gt;
        &lt;encoding&gt;UTF-8encoding&gt;
        &lt;scala.version&gt;2.10.6scala.version&gt;
        &lt;scala.compat.version&gt;2.10scala.compat.version&gt;
    properties&gt;

    &lt;dependencies&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.scala-langgroupId&gt;
            &lt;artifactId&gt;scala-libraryartifactId&gt;
            &lt;version&gt;${scala.version}version&gt;
        dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.sparkgroupId&gt;
            &lt;artifactId&gt;spark-core_2.10artifactId&gt;
            &lt;version&gt;1.5.2version&gt;
        dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.sparkgroupId&gt;
            &lt;artifactId&gt;spark-streaming_2.10artifactId&gt;
            &lt;version&gt;1.5.2version&gt;
        dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.hadoopgroupId&gt;
            &lt;artifactId&gt;hadoop-clientartifactId&gt;
            &lt;version&gt;2.6.2version&gt;
        dependency&gt;
    dependencies&gt;

    &lt;build&gt;
        &lt;sourceDirectory&gt;src/main/scalasourceDirectory&gt;
        &lt;testSourceDirectory&gt;src/test/scalatestSourceDirectory&gt;
        &lt;plugins&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;net.alchim31.mavengroupId&gt;
                &lt;artifactId&gt;scala-maven-pluginartifactId&gt;
                &lt;version&gt;3.2.0version&gt;
                &lt;executions&gt;
                    &lt;execution&gt;
                        &lt;goals&gt;
                            &lt;goal&gt;compilegoal&gt;
                            &lt;goal&gt;testCompilegoal&gt;
                        goals&gt;
                        &lt;configuration&gt;
                            &lt;args&gt;
                                &lt;arg&gt;-make:transitivearg&gt;
                                &lt;arg&gt;-dependencyfilearg&gt;
                                &lt;arg&gt;${project.build.directory}/.scala_dependenciesarg&gt;
                            args&gt;
                        configuration&gt;
                    execution&gt;
                executions&gt;
            plugin&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.apache.maven.pluginsgroupId&gt;
                &lt;artifactId&gt;maven-surefire-pluginartifactId&gt;
                &lt;version&gt;2.18.1version&gt;
                &lt;configuration&gt;
                    &lt;useFile&gt;falseuseFile&gt;
                    &lt;disableXmlReport&gt;truedisableXmlReport&gt;
                    &lt;includes&gt;
                        &lt;include&gt;**/*Test.*include&gt;
                        &lt;include&gt;**/*Suite.*include&gt;
                    includes&gt;
                configuration&gt;
            plugin&gt;

            &lt;plugin&gt;
                &lt;groupId&gt;org.apache.maven.pluginsgroupId&gt;
                &lt;artifactId&gt;maven-shade-pluginartifactId&gt;
                &lt;version&gt;2.3version&gt;
                &lt;executions&gt;
                    &lt;execution&gt;
                        &lt;phase&gt;packagephase&gt;
                        &lt;goals&gt;
                            &lt;goal&gt;shadegoal&gt;
                        goals&gt;
                        &lt;configuration&gt;
                            &lt;filters&gt;
                                &lt;filter&gt;
                                    &lt;artifact&gt;*:*artifact&gt;
                                    &lt;excludes&gt;
                                        &lt;exclude&gt;META-INF/*.SFexclude&gt;
                                        &lt;exclude&gt;META-INF/*.DSAexclude&gt;
                                        &lt;exclude&gt;META-INF/*.RSAexclude&gt;
                                    excludes&gt;
                                filter&gt;
                            filters&gt;
                            &lt;transformers&gt;
                                &lt;transformer implementation=&quot;org.apache.maven.plugins.shade.resource.ManifestResourceTransformer&quot;&gt;
                                    &lt;mainClass&gt;cn.toto.spark.WordCountmainClass&gt;
                                transformer&gt;
                            transformers&gt;
                        configuration&gt;
                    execution&gt;
                executions&gt;
            plugin&gt;
        plugins&gt;
    build&gt;
project&gt;
</code></pre>

<p><strong>将src/main/java和src/test/java分别修改成src/main/scala和src/test/scala(或者创建scala的Directory)，与pom.xml中的配置保持一致</strong><br />
<a href="https://img.it610.com/image/info8/3003d185ff004ef38d847d62678a6b3e.png"><img src="https://img.it610.com/image/info8/3003d185ff004ef38d847d62678a6b3e.png" alt="启动Spark Shell,在Spark Shell中编写WordCount程序，在IDEA中编写WordCount的Maven程序，spark-
submit使用spark的jar来做单词统计_第8张图片" /></a><br />
<a href="https://img.it610.com/image/info8/47615223c0d243bb9f9156ec94e79fd9.jpg"><img src="https://img.it610.com/image/info8/47615223c0d243bb9f9156ec94e79fd9.jpg" alt="启动Spark Shell,在Spark Shell中编写WordCount程序，在IDEA中编写WordCount的Maven程序，spark-
submit使用spark的jar来做单词统计_第9张图片" /></a></p>

<p><strong>或者通过如下方式：</strong><br />
<a href="https://img.it610.com/image/info8/785e22c2f59c4a7f826a42df4ce2da2e.jpg"><img src="https://img.it610.com/image/info8/785e22c2f59c4a7f826a42df4ce2da2e.jpg" alt="启动Spark Shell,在Spark Shell中编写WordCount程序，在IDEA中编写WordCount的Maven程序，spark-
submit使用spark的jar来做单词统计_第10张图片" /></a><br />
<a href="https://img.it610.com/image/info8/5b0bafd2ff58471f99b2b6748fb3dc22.jpg"><img src="https://img.it610.com/image/info8/5b0bafd2ff58471f99b2b6748fb3dc22.jpg" alt="启动Spark Shell,在Spark Shell中编写WordCount程序，在IDEA中编写WordCount的Maven程序，spark-
submit使用spark的jar来做单词统计_第11张图片" /></a><br />
<strong>新建一个scala class，类型为Object</strong><br />
<a href="https://img.it610.com/image/info8/b565fbdc5fe64278975d57b7cd46c5d2.jpg"><img src="https://img.it610.com/image/info8/b565fbdc5fe64278975d57b7cd46c5d2.jpg" alt="启动Spark Shell,在Spark Shell中编写WordCount程序，在IDEA中编写WordCount的Maven程序，spark-
submit使用spark的jar来做单词统计_第12张图片" /></a></p>

<p><strong>编写spark程序代码：</strong></p>

<pre><code>package cn.toto.spark

import org.apache.spark.rdd.RDD
import org.apache.spark.{SparkConf, SparkContext}

/**
  * Created by toto on 2017/7/6.
  */
object WordCount {

  def main(args: Array[String]): Unit = {
    //创建sparkconf
    val conf=new SparkConf().setAppName(&quot;WordCount&quot;)
    //创建sparkcontext
    val sc=new SparkContext(conf)
    //读取hdfs中的数据
    val line:RDD[String]=sc.textFile(args(0))
    //切分单词
    val words:RDD[String]=line.flatMap(_.split(&quot; &quot;))
    //将单词计算
    val wordAndOne:RDD[(String,Int)]=words.map((_,1))
    //分组聚合
    val result:RDD[(String,Int)]=wordAndOne.reduceByKey((x,y)=&gt;x+y)
    //排序
    val finalResult:RDD[(String,Int)]=result.sortBy(_._2,false)
    //将数据存到HDFS中
    finalResult.saveAsTextFile(args(1))
    //释放资源
    sc.stop()
  }
}
</code></pre>

<p><strong>打包：</strong><br />
<a href="https://img.it610.com/image/info8/89db257a27204293aa71d45eeeb95910.jpg"><img src="https://img.it610.com/image/info8/89db257a27204293aa71d45eeeb95910.jpg" alt="启动Spark Shell,在Spark Shell中编写WordCount程序，在IDEA中编写WordCount的Maven程序，spark-
submit使用spark的jar来做单词统计_第13张图片" /></a><br />
<strong>进入工程的target目录下面，获取jar包</strong><br />
<a href="https://img.it610.com/image/info8/2abff1e2b1754a47a08ae02cd698f82d.jpg"><img src="https://img.it610.com/image/info8/2abff1e2b1754a47a08ae02cd698f82d.jpg" alt="启动Spark Shell,在Spark Shell中编写WordCount程序，在IDEA中编写WordCount的Maven程序，spark-
submit使用spark的jar来做单词统计_第14张图片" /></a><br />
<strong>或者直接在IDEA的工程目录下找到：</strong><br />
<a href="https://img.it610.com/image/info8/bd0851fce7c84d3a915f5e5d5d192521.png"><img src="https://img.it610.com/image/info8/bd0851fce7c84d3a915f5e5d5d192521.png" alt="启动Spark Shell,在Spark Shell中编写WordCount程序，在IDEA中编写WordCount的Maven程序，spark-
submit使用spark的jar来做单词统计_第15张图片" /></a></p>

<p><strong>将wordCount-1.0-SNAPSHOT.jar上传到/home/tuzq/software/sparkdata下</strong><br />
<a href="https://img.it610.com/image/info8/7ff96d43b4104278a2b9422d88bf509b.png"><img src="https://img.it610.com/image/info8/7ff96d43b4104278a2b9422d88bf509b.png" alt="这里写图片描述" /></a></p>

<p><strong>使用spark的jar来做单词统计</strong><br />
要注意的是最后的输出路径要不存在，并且运行下面的程序的时候，最好是把spark-shell给关闭了。否则可能会报错。</p>

<pre><code>bin/spark-submit --master spark://hadoop1:7077,hadoop2:7077 --executor-memory 512m --total-executor-cores 6 --class cn.toto.spark.WordCount /home/tuzq/software/sparkdata/wordCount-1.0-SNAPSHOT.jar hdfs://mycluster/wordcount/input hdfs://mycluster/wordcount/out0001
</code></pre>

<p>运行时的状态：<br />
<a href="https://img.it610.com/image/info8/0bf5634bd5304683bc411a4ac61be8d5.jpg"><img src="https://img.it610.com/image/info8/0bf5634bd5304683bc411a4ac61be8d5.jpg" alt="启动Spark Shell,在Spark Shell中编写WordCount程序，在IDEA中编写WordCount的Maven程序，spark-
submit使用spark的jar来做单词统计_第16张图片" /></a></p>

<p>查看hdfs上的结果：</p>

<pre><code>[root@hadoop1 spark-2.1.1-bin-hadoop2.7]# hdfs dfs -ls hdfs://mycluster/wordcount/out0002
Found 10 items
-rw-r--r--   3 root supergroup          0 2017-07-06 13:13 hdfs://mycluster/wordcount/out0002/_SUCCESS
-rw-r--r--   3 root supergroup        191 2017-07-06 13:13 hdfs://mycluster/wordcount/out0002/part-00000
-rw-r--r--   3 root supergroup        671 2017-07-06 13:13 hdfs://mycluster/wordcount/out0002/part-00001
-rw-r--r--   3 root supergroup        245 2017-07-06 13:13 hdfs://mycluster/wordcount/out0002/part-00002
-rw-r--r--   3 root supergroup         31 2017-07-06 13:13 hdfs://mycluster/wordcount/out0002/part-00003
-rw-r--r--   3 root supergroup       1096 2017-07-06 13:13 hdfs://mycluster/wordcount/out0002/part-00004
-rw-r--r--   3 root supergroup         11 2017-07-06 13:13 hdfs://mycluster/wordcount/out0002/part-00005
-rw-r--r--   3 root supergroup        936 2017-07-06 13:13 hdfs://mycluster/wordcount/out0002/part-00006
-rw-r--r--   3 root supergroup        588 2017-07-06 13:13 hdfs://mycluster/wordcount/out0002/part-00007
-rw-r--r--   3 root supergroup        609 2017-07-06 13:13 hdfs://mycluster/wordcount/out0002/part-00008
</code></pre>

<p>查看其中的任何一个：</p>

<pre><code>[root@hadoop1 spark-2.1.1-bin-hadoop2.7]# hdfs dfs -cat hdfs://mycluster/wordcount/out0002/part-00000
(and,770752)
(is,659375)
(I,505440)
(a,468642)
(to,431857)
(in,421230)
(the,331176)
(of,272080)
(FDS,218862)
(for,213029)
(The,196569)
(true,196567)
(but,196566)
(on,193650)
(without,193649)
[root@hadoop1 spark-2.1.1-bin-hadoop2.7]#
</code></pre>

        </div>

        


        

<div class="post-archive">
    <h2>See Also</h2>
    <ul class="listing">
        
        <li><a href="/posts/007hadoop%E9%9B%86%E7%BE%A4%E9%85%8D%E7%BD%AEhadoop%E9%9B%86%E7%BE%A4%E7%9A%84%E5%90%AF%E5%8A%A8%E5%92%8C%E6%B5%8B%E8%AF%95ssh%E5%85%8D%E7%99%BB%E9%99%86%E9%85%8D%E7%BD%AEstartallshhdfs%E5%B8%B8%E7%94%A8%E7%9A%84shell/">007Hadoop集群配置Hadoop集群的启动和测试SSH免登陆配置startallshhdfs常用的shell</a></li>
        
        <li><a href="/posts/009shell%E8%84%9A%E6%9C%AC%E4%B8%8B%E6%9D%A1%E4%BB%B6%E6%B5%8B%E8%AF%95eqne/">009Shell脚本下条件测试eqne</a></li>
        
        <li><a href="/posts/00pythonmanagepyshell%E5%92%8Cpython%E7%9A%84%E5%88%86%E6%9E%90/">00Pythonmanagepyshell和Python的分析</a></li>
        
        <li><a href="/posts/010zookeeper%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5zookeeper%E7%9A%84%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BAzookeeper%E7%9A%84shell%E5%91%BD%E4%BB%A4/">010Zookeeper的基本概念Zookeeper的集群搭建Zookeeper的shell命令</a></li>
        
        <li><a href="/posts/018dockerfileshell/">018DockerfileSHELL</a></li>
        
    </ul>
</div>


        <div class="post-meta meta-tags">
            
            <ul class="clearfix">
                
                <li><a href='https://zaina.newban.cn/tags/shell'>shell</a></li>
                
            </ul>
            
        </div>
    </article>
    
    

    
    
</div>

                    <footer id="footer">
    <div>
        &copy; 2020 <a href="https://zaina.newban.cn">开发者问答集锦 By </a>
        
    </div>
    <br />
    <div>
        <div class="github-badge">
            <a href="https://gohugo.io/" target="_black" rel="nofollow"><span class="badge-subject">Powered by</span><span class="badge-value bg-blue">Hugo</span></a>
        </div>
        <div class="github-badge">
            <a href="https://www.flysnow.org/" target="_black"><span class="badge-subject">Design by</span><span class="badge-value bg-brightgreen">飞雪无情</span></a>
        </div>
        <div class="github-badge">
            <a href="https://github.com/flysnow-org/maupassant-hugo" target="_black"><span class="badge-subject">Theme</span><span class="badge-value bg-yellowgreen">Maupassant</span></a>
        </div>
    </div>
</footer>


    
    <script type="text/javascript">
        window.MathJax = {
            tex2jax: {
                inlineMath: [['$', '$']],
                processEscapes: true
                }
            };
    </script>
    <script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML' async></script>

<a id="rocket" href="#top"></a>
<script type="text/javascript" src='/js/totop.js?v=0.0.0' async=""></script>



    <script type="text/javascript" src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script>




                </div>

                <div id="secondary">
    <section class="widget">
        <form id="search" action='https://zaina.newban.cn/search/' method="get" accept-charset="utf-8" target="_blank" _lpchecked="1">
      
      <input type="text" name="q" maxlength="20" placeholder="Search">
      <input type="hidden" name="sitesearch" value="https://zaina.newban.cn">
      <button type="submit" class="submit icon-search"></button>
</form>
    </section>
    
    <section class="widget">
        <h3 class="widget-title">最近文章</h3>
<ul class="widget-list">
    
    <li>
        <a href="https://zaina.newban.cn/posts/001rubyruby%E4%B8%AD%E5%85%A8%E5%B1%80%E5%8F%98%E9%87%8F%E5%AE%9E%E4%BE%8B%E5%8F%98%E9%87%8F%E5%B1%80%E9%83%A8%E5%8F%98%E9%87%8F%E7%B1%BB%E5%8F%98%E9%87%8Fsymbol%E5%AF%B9%E6%AF%94/" title="001rubyRuby中全局变量实例变量局部变量类变量Symbol对比">001rubyRuby中全局变量实例变量局部变量类变量Symbol对比</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/007hadoop%E9%9B%86%E7%BE%A4%E9%85%8D%E7%BD%AEhadoop%E9%9B%86%E7%BE%A4%E7%9A%84%E5%90%AF%E5%8A%A8%E5%92%8C%E6%B5%8B%E8%AF%95ssh%E5%85%8D%E7%99%BB%E9%99%86%E9%85%8D%E7%BD%AEstartallshhdfs%E5%B8%B8%E7%94%A8%E7%9A%84shell/" title="007Hadoop集群配置Hadoop集群的启动和测试SSH免登陆配置startallshhdfs常用的shell">007Hadoop集群配置Hadoop集群的启动和测试SSH免登陆配置startallshhdfs常用的shell</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/009shell%E8%84%9A%E6%9C%AC%E4%B8%8B%E6%9D%A1%E4%BB%B6%E6%B5%8B%E8%AF%95eqne/" title="009Shell脚本下条件测试eqne">009Shell脚本下条件测试eqne</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/00pythonmanagepyshell%E5%92%8Cpython%E7%9A%84%E5%88%86%E6%9E%90/" title="00Pythonmanagepyshell和Python的分析">00Pythonmanagepyshell和Python的分析</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/010zookeeper%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5zookeeper%E7%9A%84%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BAzookeeper%E7%9A%84shell%E5%91%BD%E4%BB%A4/" title="010Zookeeper的基本概念Zookeeper的集群搭建Zookeeper的shell命令">010Zookeeper的基本概念Zookeeper的集群搭建Zookeeper的shell命令</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/018dockerfileshell/" title="018DockerfileSHELL">018DockerfileSHELL</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/01shell%E5%85%A5%E9%97%A801bashshell%E7%89%B9%E6%80%A7/" title="01Shell入门01bashShell特性">01Shell入门01bashShell特性</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/01shell%E5%8F%98%E9%87%8F/" title="01Shell变量">01Shell变量</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/01shell%E5%9F%BA%E7%A1%80%E6%A6%82%E8%BF%B0%E8%84%9A%E6%9C%AC%E6%89%A7%E8%A1%8C%E6%96%B9%E5%BC%8Fbash%E5%9F%BA%E6%9C%AC%E5%8A%9F%E8%83%BD/" title="01Shell基础概述脚本执行方式Bash基本功能">01Shell基础概述脚本执行方式Bash基本功能</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/01shell%E7%BC%96%E7%A8%8Bhelloworld/" title="01shell编程helloworld">01shell编程helloworld</a>
    </li>
    
</ul>
    </section>

    

    <section class="widget">
        <h3 class="widget-title"><a href="/categories">分类</a></h3>
<ul class="widget-list">
    
</ul>
    </section>

    <section class="widget">
        <h3 class="widget-title"><a href="/tags">标签</a></h3>
<div class="tagcloud">
    
    <a href="https://zaina.newban.cn/tags/ruby/">ruby</a>
    
    <a href="https://zaina.newban.cn/tags/shell/">shell</a>
    
</div>
    </section>

    

    <section class="widget">
        <h3 class="widget-title">其它</h3>
        <ul class="widget-list">
            <li><a href="https://zaina.newban.cn/index.xml">文章 RSS</a></li>
        </ul>
    </section>
</div>
            </div>
        </div>
    </div>
</body>

</html>