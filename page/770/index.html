<!doctype html>
<html lang="en-us">
<head>
	<meta name="generator" content="Hugo 0.59.1" />

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">


    <title>开发者问答集锦 | </title>
    <meta property="og:title" content="开发者问答集锦 | ">
    <meta property="og:type" content="website">
    <meta name="Keywords" content="">
    <meta name="description" content="">
    <meta property="og:url" content="https://zaina.newban.cn/">
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">

    <link rel="stylesheet" href='/css/normalize.css'>
    <link rel="stylesheet" href='/css/style.css'>
    <link rel="alternate" type="application/rss+xml+xml" href="https://zaina.newban.cn/index.xml" title="开发者问答集锦" />
    <script type="text/javascript" src="//cdn.bootcdn.net/ajax/libs/jquery/3.4.1/jquery.min.js"></script>

    
    
    
    
    
    
</head>


<body>
    <header id="header" class="clearfix">
    <div class="container">
        <div class="col-group">
            <div class="site-name ">
                
                    <h1>
                        <a id="logo" href="https://zaina.newban.cn">
                            开发者问答集锦
                        </a>
                    </h1>
                
                
            </div>
            <div>
                <nav id="nav-menu" class="clearfix">
                    <a class="current" href="https://zaina.newban.cn">首页</a>
                    
                </nav>
            </div>
        </div>
    </div>
</header>

    <div id="body">
        <div class="container">
            <div class="col-group">

                <div class="col-8" id="main">
                    
<div class="res-cons">
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/scrapyshell%E5%A6%82%E4%BD%95%E6%B7%BB%E5%8A%A0useragent/" title="Scrapyshell如何添加UserAgent">Scrapyshell如何添加UserAgent</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            我们在运用scrapy shell调试的时候，通常会遇到返回的response的状态码为302，这是因为没有加User_Agent的原因。比如爬取拉勾网的时候，没加请求头给我返回302重定向，如图：
所以我们可以在进行scrapy shell 调试的时候，加入User_Agent进行伪装，
scrapy shell -s USER_AGENT=&quot;Mozilla/5.0 (Windows NT 10.0; …) Gecko/20100101 Firefox/60.0&quot; 你需要爬取的url  然后就可以愉快的调试和爬取了，效果如图：

本人不是老鸟，记录和分享换一下自己爬虫过程中的问题和疑点。
不喜勿喷，谢谢大家~~~……
        </div>
        <p class="readmore"><a href="https://zaina.newban.cn/posts/scrapyshell%E5%A6%82%E4%BD%95%E6%B7%BB%E5%8A%A0useragent/">阅读全文</a></p>
    </article>
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/scrapyshell%E7%88%AC%E5%8F%96%E4%B8%80%E4%BA%9B%E7%BD%91%E7%AB%99%E4%B8%8D%E5%93%8D%E5%BA%94/" title="scrapyshell爬取一些网站不响应">scrapyshell爬取一些网站不响应</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            在爬去京东某商品网页时，如https://search.jd.com/Search?keyword=%E6%83%A0%E6%99%AE&amp;enc=utf-8&amp;suggest=1.his.0.0&amp;wq=&amp;pvid=d66c3ae3039d42b09f015585015ef653 实际上用 https://search.jd.com/Search?keyword=惠普&amp;enc=utf-8 也可以
但是在scrapy shell 里始终无响应，仔细观察，你会发现有从定向的的现象，因此我们要解决的从定向问题（个人认为原因是出在这个地方）
在scrapy.Request中，我们知道可以通过设置参数来阻止重定向
from scrapy import Request Request(&quot;https://search.jd.com/Search?keyword=惠普&amp;enc=utf-8&quot;,meta = {'dont_redirect': True})  {
区分scrapy的Request对象
python 的第三方库 requests模块
pip install requests
import requests html = requests.get(url, headers=headers, allow_redirects=False)  }
回来
那么如何在shell里实现
scrapy shell
from scrapy import Request
response=Request(&ldquo;https://search.jd.com/Search?keyword=惠普&amp;enc=utf-8&quot;,meta = { &lsquo;dont_redirect&rsquo;: True})
re = fetch(response)……
        </div>
        <p class="readmore"><a href="https://zaina.newban.cn/posts/scrapyshell%E7%88%AC%E5%8F%96%E4%B8%80%E4%BA%9B%E7%BD%91%E7%AB%99%E4%B8%8D%E5%93%8D%E5%BA%94/">阅读全文</a></p>
    </article>
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/scrapyshell%E7%9A%84%E4%BD%BF%E7%94%A8/" title="scrapyshell的使用">scrapyshell的使用</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            ……
        </div>
        <p class="readmore"><a href="https://zaina.newban.cn/posts/scrapyshell%E7%9A%84%E4%BD%BF%E7%94%A8/">阅读全文</a></p>
    </article>
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/scrapyshell%E7%9A%84%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/" title="ScrapyShell的使用教程">ScrapyShell的使用教程</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            Scrapy shell Scrapy shell是一个交互终端在未启动spider的情况下尝试及调试您的爬取代码。 其本意是用来测试提取数据的代码，不过您可以将其作为正常的Python终端，在上面测试任何的Python代码。
该终端是用来测试XPath或CSS表达式，查看他们的工作方式及从爬取的网页中提取的数据。 在编写您的spider时，该终端提供了交互性测试您的表达式代码的功能，免去了每次修改后运行spider的麻烦。（安装IPython，替代标准Python终端 pip install IPython）
启动终端 scrapy shell &lt;url&gt;  url是要爬取的网页地址
可用快捷命令 shelp()-打印可用对象以及快捷命令的帮助列表
fetch(request_or_url)-根据给定的请求（request）或URL获取一个新的response,并更新相关对象。
view(response)-在本机的浏览器打开给定的response。其中在response的body中添加一个 base(tag),使得外部链接（例如图片及css正常显示）
可用Scrapy对象 crawler- 当前crawler对象。
spider-处理URL的spider。对当前URL没有处理的Spider时则为一个Spider对象
request-最近获取到的页面的 Request 对象。 您可以使用 replace() 修改该request。或者 使用 fetch 快捷方式来获取新的request。
response - 包含最近获取到的页面的 Response 对象。
sel-根据最近获取到的response构建的 Selector 对象。
settings - 当前的 Scrapy settings……
        </div>
        <p class="readmore"><a href="https://zaina.newban.cn/posts/scrapyshell%E7%9A%84%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/">阅读全文</a></p>
    </article>
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/scrapyshell%E7%A2%B0%E5%88%B0503%E7%9A%84%E9%94%99%E8%AF%AF/" title="scrapyshell碰到503的错误">scrapyshell碰到503的错误</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            这几天刚刚学习scrapy的时候，有的时候想用scrapy.shell验证一下xpath的正确性，方便点，但经常遇到503的错误，所以总结一下：
打开cmd直接输入scrapy.shell，
就会报错503
所以我们需要这样做，进入项目的spiders文件夹

然后就ok了
但是在这之前，我们还需要设置一些东西，进入你要爬的网站，比如http://www.xicidaili.com/nn/ 然后F12打开开发者工具，在network里找到第一个
把 USER_AGENT 放到settings.py里去

这样就不会报503的错误了
当然。如果你只是想简单的scrapy shell一下，那么直接在scrapy shell -s USER_AGENT='Mozilla/5.0' +url 就OK了
转载请注明出处……
        </div>
        <p class="readmore"><a href="https://zaina.newban.cn/posts/scrapyshell%E7%A2%B0%E5%88%B0503%E7%9A%84%E9%94%99%E8%AF%AF/">阅读全文</a></p>
    </article>
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/scrapyshell%E8%AE%BF%E9%97%AEjandan%E8%A2%AB%E6%8B%92%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/" title="ScrapyShell访问jandan被拒解决方法">ScrapyShell访问jandan被拒解决方法</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            是用Scrapy Shell调试爬虫，测试jandan的是否发现，煎蛋网好像有简单的防爬功能。各种百度。总结一下
1.start_requests(self)添加user-agent字段
2.中间件方式。
但是上述方式都不能在shell中奏效，调试很不方便。
很简单;直接修改scrapy的user-agent默认值搞定。
settings/default-setting.py
246 #USER_AGENT = &lsquo;Scrapy/%s (+http://scrapy.org)' % import_module(&lsquo;scrapy&rsquo;).version
247 USER_AGENT = &lsquo;Mozilla/5.0 (Windows NT 5.1; rv:5.0) Gecko/20100101 Firefox/5.0&rsquo;
使用shell再次，发现已经可以正常访问html不会在出现403错误了。……
        </div>
        <p class="readmore"><a href="https://zaina.newban.cn/posts/scrapyshell%E8%AE%BF%E9%97%AEjandan%E8%A2%AB%E6%8B%92%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/">阅读全文</a></p>
    </article>
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/scrapyshell%E8%B0%83%E8%AF%95%E4%BB%A3%E7%A0%81/" title="ScrapyShell调试代码">ScrapyShell调试代码</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            Scrapy Shell
Scrapy终端是一个交互终端，我们可以在未启动spider的情况下尝试及调试代码，也可以用来测试XPath或CSS表达式，查看他们的工作方式，方便我们爬取的网页中提取的数据。
启动Scrapy Shell
进入cmd输入命令行：
scrapy shell &quot;http://quotes.toscrape.com/&quot;  
状态码200，表示请求成功。
在爬取一个网站的时候，最好是使用shell来查看下是否有反爬机制，如果返回的状态码不是200，多半是有反爬机制。如果在不知道的前提下强行爬取可能会导致爬虫中断需要登录后才可访问网站，严重的甚至是ip被封。
测试XPath
&gt;&gt;&gt; response.xpath('//div[@class=&quot;quote&quot;]//small/text()') [, , , , , , , , , ] &gt;&gt;&gt; response.xpath('//div[@class=&quot;quote&quot;]//small/text()').extract() ['Albert Einstein', 'J.K. Rowling', 'Albert Einstein', 'Jane Austen', 'Marilyn Monroe', 'Albert Einstein', 'André Gide', 'Thomas A. Edison', 'Eleanor Roosevelt', 'Steve Martin'] &gt;&gt;&gt; response.xpath('//div[@class=&quot;quote&quot;][1]//small/text()').extract() ['Albert Einstein'] &gt;&gt;&gt; response.xpath('//div[@class=&quot;quote&quot;][1]//small/text()').extract()[0] 'Albert Einstein'  以后做数据提取的时候，可以把现在Scrapy Shell中测试，测试通过后再应用到代码中。……
        </div>
        <p class="readmore"><a href="https://zaina.newban.cn/posts/scrapyshell%E8%B0%83%E8%AF%95%E4%BB%A3%E7%A0%81/">阅读全文</a></p>
    </article>
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/scrapyshell%E8%B0%83%E8%AF%95%E6%8A%A5%E9%94%99typeerrormoduleinittakesatmost2arguments3given/" title="scrapyshell调试报错TypeErrormoduleinittakesatmost2arguments3given">scrapyshell调试报错TypeErrormoduleinittakesatmost2arguments3given</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            1、使用scrapy shell的时候本人之前安装了ipython，使用shell调式格式从&gt;&gt;&gt;变成了【1】这种带有ipython的格式，结果整齐度看起来比较舒服。
2、现在创建了crawl spider，同时进入到项目目录，使用scrapy shell xxxxxxxx在cmd或者cmder中进行调式的报错TypeError: module.init() takes at most 2 arguments (3 g iven)，说明了应该是ipython直接运行了pycharm中项目的代码，在某一个项目中的一项显示出了类型错误，后来在cmd或者cmder的创始目录进行scrapy shell xxxxxxxx调式的时候，可以进入其中，可以调式response.css或者response.xpath。……
        </div>
        <p class="readmore"><a href="https://zaina.newban.cn/posts/scrapyshell%E8%B0%83%E8%AF%95%E6%8A%A5%E9%94%99typeerrormoduleinittakesatmost2arguments3given/">阅读全文</a></p>
    </article>
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/scrapyshell%E8%B0%83%E8%AF%95%E8%BF%94%E5%9B%9E403%E9%94%99%E8%AF%AF/" title="Scrapyshell调试返回403错误">Scrapyshell调试返回403错误</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            一、问题描述
有时候用scrapy shell来调试很方便,但是有些网站有防爬虫机制,所以使用scrapy shell会返回403,比如下面
C:\Users\fendo&gt;scrapy shell https://book.douban.com/subject/26805083/ 2017-04-17 15:18:53 [scrapy.utils.log] INFO: Scrapy 1.3.3 started (bot: scrapybot) 2017-04-17 15:18:53 [scrapy.utils.log] INFO: Overridden settings: {'DUPEFILTER_CLASS': 'scrapy.dupefilters.BaseDupeFilter', 'LOGSTATS_INTERVAL': 0} 2017-04-17 15:18:53 [scrapy.middleware] INFO: Enabled extensions: ['scrapy.extensions.corestats.CoreStats', 'scrapy.extensions.telnet.TelnetConsole'] 2017-04-17 15:18:54 [scrapy.middleware] INFO: Enabled downloader middlewares: ['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware', 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware', 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware', 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware', 'scrapy.downloadermiddlewares.retry.RetryMiddleware', 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware', 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware', 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware', 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware', 'scrapy.downloadermiddlewares.stats.DownloaderStats'] 2017-04-17 15:18:54 [scrapy.middleware] INFO: Enabled spider middlewares: ['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware', 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware', 'scrapy.spidermiddlewares.referer.RefererMiddleware', 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware', 'scrapy.spidermiddlewares.depth.DepthMiddleware'] 2017-04-17 15:18:54 [scrapy.middleware] INFO: Enabled item pipelines: [] 2017-04-17 15:18:54 [scrapy.……
        </div>
        <p class="readmore"><a href="https://zaina.newban.cn/posts/scrapyshell%E8%B0%83%E8%AF%95%E8%BF%94%E5%9B%9E403%E9%94%99%E8%AF%AF/">阅读全文</a></p>
    </article>
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/scrapy%E4%B8%ADshell%E5%87%BA%E7%8E%B0403%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/" title="scrapy中shell出现403解决方案">scrapy中shell出现403解决方案</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            我们使用scrapy shell来进行调试是很方便的，但是有时会出现403错误的问题，我们来解决这个问题： 出现403，表示网站拒绝提供服务
因为有的网站有反爬机制，当你使用scrapy shell的时候是以是scrapy爬虫的标识进行访问网站的，这时候网站会拒绝为爬虫提供服务，这时候就会返回403错误
下面列举三个方案来解决这个问题，三个方案的原理都是一样的，即修改user-agent的值，使用浏览器的标识来对网站进行访问，这样网站就不会拒绝服务了
方案一：只治标. 在使用scrapy shell的时候，在其后面加上-s USER_AGENT=&lsquo;Mozills/5.0’
eg: 我们要对百度进行scrapy shell的时候
scrapy shell http://www.baidu.com -s USER_AGENT='Mozills/5.0'  成功！！！
方案二：半治标半治本. 修改scrapy项目里的settings.py USER_AGENT
把settings.py里的USER_AGENT的属性启用并修改
修改前：
#USER_AGENT = 'yi (+http://www.yourdomain.com)'  修改后：
USER_AGENT = 'Mozilla/5.0 (Windows NT 5.1; rv:5.0) Gecko/20100101 Firefox/5.0'  再次使用scrapy shell：
（注意：这里的scrapy shell只能在项目里使用，直接在cmd中使用是不生效的，这也是为什么说半治标的原因）
scrapy shell https://movie.douban.com/top250  我们看一下返回的信息:
response &lt;200 https://movie.douban.com/top250&gt;  返回200， 成功！！！

方案三： 治本. 修改整个python的default_settings.py文件里的默认USER_AGENT值
 之后在不管是在项目中还是在cmd中使用scrapy shell，都是以浏览器的标识符来进行访问的了
 找一下default_settings.py文件的位置
我的default_settings.py文件在C:\ProgramData\Anaconda3\Lib\site- packages\scrapy\settings下
找到文件位置后，打开文件，修改 USER_AGENT的值……
        </div>
        <p class="readmore"><a href="https://zaina.newban.cn/posts/scrapy%E4%B8%ADshell%E5%87%BA%E7%8E%B0403%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/">阅读全文</a></p>
    </article>
    
    



<ol class="page-navigator">
    
    <li class="prev">
        <a href="https://zaina.newban.cn/page/769/">上一页</a>
    </li>
    

    

    
        
        
    
    

    
        
        
        <li >
            <a href="https://zaina.newban.cn/">1</a>
        </li>
        
    
        
        <li>
            <span>...</span>
        </li>
        
    
        
        
        <li >
            <a href="https://zaina.newban.cn/page/768/">768</a>
        </li>
        
    
        
        
        <li >
            <a href="https://zaina.newban.cn/page/769/">769</a>
        </li>
        
    
        
        
        <li  class="current">
            <a href="https://zaina.newban.cn/page/770/">770</a>
        </li>
        
    
        
        
        <li >
            <a href="https://zaina.newban.cn/page/771/">771</a>
        </li>
        
    
        
        
        <li >
            <a href="https://zaina.newban.cn/page/772/">772</a>
        </li>
        
    
        
        <li>
            <span>...</span>
        </li>
        
    
        
        
        <li >
            <a href="https://zaina.newban.cn/page/1960/">1960</a>
        </li>
        
    

    
    

    <li class="next">
        <a href="https://zaina.newban.cn/page/771/">下一页</a>
    </li>
    
</ol>




</div>

                    <footer id="footer">
    <div>
        &copy; 2020 <a href="https://zaina.newban.cn">开发者问答集锦 By </a>
        
    </div>
    <br />
    <div>
        <div class="github-badge">
            <a href="https://gohugo.io/" target="_black" rel="nofollow"><span class="badge-subject">Powered by</span><span class="badge-value bg-blue">Hugo</span></a>
        </div>
        <div class="github-badge">
            <a href="https://www.flysnow.org/" target="_black"><span class="badge-subject">Design by</span><span class="badge-value bg-brightgreen">飞雪无情</span></a>
        </div>
        <div class="github-badge">
            <a href="https://github.com/flysnow-org/maupassant-hugo" target="_black"><span class="badge-subject">Theme</span><span class="badge-value bg-yellowgreen">Maupassant</span></a>
        </div>
    </div>
</footer>



<a id="rocket" href="#top"></a>
<script type="text/javascript" src='/js/totop.js?v=0.0.0' async=""></script>



    <script type="text/javascript" src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script>




                </div>

                <div id="secondary">
    <section class="widget">
        <form id="search" action='https://zaina.newban.cn/search/' method="get" accept-charset="utf-8" target="_blank" _lpchecked="1">
      
      <input type="text" name="q" maxlength="20" placeholder="Search">
      <input type="hidden" name="sitesearch" value="https://zaina.newban.cn">
      <button type="submit" class="submit icon-search"></button>
</form>
    </section>
    
    <section class="widget">
        <h3 class="widget-title">最近文章</h3>
<ul class="widget-list">
    
    <li>
        <a href="https://zaina.newban.cn/posts/001rubyruby%E4%B8%AD%E5%85%A8%E5%B1%80%E5%8F%98%E9%87%8F%E5%AE%9E%E4%BE%8B%E5%8F%98%E9%87%8F%E5%B1%80%E9%83%A8%E5%8F%98%E9%87%8F%E7%B1%BB%E5%8F%98%E9%87%8Fsymbol%E5%AF%B9%E6%AF%94/" title="001rubyRuby中全局变量实例变量局部变量类变量Symbol对比">001rubyRuby中全局变量实例变量局部变量类变量Symbol对比</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/007hadoop%E9%9B%86%E7%BE%A4%E9%85%8D%E7%BD%AEhadoop%E9%9B%86%E7%BE%A4%E7%9A%84%E5%90%AF%E5%8A%A8%E5%92%8C%E6%B5%8B%E8%AF%95ssh%E5%85%8D%E7%99%BB%E9%99%86%E9%85%8D%E7%BD%AEstartallshhdfs%E5%B8%B8%E7%94%A8%E7%9A%84shell/" title="007Hadoop集群配置Hadoop集群的启动和测试SSH免登陆配置startallshhdfs常用的shell">007Hadoop集群配置Hadoop集群的启动和测试SSH免登陆配置startallshhdfs常用的shell</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/009shell%E8%84%9A%E6%9C%AC%E4%B8%8B%E6%9D%A1%E4%BB%B6%E6%B5%8B%E8%AF%95eqne/" title="009Shell脚本下条件测试eqne">009Shell脚本下条件测试eqne</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/00pythonmanagepyshell%E5%92%8Cpython%E7%9A%84%E5%88%86%E6%9E%90/" title="00Pythonmanagepyshell和Python的分析">00Pythonmanagepyshell和Python的分析</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/010zookeeper%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5zookeeper%E7%9A%84%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BAzookeeper%E7%9A%84shell%E5%91%BD%E4%BB%A4/" title="010Zookeeper的基本概念Zookeeper的集群搭建Zookeeper的shell命令">010Zookeeper的基本概念Zookeeper的集群搭建Zookeeper的shell命令</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/018dockerfileshell/" title="018DockerfileSHELL">018DockerfileSHELL</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/01shell%E5%85%A5%E9%97%A801bashshell%E7%89%B9%E6%80%A7/" title="01Shell入门01bashShell特性">01Shell入门01bashShell特性</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/01shell%E5%8F%98%E9%87%8F/" title="01Shell变量">01Shell变量</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/01shell%E5%9F%BA%E7%A1%80%E6%A6%82%E8%BF%B0%E8%84%9A%E6%9C%AC%E6%89%A7%E8%A1%8C%E6%96%B9%E5%BC%8Fbash%E5%9F%BA%E6%9C%AC%E5%8A%9F%E8%83%BD/" title="01Shell基础概述脚本执行方式Bash基本功能">01Shell基础概述脚本执行方式Bash基本功能</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/01shell%E7%BC%96%E7%A8%8Bhelloworld/" title="01shell编程helloworld">01shell编程helloworld</a>
    </li>
    
</ul>
    </section>

    

    <section class="widget">
        <h3 class="widget-title"><a href="/categories">分类</a></h3>
<ul class="widget-list">
    
</ul>
    </section>

    <section class="widget">
        <h3 class="widget-title"><a href="/tags">标签</a></h3>
<div class="tagcloud">
    
    <a href="https://zaina.newban.cn/tags/ruby/">ruby</a>
    
    <a href="https://zaina.newban.cn/tags/shell/">shell</a>
    
</div>
    </section>

    

    <section class="widget">
        <h3 class="widget-title">其它</h3>
        <ul class="widget-list">
            <li><a href="https://zaina.newban.cn/index.xml">文章 RSS</a></li>
        </ul>
    </section>
</div>
            </div>
        </div>
    </div>
</body>

</html>