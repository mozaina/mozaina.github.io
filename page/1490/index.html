<!doctype html>
<html lang="en-us">
<head>
	<meta name="generator" content="Hugo 0.59.1" />

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">


    <title>开发者问答集锦 | </title>
    <meta property="og:title" content="开发者问答集锦 | ">
    <meta property="og:type" content="website">
    <meta name="Keywords" content="">
    <meta name="description" content="">
    <meta property="og:url" content="https://zaina.newban.cn/">
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">

    <link rel="stylesheet" href='/css/normalize.css'>
    <link rel="stylesheet" href='/css/style.css'>
    <link rel="alternate" type="application/rss+xml+xml" href="https://zaina.newban.cn/index.xml" title="开发者问答集锦" />
    <script type="text/javascript" src="//cdn.bootcdn.net/ajax/libs/jquery/3.4.1/jquery.min.js"></script>

    
    
    
    
    
    
</head>


<body>
    <header id="header" class="clearfix">
    <div class="container">
        <div class="col-group">
            <div class="site-name ">
                
                    <h1>
                        <a id="logo" href="https://zaina.newban.cn">
                            开发者问答集锦
                        </a>
                    </h1>
                
                
            </div>
            <div>
                <nav id="nav-menu" class="clearfix">
                    <a class="current" href="https://zaina.newban.cn">首页</a>
                    
                </nav>
            </div>
        </div>
    </div>
</header>

    <div id="body">
        <div class="container">
            <div class="col-group">

                <div class="col-8" id="main">
                    
<div class="res-cons">
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/sparkshell%E5%90%AF%E5%8A%A8%E5%87%BA%E9%94%99%E9%97%AE%E9%A2%98/" title="sparkshell启动出错问题">sparkshell启动出错问题</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            错误描述：直接启动spark- shell，pia,出错了，之前一直是这样启动的啊，一点错也没有。心情不好的时候真的想一删了之，然后再下一个版本来用。可是想一想如果下载的也是这个样子，那我岂不是浪费时间，又做重复的事情，赔了夫人又折兵，虽然我没有夫人。。。。恩，还是静心看了看错误，忽然想起前段时间使用spark sql 从hive里面取数据来着，但是我的hive- site.xml和驱动包已经考到了对应的目录了，怎么还给我整这么一出，我估计是没有配置好路径的问题。然后我就直接在启动spark- shell的时候指定了spark-sql需要的驱动包，因为spark-shell启动的时候会启动spark-sql。错误日志和解决方法如下：
Caused by: org.datanucleus.store.rdbms.connectionpool.DatastoreDriverNotFoundException: The specified datastore driver (&ldquo;com.mysql.jdbc.Driver&rdquo;) was not found in the CLASSPATH. Please check your CLASSPATH specification, and the name of the driver.
at org.datanucleus.store.rdbms.connectionpool.AbstractConnectionPoolFactory.loadDriver(AbstractConnectionPoolFactory.java:58)
at org.datanucleus.store.rdbms.connectionpool.DBCPConnectionPoolFactory.createConnectionPool(DBCPConnectionPoolFactory.java:50)
at org.datanucleus.store.rdbms.ConnectionFactoryImpl.generateDataSources(ConnectionFactoryImpl.java:238)
&hellip; 127 more
解决方法：
[root@hadoop0 bin]# ./spark-shell &ndash;driver-class-path /usr/local/spark/lib/mysql-connector-java-5.1.18-bin.jar……
        </div>
        <p class="readmore"><a href="https://zaina.newban.cn/posts/sparkshell%E5%90%AF%E5%8A%A8%E5%87%BA%E9%94%99%E9%97%AE%E9%A2%98/">阅读全文</a></p>
    </article>
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/sparkshell%E5%90%AF%E5%8A%A8%E5%88%86%E6%9E%90/" title="sparkshell启动分析">sparkshell启动分析</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            spark-shell脚本源码 #!/usr/bin/env bash # # Licensed to the Apache Software Foundation (ASF) under one or more # contributor license agreements. See the NOTICE file distributed with # this work for additional information regarding copyright ownership. # The ASF licenses this file to You under the Apache License, Version 2.0 # (the &quot;License&quot;); you may not use this file except in compliance with # the License. You may obtain a copy of the License at # # http://www.……
        </div>
        <p class="readmore"><a href="https://zaina.newban.cn/posts/sparkshell%E5%90%AF%E5%8A%A8%E5%88%86%E6%9E%90/">阅读全文</a></p>
    </article>
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/sparkshell%E5%90%AF%E5%8A%A8%E5%91%BD%E4%BB%A4%E8%AF%A6%E7%BB%86%E8%A7%A3%E6%9E%901/" title="sparkshell启动命令详细解析1">sparkshell启动命令详细解析1</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            环境：
spark 2.3.3
scala 2.11.8
Java 1.8.0_141
执行spark-shell命令后，会启动spark-shell交互命令行窗口：

那么spark-shell命令的启动流程是怎样的呢？
下面让我们来一步一步分析
首先，查看${SPARK_HOME}/bin/spark-shell启动脚本

可以看到，spark-shell脚本使用启动参数调用main方法

spark-shell脚本中的main方法最终会调用命令：
&rdquo;${SPARK_HOME}&ldquo;/bin/spark-submit &ndash;class org.apache.spark.repl.Main &ndash;name &ldquo;Spark shell&rdquo; &ldquo;$@&rdquo;
那么此时会执行spark-submit脚本，会将
--class org.apache.spark.repl.Main &ndash;name &ldquo;Spark shell&rdquo;
参数和spark-shell启动参数
&rdquo;$@&rdquo;
一起传递给spark-submit脚本
查看${SPARK_HOME}/bin/spark-submit脚本：

最终会通过命令：
exec &ldquo;${SPARK_HOME}&ldquo;/bin/spark-class org.apache.spark.deploy.SparkSubmit &ldquo;$@&rdquo;
调用org.apache.spark.deploy.SparkSubmit类。（这里${SPARK_HOME}/bin/spark-class 脚本不再分析）
下面查看org.apache.spark.deploy.SparkSubmit类的main方法

首先解析传递的参数，然后根据appArgs.action 匹配相应的动作.
而appArgs.action的设置是在org.apache.spark.deploy.SparkSubmitArguments
var action: SparkSubmitAction = null
…
// Action should be SUBMIT unless otherwise specified
action = Option(action).getOrElse(SUBMIT)
可以看到，由于我们没有传递action参数，所以默认是SUBMIT，所以org.apache.spark.deploy.SparkSubmit的main方法会调用submit方法
case SparkSubmitAction.SUBMIT =&gt; submit(appArgs, uninitLog)
( 即Spark WebUI的堆栈信息—&gt; org.……
        </div>
        <p class="readmore"><a href="https://zaina.newban.cn/posts/sparkshell%E5%90%AF%E5%8A%A8%E5%91%BD%E4%BB%A4%E8%AF%A6%E7%BB%86%E8%A7%A3%E6%9E%901/">阅读全文</a></p>
    </article>
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/sparkshell%E5%90%AF%E5%8A%A8%E5%92%8C%E6%8F%90%E4%BA%A4%E4%BB%BB%E5%8A%A1/" title="sparkShell启动和提交任务">sparkShell启动和提交任务</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            ……
        </div>
        <p class="readmore"><a href="https://zaina.newban.cn/posts/sparkshell%E5%90%AF%E5%8A%A8%E5%92%8C%E6%8F%90%E4%BA%A4%E4%BB%BB%E5%8A%A1/">阅读全文</a></p>
    </article>
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/sparkshell%E5%90%AF%E5%8A%A8%E6%8A%A5%E9%94%99errornotfoundvaluespark%E4%BD%8E%E7%BA%A7%E5%B7%B2%E8%A7%A3%E5%86%B3/" title="sparkshell启动报错errornotfoundvaluespark低级已解决">sparkshell启动报错errornotfoundvaluespark低级已解决</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            查看报错原因： java.net.BindException: Cannot assign requested address: Service ‘sparkDriver’ failed after 16 retries (starting from 0)! Consider explicitly setting the appropriate port for the service ‘sparkDriver’ (for example spark.ui.port for SparkUI) to an available port or increasing spark.port.maxRetries.
我擦，一看肯定是找不到对应的主机，然后就去看看是不是hosts文件的映射出问题了，
果然是。
之前为了上网将ip改成dhcp（动态的），所以当前ip和hosts文件不一致。
改了hosts文件后。666，又可以进去了。……
        </div>
        <p class="readmore"><a href="https://zaina.newban.cn/posts/sparkshell%E5%90%AF%E5%8A%A8%E6%8A%A5%E9%94%99errornotfoundvaluespark%E4%BD%8E%E7%BA%A7%E5%B7%B2%E8%A7%A3%E5%86%B3/">阅读全文</a></p>
    </article>
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/sparkshell%E5%90%AF%E5%8A%A8%E6%8A%A5%E9%94%99sparkshellline445271%E5%B7%B2%E6%9D%80%E6%AD%BB/" title="sparkshell启动报错sparkshellline445271已杀死">sparkshell启动报错sparkshellline445271已杀死</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            最近接触Spark的，在已经配置好的集群master上启动spark- shell时，出现此错误。除此之外，命令行再无其他提示信息，上下滚动，就连ERROR提示都没发现，很是疑惑。
解决步骤如下：
1. 先是打开spark webui，查看Completed Applications，按照Submitted Time，找到最新的一条启动记录，打开：

查看application详细：（ 当然，以下截图，是启动成功的。启动失败的，State列为killed ）

找到Logs列，打开stderr，发现以下错误提示：
ERROR executor.CoarseGrainedExecutorBackend: RECEIVED SIGNAL 15: SIGTERM ver
2. 紧接着查找此错误，但是网上搜到的大多和spark无关，只在一篇文章下，看到，可能是内存问题，可通过加大excutor- memory值的方式解决。然后开始尝试，
把master和多个slave的memory改大。原以为这样就行了，但是此处出现了一点点意外。 由于机器配置了很多环境，可用内存不多，所以就暂且都改成了小数 *.5 的形式。
但是在启动的时候竟然发现slave启动不了，只是提示了failed launch&hellip;。提示虽然简单，但是已经很明显了。果断开始查看启动日志，在slave机器上找到对应日志，查看：

想到可能是设置的测试值为小数问题，接着回去找到配置文件，将内存值设置改成整数2，重启spark-shell，成功。

3. 查看spark webui，也显示正常

以上就是此次问题的处理步骤，当然中间还有些其他问题，像重启hadoop失败等等。与此问题无关就略过了。
先记下来，以备后续查看。。……
        </div>
        <p class="readmore"><a href="https://zaina.newban.cn/posts/sparkshell%E5%90%AF%E5%8A%A8%E6%8A%A5%E9%94%99sparkshellline445271%E5%B7%B2%E6%9D%80%E6%AD%BB/">阅读全文</a></p>
    </article>
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/sparkshell%E5%90%AF%E5%8A%A8%E6%8A%A5%E9%94%99yarnapplicationhasalreadyendeditmighthavebeenkilledorunabletolaunch/" title="sparkshell启动报错YarnapplicationhasalreadyendedItmighthavebeenkilledorunabletolaunch">sparkshell启动报错YarnapplicationhasalreadyendedItmighthavebeenkilledorunabletolaunch</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            前半部分转自：https://www.cnblogs.com/tibit/p/7337045.html （后半原创）
spark-shell不支持yarn cluster，以yarn client方式启动
spark-shell --master=yarn --deploy-mode=client  启动日志，错误信息如下

其中“Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME”，只是一个警告，官方的解释如下：
To make Spark runtime jars accessible from YARN side, you can specify spark.yarn.archive or spark.yarn.jars. For details please refer to Spark Properties. If neither spark.yarn.archive nor spark.yarn.jars is specified, Spark will create a zip file with all jars under$SPARK_HOME/jars and upload it to the distributed cache.……
        </div>
        <p class="readmore"><a href="https://zaina.newban.cn/posts/sparkshell%E5%90%AF%E5%8A%A8%E6%8A%A5%E9%94%99yarnapplicationhasalreadyendeditmighthavebeenkilledorunabletolaunch/">阅读全文</a></p>
    </article>
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/sparkshell%E5%90%AF%E5%8A%A8%E6%8A%A5%E9%94%99%E7%9A%84%E5%9D%91/" title="sparkShell启动报错的坑">sparkShell启动报错的坑</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            部署spark版本2.4.1（包为spark-2.4.1-bin-without-hadoop.tgz）时，启动spark-shell报错
错误信息是：Exception in thread &ldquo;main&rdquo; java.lang.NoSuchMethodError: jline.console.completer.CandidateListCompletionHandler.setPrintSpaceAfterFullCompletion(Z)V，查了一下午，发现可能是spark2.4.1的bug
详细看：
http://mail-archives.apache.org/mod_mbox/spark- issues/201810.mbox/%3CJIRA.13192953.1539979697000.165392.1540166400377@Atlassian.JIRA%3E
解决办法：换到spark2.3.3版本，启动正常……
        </div>
        <p class="readmore"><a href="https://zaina.newban.cn/posts/sparkshell%E5%90%AF%E5%8A%A8%E6%8A%A5%E9%94%99%E7%9A%84%E5%9D%91/">阅读全文</a></p>
    </article>
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/sparkshell%E5%90%AF%E5%8A%A8%E6%8A%A5%E9%94%99%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95/" title="sparkshell启动报错解决办法">sparkshell启动报错解决办法</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            spark-shell启动报错解决办法:
scala版本不兼容问题
这是因为加入了项目依赖库到/usr/cwgis/app/spark/jars/lib/中
删除相关的scala开头的jar文件即可启动spark-shell
[root@node111 ~]# runCmd.sh &quot;rm /usr/cwgis/app/spark/jars/lib/scala*.jar&quot; all  错误: 找不到或无法加载主类 org.apache.spark.deploy.yarn.ExecutorLauncher
SparkException: Yarn application has already ended! It might have been killed or unable to launch application master
spark1.0版本
[hadoop@localhost spark-1.0.1-bin-hadoop2]$ export SPARK_JAR=lib/spark-assembly-1.0.1-hadoop2.2.0.jar  spark other version
创建压缩jar文件方法:
生成一个spark-libs.jar文件，打包/spark/jars目录下所有jar文件和子目录jar文件
jar cv0f spark-libs.jar -C /usr/cwgis/app/spark/jars/ .  在spark-default.conf中设置 spark.yarn.archive=hdfs://mycluster:8020/spark/spark- libs.jar
或者 spark.yarn.jars=hdfs://mycluster:8020/spark/spark-libs.jar……
        </div>
        <p class="readmore"><a href="https://zaina.newban.cn/posts/sparkshell%E5%90%AF%E5%8A%A8%E6%8A%A5%E9%94%99%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95/">阅读全文</a></p>
    </article>
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/sparkshell%E5%90%AF%E5%8A%A8%E7%9A%84%E6%97%B6%E5%80%99%E6%8A%A5errorwhileinstantiatingorgapachesparksqlhivehivesessionstatebuilder%E9%94%99%E8%AF%AF/" title="Sparkshell启动的时候报ErrorwhileinstantiatingorgapachesparksqlhiveHiveSessionStateBuilder错误">Sparkshell启动的时候报ErrorwhileinstantiatingorgapachesparksqlhiveHiveSessionStateBuilder错误</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            版权声明：未经允许，随意转载，请附上本文链接谢谢（づ￣3￣）づ╭❤～
https://blog.csdn.net/xiaoduan_/article/details/79815692
Spark-shell启动的时候报java.lang.IllegalArgumentException: Error while instantiating ‘org.apache.spark.sql.hive.HiveSessionStateBuilder’和error: not found: value spark，error: not found: value spark错误
具体报错信息如下
o adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel). 18/04/04 12:14:18 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable 18/04/04 12:14:23 WARN conf.HiveConf: HiveConf of name hive.metastore.scheame.verification does not exist 18/04/04 12:14:26 WARN conf.HiveConf: HiveConf of name hive.metastore.scheame.verification does not exist java.lang.IllegalArgumentException: Error while instantiating 'org.……
        </div>
        <p class="readmore"><a href="https://zaina.newban.cn/posts/sparkshell%E5%90%AF%E5%8A%A8%E7%9A%84%E6%97%B6%E5%80%99%E6%8A%A5errorwhileinstantiatingorgapachesparksqlhivehivesessionstatebuilder%E9%94%99%E8%AF%AF/">阅读全文</a></p>
    </article>
    
    



<ol class="page-navigator">
    
    <li class="prev">
        <a href="https://zaina.newban.cn/page/1489/">上一页</a>
    </li>
    

    

    
        
        
    
    

    
        
        
        <li >
            <a href="https://zaina.newban.cn/">1</a>
        </li>
        
    
        
        <li>
            <span>...</span>
        </li>
        
    
        
        
        <li >
            <a href="https://zaina.newban.cn/page/1488/">1488</a>
        </li>
        
    
        
        
        <li >
            <a href="https://zaina.newban.cn/page/1489/">1489</a>
        </li>
        
    
        
        
        <li  class="current">
            <a href="https://zaina.newban.cn/page/1490/">1490</a>
        </li>
        
    
        
        
        <li >
            <a href="https://zaina.newban.cn/page/1491/">1491</a>
        </li>
        
    
        
        
        <li >
            <a href="https://zaina.newban.cn/page/1492/">1492</a>
        </li>
        
    
        
        <li>
            <span>...</span>
        </li>
        
    
        
        
        <li >
            <a href="https://zaina.newban.cn/page/1960/">1960</a>
        </li>
        
    

    
    

    <li class="next">
        <a href="https://zaina.newban.cn/page/1491/">下一页</a>
    </li>
    
</ol>




</div>

                    <footer id="footer">
    <div>
        &copy; 2020 <a href="https://zaina.newban.cn">开发者问答集锦 By </a>
        
    </div>
    <br />
    <div>
        <div class="github-badge">
            <a href="https://gohugo.io/" target="_black" rel="nofollow"><span class="badge-subject">Powered by</span><span class="badge-value bg-blue">Hugo</span></a>
        </div>
        <div class="github-badge">
            <a href="https://www.flysnow.org/" target="_black"><span class="badge-subject">Design by</span><span class="badge-value bg-brightgreen">飞雪无情</span></a>
        </div>
        <div class="github-badge">
            <a href="https://github.com/flysnow-org/maupassant-hugo" target="_black"><span class="badge-subject">Theme</span><span class="badge-value bg-yellowgreen">Maupassant</span></a>
        </div>
    </div>
</footer>



<a id="rocket" href="#top"></a>
<script type="text/javascript" src='/js/totop.js?v=0.0.0' async=""></script>



    <script type="text/javascript" src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script>




                </div>

                <div id="secondary">
    <section class="widget">
        <form id="search" action='https://zaina.newban.cn/search/' method="get" accept-charset="utf-8" target="_blank" _lpchecked="1">
      
      <input type="text" name="q" maxlength="20" placeholder="Search">
      <input type="hidden" name="sitesearch" value="https://zaina.newban.cn">
      <button type="submit" class="submit icon-search"></button>
</form>
    </section>
    
    <section class="widget">
        <h3 class="widget-title">最近文章</h3>
<ul class="widget-list">
    
    <li>
        <a href="https://zaina.newban.cn/posts/001rubyruby%E4%B8%AD%E5%85%A8%E5%B1%80%E5%8F%98%E9%87%8F%E5%AE%9E%E4%BE%8B%E5%8F%98%E9%87%8F%E5%B1%80%E9%83%A8%E5%8F%98%E9%87%8F%E7%B1%BB%E5%8F%98%E9%87%8Fsymbol%E5%AF%B9%E6%AF%94/" title="001rubyRuby中全局变量实例变量局部变量类变量Symbol对比">001rubyRuby中全局变量实例变量局部变量类变量Symbol对比</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/007hadoop%E9%9B%86%E7%BE%A4%E9%85%8D%E7%BD%AEhadoop%E9%9B%86%E7%BE%A4%E7%9A%84%E5%90%AF%E5%8A%A8%E5%92%8C%E6%B5%8B%E8%AF%95ssh%E5%85%8D%E7%99%BB%E9%99%86%E9%85%8D%E7%BD%AEstartallshhdfs%E5%B8%B8%E7%94%A8%E7%9A%84shell/" title="007Hadoop集群配置Hadoop集群的启动和测试SSH免登陆配置startallshhdfs常用的shell">007Hadoop集群配置Hadoop集群的启动和测试SSH免登陆配置startallshhdfs常用的shell</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/009shell%E8%84%9A%E6%9C%AC%E4%B8%8B%E6%9D%A1%E4%BB%B6%E6%B5%8B%E8%AF%95eqne/" title="009Shell脚本下条件测试eqne">009Shell脚本下条件测试eqne</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/00pythonmanagepyshell%E5%92%8Cpython%E7%9A%84%E5%88%86%E6%9E%90/" title="00Pythonmanagepyshell和Python的分析">00Pythonmanagepyshell和Python的分析</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/010zookeeper%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5zookeeper%E7%9A%84%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BAzookeeper%E7%9A%84shell%E5%91%BD%E4%BB%A4/" title="010Zookeeper的基本概念Zookeeper的集群搭建Zookeeper的shell命令">010Zookeeper的基本概念Zookeeper的集群搭建Zookeeper的shell命令</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/018dockerfileshell/" title="018DockerfileSHELL">018DockerfileSHELL</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/01shell%E5%85%A5%E9%97%A801bashshell%E7%89%B9%E6%80%A7/" title="01Shell入门01bashShell特性">01Shell入门01bashShell特性</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/01shell%E5%8F%98%E9%87%8F/" title="01Shell变量">01Shell变量</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/01shell%E5%9F%BA%E7%A1%80%E6%A6%82%E8%BF%B0%E8%84%9A%E6%9C%AC%E6%89%A7%E8%A1%8C%E6%96%B9%E5%BC%8Fbash%E5%9F%BA%E6%9C%AC%E5%8A%9F%E8%83%BD/" title="01Shell基础概述脚本执行方式Bash基本功能">01Shell基础概述脚本执行方式Bash基本功能</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/01shell%E7%BC%96%E7%A8%8Bhelloworld/" title="01shell编程helloworld">01shell编程helloworld</a>
    </li>
    
</ul>
    </section>

    

    <section class="widget">
        <h3 class="widget-title"><a href="/categories">分类</a></h3>
<ul class="widget-list">
    
</ul>
    </section>

    <section class="widget">
        <h3 class="widget-title"><a href="/tags">标签</a></h3>
<div class="tagcloud">
    
    <a href="https://zaina.newban.cn/tags/ruby/">ruby</a>
    
    <a href="https://zaina.newban.cn/tags/shell/">shell</a>
    
</div>
    </section>

    

    <section class="widget">
        <h3 class="widget-title">其它</h3>
        <ul class="widget-list">
            <li><a href="https://zaina.newban.cn/index.xml">文章 RSS</a></li>
        </ul>
    </section>
</div>
            </div>
        </div>
    </div>
</body>

</html>