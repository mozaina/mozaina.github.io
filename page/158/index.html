<!doctype html>
<html lang="en-us">
<head>
	<meta name="generator" content="Hugo 0.59.1" />

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">


    <title>开发者问答集锦 | </title>
    <meta property="og:title" content="开发者问答集锦 | ">
    <meta property="og:type" content="website">
    <meta name="Keywords" content="">
    <meta name="description" content="">
    <meta property="og:url" content="https://zaina.newban.cn/">
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">

    <link rel="stylesheet" href='/css/normalize.css'>
    <link rel="stylesheet" href='/css/style.css'>
    <link rel="alternate" type="application/rss+xml+xml" href="https://zaina.newban.cn/index.xml" title="开发者问答集锦" />
    <script type="text/javascript" src="//cdn.bootcdn.net/ajax/libs/jquery/3.4.1/jquery.min.js"></script>

    
    
    
    
    
    
</head>


<body>
    <header id="header" class="clearfix">
    <div class="container">
        <div class="col-group">
            <div class="site-name ">
                
                    <h1>
                        <a id="logo" href="https://zaina.newban.cn">
                            开发者问答集锦
                        </a>
                    </h1>
                
                
            </div>
            <div>
                <nav id="nav-menu" class="clearfix">
                    <a class="current" href="https://zaina.newban.cn">首页</a>
                    
                </nav>
            </div>
        </div>
    </div>
</header>

    <div id="body">
        <div class="container">
            <div class="col-group">

                <div class="col-8" id="main">
                    
<div class="res-cons">
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/hadoopshell%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3/" title="HADOOPSHELL官方文档">HADOOPSHELL官方文档</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            ……
        </div>
        <p class="readmore"><a href="https://zaina.newban.cn/posts/hadoopshell%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3/">阅读全文</a></p>
    </article>
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/hadoopshell%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/" title="hadoopshell常用命令">hadoopshell常用命令</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            ……
        </div>
        <p class="readmore"><a href="https://zaina.newban.cn/posts/hadoopshell%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/">阅读全文</a></p>
    </article>
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/hadoopshell%E6%89%A7%E8%A1%8C%E7%A4%BA%E4%BE%8Bwordcountjar%E5%8C%85/" title="hadoopshell执行示例wordcountjar包">hadoopshell执行示例wordcountjar包</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            创建用户目录
bin/hdfs dfs -mkdir -p /user/hadoop
创建input目录
bin/hdfs dfs -mkdir input
导入数据
bin/hdfs dfs -put etc/hadoop/*.xml input
Hadoop运行程序时，默认输出目录不能存在，删除output文件夹
bin/hdfs dfs -rm -r /user/hadoop/output
执行jar包
bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-*.jar grep input output &lsquo;dfs[a-z.]+&rsquo;
(1)bin/hadoop：${HADOOP_HOME}/bin下的shell脚本名。
(2) jar：hadoop脚本需要的command参数。
(3) share/hadoop/mapreduce/hadoop-mapreduce- examples-*.jar：要执行的jar包在本地文件系统中的完整路径，参递给RunJar类。
(4) grep：main方法所在的类，参递给RunJar类。
(5) input：传递给WordCount类，作为DFS文件系统的路径，指示输入数据来源。
(6)output ：传递给WordCount类，作为DFS文件系统的路径，指示输出数据路径。
查看hdfs中的输出结果
bin/hdfs dfs -cat output/*
将输出结果导到本地
rm -R ./output
bin/hdfs dfs -get output output # 将 HDFS 上的 output 文件夹拷贝到本机
cat ./output/*
在程序中输出前删除输出目录代码
onfiguration conf = new Configuration();……
        </div>
        <p class="readmore"><a href="https://zaina.newban.cn/posts/hadoopshell%E6%89%A7%E8%A1%8C%E7%A4%BA%E4%BE%8Bwordcountjar%E5%8C%85/">阅读全文</a></p>
    </article>
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/hadoop%E4%B8%89hdfs%E8%AF%BB%E5%86%99%E5%8E%9F%E7%90%86%E4%B8%8Eshell%E5%91%BD%E4%BB%A4/" title="Hadoop三HDFS读写原理与shell命令">Hadoop三HDFS读写原理与shell命令</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            一 HDFS概述 1.1 HDFS产生背景 随着数据量越来越大，在一个操作系统管辖的范围内存不下了，那么就分配到更多的操作系统管理的磁盘中，但是不方便管理和维护，迫切需要一种系统来管理多台机器上的文件，这就是分布式文件管理系统。HDFS只是分布式文件管理系统中的一种。
1.2 HDFS概念 HDFS，它是一个文件系统，用于存储文件，通过目录树来定位文件；其次，它是分布式的，由很多服务器联合起来实现其功能，集群中的服务器有各自的角色。
HDFS的设计适合一次写入，多次读出的场景，且不支持文件的修改。适合用来做数据分析，并不适合用来做网盘应用。
1.3 HDFS优缺点 1.3.1 优点
1）高容错性
（1）数据自动保存多个副本。它通过增加副本的形式，提高容错性。
（2）某一个副本丢失以后，它可以自动恢复。
2）适合大数据处理
（1）数据规模：能够处理数据规模达到 GB、TB、甚至PB级别的数据。
（2）文件规模：能够处理百万规模以上的文件数量，数量相当之大。
3）流式数据访问
（1）一次写入，多次读取，不能修改，只能追加。
（2）它能保证数据的一致性。
4）可构建在廉价机器上，通过多副本机制，提高可靠性。
1.3.2 缺点
1）不适合低延时数据访问，比如毫秒级的存储数据，是做不到的。
2）无法高效的对大量小文件进行存储
（1）存储大量小文件的话，它会占用 NameNode大量的内存来存储文件、目录和块信息。这样是不可取的，因为NameNode的内存总是有限的。
（2）小文件存储的寻道时间会超过读取时间，它违反了HDFS的设计目标。
3）并发写入、文件随机修改
（1）一个文件只能有一个写，不允许多个线程同时写。
（2）仅支持数据 append（追加），不支持文件的随机修改。
抛出问题：HDFS文件系统为什么不适用于存储小文件？ 这是和HDFS系统底层设计实现有关系的，HDFS本身的设计就是用来解决海量大文件数据的存储.，他天生喜欢大数据的处理，大文件存储在HDFS中，会被切分成很多的小数据块，任何一个文件不管有多小，都是一个独立的数据块，而这些数据块的信息则是保存在元数据中的，在之前的博客HDFS基础里面介绍过在HDFS集群的namenode中会存储元数据的信息，这里再说一下，元数据的信息主要包括以下3部分：
1）抽象目录树
2）文件和数据块的映射关系，一个数据块的元数据大小大约是150byte
3）数据块的多个副本存储地
而元数据的存储在磁盘（1和2）和内存中（1、2和3），而服务器中的内存是有上限的，举个例子：
有100个1M的文件存储进入HDFS系统，那么数据块的个数就是100个，元数据的大小就是100*150byte，消耗了15000byte的内存，但是只存储了100M的数据。
有1个100M的文件存储进入HDFS系统，那么数据块的个数就是1个，元数据的大小就是150byte，消耗量150byte的内存，存储量100M的数据。
所以说HDFS文件系统不适用于存储小文件。
1.4 HDFS架构 ### 
###
1）Client：就是客户端。
（1）文件切分。文件上传 HDFS 的时候，Client 将文件切分成一个一个的Block，然后进行存储。
（2）与NameNode交互，获取文件的位置信息。
（3）与DataNode交互，读取或者写入数据。
（4）Client提供一些命令来管理HDFS，比如启动或者关闭HDFS。
（5）Client可以通过一些命令来访问HDFS。
2）NameNode：就是master，它是一个主管、管理者。
（1）管理HDFS的名称空间。
（2）管理数据块（Block）映射信息
（3）配置副本策略
（4）处理客户端读写请求。
3） DataNode：就是Slave。NameNode下达命令，DataNode执行实际的操作。
（1）存储实际的数据块。
（2）执行数据块的读/写操作。
4） Secondary NameNode：并非NameNode的热备。当NameNode挂掉的时候，它并不能马上替换NameNode并提供服务。……
        </div>
        <p class="readmore"><a href="https://zaina.newban.cn/posts/hadoop%E4%B8%89hdfs%E8%AF%BB%E5%86%99%E5%8E%9F%E7%90%86%E4%B8%8Eshell%E5%91%BD%E4%BB%A4/">阅读全文</a></p>
    </article>
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/hadoop%E4%B9%8Bhdfs%E7%9A%84shell%E8%84%9A%E6%9C%AC%E5%91%BD%E4%BB%A4%E6%80%BB%E7%BB%93/" title="Hadoop之HDFS的Shell脚本命令总结">Hadoop之HDFS的Shell脚本命令总结</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            一、HDFS的Shell的基本概念
1.调用文件系统(FS)Shell命令应使用 bin/hadoop fs 命令或 bin/hdfs dfs 命令的形式。[为了简便，一般将bin目录添加到path中]
2.所有的FS shell命令使用URI路径作为参数。
URI格式是scheme://authority/path。HDFS的scheme是hdfs，对本地文件系统，scheme是file。其中scheme和authority参数都是可选的，如果未加指定，就会使用配置中指定的默认scheme。例如：hdfs://namenode:namenodePort/parent/child，可以表示成/parent/child（假设配置文件是namenode:namenodePort）
3.大多数FS Shell命令的行为和对应的LINUX Shell命令类似。
二、HDFS的Shell命令
-help [cmd] //显示命令的帮助信息
-ls&reg; //显示当前目录下所有文件
-du(s) //显示目录中所有文件大小
-count[-q] //显示目录中文件数量
-mv //移动多个文件到目标目录
-cp //复制多个文件到目标目录
-rm&reg; //删除文件(夹)
-put //本地文件复制到hdfs
-copyFromLocal //同put
-moveFromLocal //从本地文件移动到hdfs
-get [-ignoreCrc] //复制文件到本地，可以忽略crc校验
-getmerge //将源目录中的所有文件排序合并到一个文件中
-cat //在终端显示文件内容
-text //在终端显示文件内容
-copyToLocal [-ignoreCrc] //复制到本地
-moveToLocal
-mkdir //创建文件夹
-touchz //创建一个空文件
三、HDFS的Shell命令(练习)
#hadoop fs -ls / 查看HDFS根目录
#hadoop fs -mkdir /test 在根目录创建一个目录test
#hadoop fs -put ./test.txt /test 或 #hadoop fs -copyFromLocal /test.……
        </div>
        <p class="readmore"><a href="https://zaina.newban.cn/posts/hadoop%E4%B9%8Bhdfs%E7%9A%84shell%E8%84%9A%E6%9C%AC%E5%91%BD%E4%BB%A4%E6%80%BB%E7%BB%93/">阅读全文</a></p>
    </article>
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/hadoop%E4%B9%8Bmapreduce%E8%B0%83%E5%BA%A6%E9%80%9A%E8%BF%87shell%E8%BF%9B%E8%A1%8C%E5%A4%9A%E6%97%A5%E6%9C%9F%E7%9A%84%E4%B8%B2%E8%A1%8C%E8%B7%91%E6%89%B9%E7%BB%9F%E8%AE%A1/" title="Hadoop之MapReduce调度通过shell进行多日期的串行跑批统计">Hadoop之MapReduce调度通过shell进行多日期的串行跑批统计</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            **1、统计对应链接访问量的Python脚本
** 由于业务上暂用不到reduce过程，所以只有一个mapper脚本。
**/Users/nisj/PycharmProjects/BiDataProc/hitsCalc3/filter_mapperOnly.py
**
#!/usr/bin/env python # encoding: utf-8 import sys # 输入为标准输入stdin for line in sys.stdin: if '/room/m-1015.htm' in line: print '%s' % (line)  **2、按天调度的shell脚本
** **/Users/nisj/PycharmProjects/BiDataProc/hitsCalc3/mpBatResultGet.sh
**
#!/usr/bin/env bash rm -rf result.txt for dataDate in 2017-08-21 2017-08-22 2017-08-23 2017-08-24 2017-08-25 2017-08-26 2017-08-27 2017-08-28; do echo $dataDate hadoop dfs -rm -r -skipTrash /nisj/mp_result; hadoop jar /opt/apps/hadoop-2.7.2/share/hadoop/tools/lib/hadoop-streaming-2.7.2.jar \ -mapper /home/hadoop/nisj/hitsCalc3/filter_mapperOnly.py -file /home/hadoop/nisj/hitsCalc3/filter_mapperOnly.py \ -input /tmp/oss_access/$dataDate/*_localhost_access_log.$dataDate.*.txt \ -output /nisj/mp_result #hadoop dfs -cat /nisj/mp_result/* hitsNum=`hadoop dfs -cat /nisj/mp_result/* |grep -v &quot;^$&quot;|wc -l` echo $dataDate '---&gt;' $hitsNum &gt;&gt; result.……
        </div>
        <p class="readmore"><a href="https://zaina.newban.cn/posts/hadoop%E4%B9%8Bmapreduce%E8%B0%83%E5%BA%A6%E9%80%9A%E8%BF%87shell%E8%BF%9B%E8%A1%8C%E5%A4%9A%E6%97%A5%E6%9C%9F%E7%9A%84%E4%B8%B2%E8%A1%8C%E8%B7%91%E6%89%B9%E7%BB%9F%E8%AE%A1/">阅读全文</a></p>
    </article>
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/hadoop%E4%BA%8Chdfs%E6%A6%82%E8%BF%B0shell%E6%93%8D%E4%BD%9C%E5%AE%A2%E6%88%B7%E7%AB%AF%E6%93%8D%E4%BD%9C%E5%90%84%E7%A7%8Dapi%E6%93%8D%E4%BD%9C%E4%BB%A5%E5%8F%8Ahdfs%E8%AF%BB%E5%86%99%E6%B5%81%E7%A8%8B/" title="hadoop二HDFS概述shell操作客户端操作各种API操作以及hdfs读写流程">hadoop二HDFS概述shell操作客户端操作各种API操作以及hdfs读写流程</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            hadoop系列笔记
hadoop（一）入门、hadoop架构、集群环境搭建.
hadoop（二）HDFS概述、shell操作、客户端操作（各种API操作）以及hdfs读写流程.
hadoop（三）hdfs的NameNode和DataNode工作机制.
hadoop（四）MapReduce入门及序列化实操.
hadoop（五）MapReduce框架原理及工作机制.
hadoop（六）hadoop数据压缩、yarn架构及工作原理、hadoop企业优化.
 文章目录  第一章HDFS概述  1.1 HDFS产生背景 1.2 HDFS概念 1.3 HDFS优缺点  1.3.1 优点 1.3.2 缺点  1.4 HDFS组成架构 1.5 HDFS文件块大小（面试重点）  第2章 HDFS的Shell操作（开发重点）  2.1 基本语法 2.2 hadoop fs常用命令  第3章 HDFS客户端操作（开发重点）  3.1 HDFS客户端环境准备 3.2 HDFS的API操作  第四章HDFS的数据流（面试重点）  4.1HDFS 写数据流程 4.2 HDFS读数据流程   第一章HDFS概述 1.1 HDFS产生背景  随着数据量越来越大，在一个操作系统管辖的范围内存不下了，那么就分配到更多的操作系统管理的磁盘中，但是不方便管理和维护，迫切需要一种系统来管理多台机器上的文件，这就是分布式文件管理系统。HDFS只是分布式文件管理系统中的一种。  1.2 HDFS概念  HDFS（Hadoop Distributed File System）， 它是一个文件系统 ，用于存储文件，通过目录树来定位文件； 其次，它是分布式的 ，由很多服务器联合起来实现其功能，集群中的服务器有各自的角色。 HDFS 使用场景：HDFS的设计适合一次写入，多次读出的场景，且不支持文件的修改。适合用来做数据分析，并不适合用来做网盘应用。  1.……
        </div>
        <p class="readmore"><a href="https://zaina.newban.cn/posts/hadoop%E4%BA%8Chdfs%E6%A6%82%E8%BF%B0shell%E6%93%8D%E4%BD%9C%E5%AE%A2%E6%88%B7%E7%AB%AF%E6%93%8D%E4%BD%9C%E5%90%84%E7%A7%8Dapi%E6%93%8D%E4%BD%9C%E4%BB%A5%E5%8F%8Ahdfs%E8%AF%BB%E5%86%99%E6%B5%81%E7%A8%8B/">阅读全文</a></p>
    </article>
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/hadoop%E4%BA%8C%E4%B8%ADhdfs%E7%9A%84shell%E6%93%8D%E4%BD%9C/" title="Hadoop二中HDFS的shell操作">Hadoop二中HDFS的shell操作</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            对hdfs的操作方式：hadoop fs xxx
1.查询操作
hadoop fs -ls / (默认本机查询)
hadoop fs - ls hdfs://hadoop:9000/ （分布式环境下查询）
hadoop fs -lsr / 递归查询
如下图（图中红框中1表示文件的副本数，目录没有）：


2.创建文件夹操作：
hadoop fs -mkdir /hadooptest

3.上传文件操作：
hadoop fs -put /root/install.log /hadooptest 从linux传到 hdfs服务器

4.下载文件操作：
hadoop fs -get /hadooptest/install.log / (从hdfs下载到linux，用ls查询即可)

5.查看文件内容：
hadoop fs -text /hadooptest/install.log 查看文件内容

6.删除文件操作：
hadoop fs -rm /hadooptest/install.log (只能删除 文件 )
hadoop fs -rmr /hadooptest (删除 目录 )

7.hadoop查询指令集……
        </div>
        <p class="readmore"><a href="https://zaina.newban.cn/posts/hadoop%E4%BA%8C%E4%B8%ADhdfs%E7%9A%84shell%E6%93%8D%E4%BD%9C/">阅读全文</a></p>
    </article>
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/hadoop%E5%85%A5%E9%97%A83shell%E5%92%8Cjava%E7%9A%84%E7%AE%80%E5%8D%95%E6%BC%94%E7%A4%BA%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%E5%9F%BA%E7%A1%80%E4%BA%91%E7%9B%98%E5%8A%9F%E8%83%BD/" title="Hadoop入门3Shell和JAVA的简单演示代码实现基础云盘功能">Hadoop入门3Shell和JAVA的简单演示代码实现基础云盘功能</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            目录
一、Shell的使用
二、JAVA api的使用
（一）配置xml文件
（二）简单代码demo（创建、查看、上传、下载）
三、Python的使用
四、参考与推荐
一、Shell的使用  平时的linux指令是针对本地电脑进行的，而HDFS是分布式的，它针对的是通过网络连接的计算机集群，因此在指令上有所区别。 在大部分普通linux指令前加上“hdfs dfs -”即可。 例如我们想要创建一个文件夹，平时都是用“mkdir /test1”指令在本地虚拟机上创建&rdquo;test1&rdquo;目录，但是如果想要在HDFS中创建一个“test1”目录，就需要在普通linux指令前加上“hdfs dfs -”，如下。
hdfs dfs -mkdir /test1
   在web网页上可以看到我们的确已经创建好了目录test1。  
二、JAVA api的使用  由上面的例子可以看到，我们可以通过shell操纵我们的HDFS，通过shell创建了一个目录，那如何用java api进行同样的操作呢？  （一）配置xml文件 1、创建项目
 在本机电脑上用ecplise创建JAVA项目，不赘述。  2、导包
 找到hadoop的路径，进入“..hadoop-2.7.0\share\hadoop\common”路径，看到有三个Jar包，将它导入到JAVA项目中。 同样的，再将“..hadoop-2.7.0\share\hadoop\common\lib”下的所有jar包导入。 再将“..hadoop-2.7.0\share\hadoop\hdfs”下的3个jar包导入。 再将“..hadoop-2.7.0\share\hadoop\hdfs\lib”下的所有jar包导入。  
3、导入虚拟机的配置文件
 利用xftp进入到虚拟机的“&hellip;/hadoop-2.7.0/etc/hadoop”目录下，找到两个文件“hdfs-site.xml”和&rdquo;core-site.xml&rdquo;，导出并放到项目的/src根目录下。  
 要修改“core-site.xml”里面的“localhost”为虚拟机的IP地址，不然本机无法找到虚拟机，它不知道这个“localhost”是谁。（其实也可以在本机上配置host的，使得别名和IP对应，继续使用别名）  
 修改  
 同样的也要修改&rdquo;hdfs-site.xml&rdquo;中的虚拟机名为IP地址。  
 运行如下代码，创建目录：
package com.bigdata.yunpan; import java.……
        </div>
        <p class="readmore"><a href="https://zaina.newban.cn/posts/hadoop%E5%85%A5%E9%97%A83shell%E5%92%8Cjava%E7%9A%84%E7%AE%80%E5%8D%95%E6%BC%94%E7%A4%BA%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%E5%9F%BA%E7%A1%80%E4%BA%91%E7%9B%98%E5%8A%9F%E8%83%BD/">阅读全文</a></p>
    </article>
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://zaina.newban.cn/posts/hadoop%E5%85%A5%E9%97%A8hadoop%E4%BD%BF%E7%94%A8shell%E5%91%BD%E4%BB%A4%E6%80%BB%E7%BB%93/" title="hadoop入门hadoop使用shell命令总结">hadoop入门hadoop使用shell命令总结</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2020年9月2日
        </date>
        
        <div class="post-content">
            ……
        </div>
        <p class="readmore"><a href="https://zaina.newban.cn/posts/hadoop%E5%85%A5%E9%97%A8hadoop%E4%BD%BF%E7%94%A8shell%E5%91%BD%E4%BB%A4%E6%80%BB%E7%BB%93/">阅读全文</a></p>
    </article>
    
    



<ol class="page-navigator">
    
    <li class="prev">
        <a href="https://zaina.newban.cn/page/157/">上一页</a>
    </li>
    

    

    
        
        
    
    

    
        
        
        <li >
            <a href="https://zaina.newban.cn/">1</a>
        </li>
        
    
        
        <li>
            <span>...</span>
        </li>
        
    
        
        
        <li >
            <a href="https://zaina.newban.cn/page/156/">156</a>
        </li>
        
    
        
        
        <li >
            <a href="https://zaina.newban.cn/page/157/">157</a>
        </li>
        
    
        
        
        <li  class="current">
            <a href="https://zaina.newban.cn/page/158/">158</a>
        </li>
        
    
        
        
        <li >
            <a href="https://zaina.newban.cn/page/159/">159</a>
        </li>
        
    
        
        
        <li >
            <a href="https://zaina.newban.cn/page/160/">160</a>
        </li>
        
    
        
        <li>
            <span>...</span>
        </li>
        
    
        
        
        <li >
            <a href="https://zaina.newban.cn/page/1960/">1960</a>
        </li>
        
    

    
    

    <li class="next">
        <a href="https://zaina.newban.cn/page/159/">下一页</a>
    </li>
    
</ol>




</div>

                    <footer id="footer">
    <div>
        &copy; 2020 <a href="https://zaina.newban.cn">开发者问答集锦 By </a>
        
    </div>
    <br />
    <div>
        <div class="github-badge">
            <a href="https://gohugo.io/" target="_black" rel="nofollow"><span class="badge-subject">Powered by</span><span class="badge-value bg-blue">Hugo</span></a>
        </div>
        <div class="github-badge">
            <a href="https://www.flysnow.org/" target="_black"><span class="badge-subject">Design by</span><span class="badge-value bg-brightgreen">飞雪无情</span></a>
        </div>
        <div class="github-badge">
            <a href="https://github.com/flysnow-org/maupassant-hugo" target="_black"><span class="badge-subject">Theme</span><span class="badge-value bg-yellowgreen">Maupassant</span></a>
        </div>
    </div>
</footer>



<a id="rocket" href="#top"></a>
<script type="text/javascript" src='/js/totop.js?v=0.0.0' async=""></script>



    <script type="text/javascript" src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script>




                </div>

                <div id="secondary">
    <section class="widget">
        <form id="search" action='https://zaina.newban.cn/search/' method="get" accept-charset="utf-8" target="_blank" _lpchecked="1">
      
      <input type="text" name="q" maxlength="20" placeholder="Search">
      <input type="hidden" name="sitesearch" value="https://zaina.newban.cn">
      <button type="submit" class="submit icon-search"></button>
</form>
    </section>
    
    <section class="widget">
        <h3 class="widget-title">最近文章</h3>
<ul class="widget-list">
    
    <li>
        <a href="https://zaina.newban.cn/posts/001rubyruby%E4%B8%AD%E5%85%A8%E5%B1%80%E5%8F%98%E9%87%8F%E5%AE%9E%E4%BE%8B%E5%8F%98%E9%87%8F%E5%B1%80%E9%83%A8%E5%8F%98%E9%87%8F%E7%B1%BB%E5%8F%98%E9%87%8Fsymbol%E5%AF%B9%E6%AF%94/" title="001rubyRuby中全局变量实例变量局部变量类变量Symbol对比">001rubyRuby中全局变量实例变量局部变量类变量Symbol对比</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/007hadoop%E9%9B%86%E7%BE%A4%E9%85%8D%E7%BD%AEhadoop%E9%9B%86%E7%BE%A4%E7%9A%84%E5%90%AF%E5%8A%A8%E5%92%8C%E6%B5%8B%E8%AF%95ssh%E5%85%8D%E7%99%BB%E9%99%86%E9%85%8D%E7%BD%AEstartallshhdfs%E5%B8%B8%E7%94%A8%E7%9A%84shell/" title="007Hadoop集群配置Hadoop集群的启动和测试SSH免登陆配置startallshhdfs常用的shell">007Hadoop集群配置Hadoop集群的启动和测试SSH免登陆配置startallshhdfs常用的shell</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/009shell%E8%84%9A%E6%9C%AC%E4%B8%8B%E6%9D%A1%E4%BB%B6%E6%B5%8B%E8%AF%95eqne/" title="009Shell脚本下条件测试eqne">009Shell脚本下条件测试eqne</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/00pythonmanagepyshell%E5%92%8Cpython%E7%9A%84%E5%88%86%E6%9E%90/" title="00Pythonmanagepyshell和Python的分析">00Pythonmanagepyshell和Python的分析</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/010zookeeper%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5zookeeper%E7%9A%84%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BAzookeeper%E7%9A%84shell%E5%91%BD%E4%BB%A4/" title="010Zookeeper的基本概念Zookeeper的集群搭建Zookeeper的shell命令">010Zookeeper的基本概念Zookeeper的集群搭建Zookeeper的shell命令</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/018dockerfileshell/" title="018DockerfileSHELL">018DockerfileSHELL</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/01shell%E5%85%A5%E9%97%A801bashshell%E7%89%B9%E6%80%A7/" title="01Shell入门01bashShell特性">01Shell入门01bashShell特性</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/01shell%E5%8F%98%E9%87%8F/" title="01Shell变量">01Shell变量</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/01shell%E5%9F%BA%E7%A1%80%E6%A6%82%E8%BF%B0%E8%84%9A%E6%9C%AC%E6%89%A7%E8%A1%8C%E6%96%B9%E5%BC%8Fbash%E5%9F%BA%E6%9C%AC%E5%8A%9F%E8%83%BD/" title="01Shell基础概述脚本执行方式Bash基本功能">01Shell基础概述脚本执行方式Bash基本功能</a>
    </li>
    
    <li>
        <a href="https://zaina.newban.cn/posts/01shell%E7%BC%96%E7%A8%8Bhelloworld/" title="01shell编程helloworld">01shell编程helloworld</a>
    </li>
    
</ul>
    </section>

    

    <section class="widget">
        <h3 class="widget-title"><a href="/categories">分类</a></h3>
<ul class="widget-list">
    
</ul>
    </section>

    <section class="widget">
        <h3 class="widget-title"><a href="/tags">标签</a></h3>
<div class="tagcloud">
    
    <a href="https://zaina.newban.cn/tags/ruby/">ruby</a>
    
    <a href="https://zaina.newban.cn/tags/shell/">shell</a>
    
</div>
    </section>

    

    <section class="widget">
        <h3 class="widget-title">其它</h3>
        <ul class="widget-list">
            <li><a href="https://zaina.newban.cn/index.xml">文章 RSS</a></li>
        </ul>
    </section>
</div>
            </div>
        </div>
    </div>
</body>

</html>